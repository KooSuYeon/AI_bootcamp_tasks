{
    "title": "\"AI 연구비 중 3분의 1은 안전·윤리 연구에 사용해야\"",
    "created_at": "2023.10.26 18:10",
    "content": "세계적인 인공지능(AI) 석학들이 AI 기업과 정부에 더 많은 안전 및 윤리 연구 투자를 요구했다. 몇개월 전 첨단 AI의 '6개월 개발 유예' 주장보다는 후퇴한 입장이다. 때맞춰 미국의 선두 AI 기업들도 연구 자금을 내놓겠다고  발표했다.로이터는 24일(현지시간) 튜링상 수상자 3명과 노벨상 수상자 1명이 포함된 최고 석학 집단이 AI 연구 자금 중 최소 3분의 1을 시스템 안전과 윤리적 사용을 보장하는 연구에 할당해야 한다는 논문을 발표했다고 보도했다. 이에 따르면 이번 논문에는 'AI 4대 천왕'으로 꼽히는 요수아 벤지오 몬트리올대학교 교수와 제프리 힌튼 토론토대학교 교수를 비롯해 스튜어트 러셀 UC버클리 교수 등 24명이 포함됐다. 특히 '사피엔스'로 잘 알려진 베스트 셀러 작가 유발 하라리 등 지난 3월 일론 머스크 등과 AI 개발 잠정 중단을 촉구했던 멤버들이 참가했다. 요슈아 벤지오 교수는 \"최근 최첨단 AI 모델은 민주적 감독 없이 개발하기에는 너무 강력하고 중요하다\"라며 \"AI가 취해진 예방조치보다 훨씬 빠르게 발전하고 있기 때문에 AI 안전에 대한 투자는 빨리 이뤄져야 한다\"라고 말했다. 세계적인 컴퓨터 과학자인 스튜어트 러셀 UC 버클리 교수는 \"기업들은 규제를 만족시키기가 너무 어렵다고 불평할 것\"이라며 \"규제가 혁신을 억제한다는 것은 터무니없는 논리\"라고 지적했다. 그 예로 \"샌드위치 가게에 대한 규제가 AI 기업보다 더 많을 것\"이라고 꼬집었다. 논문 발표 다음 날인 25일에는 최첨단 AI 모델 기업들이 실제로 연구 기금을 내놓겠다고 발표했다. 오픈AI와 마이크로소프트, 구글, 앤트로픽 등 '프론티어 모델 포럼'은 첫 이사로 워싱턴의 싱크 탱크인 브루킹스 연구소 크리스 메세롤을 이사로 임명하고 몇달 안에 자문위원회를 구성한다고 밝혔다. 더불어 후원사 등과 최소 1000만달러(약 136억원) 이상의 초기 안전 연구 자금을 마련하겠다고 발표했다. 프론티어 모델 포럼은 지난 7월 백악관에서 발표한 'AI 안전 서약'에 따른 것으로, 인류에 위협을 가할 수 있는 첨단 AI 모델을 보유한 기업이 안전과 윤리를 보장하기 위해 별도로 구성한 협의체다. 이처럼 최근 AI 규제는 최첨단 모델에 집중되는 모양새다. 다음 달 초 영국에서 열리는 G7의 'AI 정상 포럼'에서도 선도 기업을 통제하는 것이 주요 의제로 알려졌다. 임대준 기자 ydj@aitimes.com"
}