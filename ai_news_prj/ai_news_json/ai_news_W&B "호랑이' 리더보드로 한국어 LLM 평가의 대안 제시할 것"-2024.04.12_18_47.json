{
    "title": "W&B \"호랑이' 리더보드로 한국어 LLM 평가의 대안 제시할 것\"",
    "created_at": "2024.04.12 18:47",
    "content": "ML옵스 및 LLM옵스 플랫폼 웨이트앤바이어스(W&B)가 11일 웨비나를 개최하고 최근 출시한 '호랑이' 리더보드의 차별점과 향후 계획을 밝혔다. 케이 카마타 W&B 머신러닝 엔지니어는 호랑이 리더보드를 만든 이유에 대해 \"LLM의 용도에 따라 평가 방법이 달라질 수 있다\"라며 \"객관적이고 통일된 평가 방법이 있어야 머신러닝 발전에 기여할 수 있다\"라고 말했다. 이어 \"호랑이 리더보드는 다각도로 모델을 평가하고 그 결과를 상세하게 분석할 수 있는 기능을 제공, 사용자가 자신의 목적에 맞는 모델을 선택할 수 있도록 돕기 위해 개발됐다\"라고 설명했다. 특히 \"2023년에 출시된 '오픈 Ko-LLM 리더보드'에 다양한 모델들이 등장했으나, 벤치마크의 순위를 의식해 LLM 모델을 조정하는 흐름이 나타나기도 했다\"라고 지적했다. 이에 W&B가 내놓은 호랑이 리더보드는 \"한국어 대형언어모델(LLM) 평가의 대안이 될 것\"이라고 전했다. ▲세부 문항별 답변을 공개하며 ▲ 모델 공개 없이 평가 가능하다는 점 ▲ 자연어처리(NLU)뿐만 아니라 텍스트생성작업(NLG)도 평가할 수 있다는 점 등을 특징으로 꼽았다. 기존 리더보드와 달리, 문제에 대한 실제 답변을 생성한 후 정답에 가까운지 평가하는 방법론을 사용한다. 퓨샷도 가능하지만, 제로샷을 활용해 보조가 없는 상황에서 모델의 능력을 평가한다는 설명이다. 이는 기존 LLM 평가 도구인 '이벨류에이션 하네스(Evaluation Harness)'가 사지선다형의 답찍기처럼 정답 확률을 계산해 답을 선택하는 것과는 달리, 사용자가 입력한 프롬프트에 대해 돌아온 소수의 답변을 평가한다는 의미다. 또 실제 사용자가 LLM을 사용할 때 퓨샷 예시를 주지 않는 것처럼, 제로샷 평가를 통해 학습하거나 참고할 정보가 없는 상황에서도 답변을 생성할 수 있는지 확인할 수 있다. 이로서 LLM의 근본적인 성능을 잘 파악할 수 있는 의미다. 호랑이 리더보드는 다양한 차트를 제공하지만 자연어를 이해하는 능력을 평가하는 'llm-kr-eval'를 가로축으로, 문장의 생성 능력을 평가하는 'MT-벤치(Bench)'를 세로축으로 두고 다양한 모델의 성능을 비교한다. llm-kr-eval은 일본의 가장 큰 LLM 스터디 모임인 llm-jp에서 구축한 평가 지표 'llm-jp-eval'을 한국어 버전으로 제작한 것이다. MT-벤치는 'GPT-4'가 대화의 품질을 1~10점으로 평가하기 때문에 LLM이 대화 흐름과 지시를 따르는 능력을 평가할 수 있다. 일반적인 사용 사례와 도전적인 지시가 포함된 80개의 질문을 통해 생성된 답의 수준을 8개의 카테고리로 분류한다. W&B 관계자는 \"MT-Bench의 한국어 데이터셋을 생성하는 첫 시도\"라고 강조했다. 자연어이해(NLU)와 자연어생성(NLG)의 지표를 통해 일본어 리더보드와 한국어 리더보드를 비교했을 때 \"일본의 모델들은 다양한 파운데이션 모델을 기반으로 제작되고 평가 지표상 차이가 크다\"라고 설명했다. 한편, W&B는 2017년 샌프란시스코에서 창업한 개발자 플랫폼이자 머신러닝 커뮤니티다. 전 세계 70만명 이상의 실무자가 사용하는 중이며, 지난해부터 국내 시장에 진입해 기업 사용자를 확보하고 있다. 특히 창업 초기부터 오픈AI와 교류하며 함께 성장했다고 전했다. 오픈AI의 창업 멤버 중인 폴란드 컴퓨터 과학자 보치엑 자렘바는 \"W&B를 통해 한명의 연구원에서 전체 팀으로, 하나의 머신에서 수천으로 인사이트를 확장할 수 있다\"라고 밝히기도 했다. W&B는 AI 모델 연구·개발 팀에는 실험관리 도구를 제공하며 시스템개발·운영 팀에는 통합적인 ML옵스 환경을 제공할 뿐만 아니라, 다양한 학습 자료와 팟캐스트 등을 공유하고 있다. 카마타 엔지니어는 \"호랑이 리더보드에 관한 웨비나 및 다양한 정보공유를 통해 한국 ML옵스 생태계 조성에 기여하겠다\"라고 강조했다. 박수빈 기자 sbin08@aitimes.com"
}