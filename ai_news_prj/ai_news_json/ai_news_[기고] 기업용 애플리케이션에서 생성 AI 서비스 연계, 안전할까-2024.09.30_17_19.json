{
    "title": "[기고] 기업용 애플리케이션에서 생성 AI 서비스 연계, 안전할까",
    "created_at": "2024.09.30 17:19",
    "content": "생성 인공지능(AI)이 광풍을 일으키고 있다. 이제 AI는 우리가 무심코 사용하는 기업용 애플리케이션에도 필수 요소로 자리잡고 있지만, 동작 방식과 원리에 대해서는 공개되지 않은 부분이 많아 '과연 안전할지' 의문을 불러일으킨다. 국내 금융사를 대상으로 활동하며 느낀 바로는 관계자들로부터 다음 두 가지 질문을 가장 많이 받는다. ▲첫째는 생성 AI의 활용가치 및 해당 금융사 비즈니스에 어떤 영향을 미칠지에 대한 질문 ▲둘째는 과연 생성 AI를 사용할 때 거버넌스나 보안에 문제가 없는지, 외부 서비스를 이용해도 법적으로 문제가 없는지에 대한 것이다. 금융기관에서의 생성 AI 활용가치나 비즈니스 영향도는 이미 많은 금융사와 연구기관들의 연구 결과로 나타나고 있다. 맥킨지의 논문인'생성 AI의 경제적 잠재력(2023년 6월)'에서는 AI가 마케팅 및 세일즈, 대고객 채널 업무, 소프트웨어 엔지니어링 및 리스크 관리 분야에 많은 영향을 미칠 것으로 전망했다. 그렇다면 금융기관은 과연 고객 데이터를 기반으로 외부 서비스를 연계해 생성 AI 프로젝트를 진행할 수 있을까. 금융기관은 기본적으로 금융권 망분리 규제에 따라야 하고, 특수한 요건이 있을 경우 비조치 의견을 구해 망분리 예외를 인정받을 수 있다. 그러나 고객 데이터를 인터넷의 통제할 수 없는 영역에서 활용하는 것은 현행법상 불가능에 가깝다. 그렇다면 응용서비스를 제공하는 서비스형소프트웨어(SaaS) 및 대형언어모델(LLM) 기업들은 AI 서비스 보안 우려에 어떻게 준비, 대처하고 있을까. 먼저 오픈AI는 'GPT-4o' 출시 전에 수행된 안전 작업을 설명하기 위해GPT-4o 시스템 카드를 출시했다. 이들은 자체 프레임워크를 기반으로 GPT-4o의 사이버 보안 위험을 '낮음'으로, 설득 위험을 '중간'으로 평가했다. 세일즈포스는 '세일즈포스 생성 AI 프론티어 전반에 걸친LLM 리스크 완화'라는 논문을 발표했다. 이 논문은LLM과 관련된 상위 10개 OWASP 리스크 및 취약점을 완화하는 방법을 설명하고 있다. SAP는 'SAP생성 AI 사이버 보안 전략'을 발표했다. SAP의 생성 AI 보안 방법론은 업계에서 널리 사용하는 표준인 NICT CSF(사이버 보안 프레임워크)와 상당 부분 일치한다. 워크데이는 책임 있는 AI 거버넌스에 대한 연구를 활발하게 진행 중이다. 마지막으로 오라클은 본사차원에서 관리하고 있는보안정책과 프랙티스를모든 고객에게 공유하고 전사적인 가이드로 관리한다. 오라클 퓨전 제품 관리 측면에서도 ‘책임 있는 AI’ 및 ‘클라우드 인프라 주제’ 섹션은 물론 여러 거버넌스, 개인정보보호 및 보안 질의응답을 포함, 기존 고객에게는오라클 퓨전 AI 플랫폼 데이터 보안 정책과 원칙을공유하고 있다. 기업에서 사용하는 CRM, ERP, HR 등의 비즈니스 애플리케이션과 범용 생성형 AI 서비스는 어떠한 흐름으로 연계될까. 아래 그림은 관련 클라우드 서비스 간의 흐름을 보여 준다. 금융 기관에서 구성도와 같이 응용 애플리케이션과 생성 AI 서비스를 연결, 새로운 AI 서비스를 기획할 때 유념해야 할 사항은 무엇일까. 현행법상 고객 정보를 저장하는 저장소는 국내 데이터센터에 위치해야 한다. 따라서 도입하고자 하는 서비스의 기반 지역과 데이터 저장 경로를 검토할 필요가 있다. 만일 데이터가 해외에 있는 LLM서비스와 연동될 경우, 데이터 흐름상에 고객 데이터가 있는지 여부를 면밀히 살펴야 한다. ▲LLM이 학습과정에서 고객 데이터를 사용하지는 않는지 ▲데이터가 LLM서비스 저장소에 유지되거나 저장되지는 않는지 ▲LLM 공급자에게 전송되지 않는지 확인이 필요하다. 더불어 ▲클라우드 환경에서 다른 고객사와 데이터가 결합되거나 공유되지 않는지 ▲별도 인스턴스 관리 및 별도 버킷에 스토리지 저장/고유 네임스페이스 관리 등 격리된 구조를 유지하는지 살펴야 한다. 데이터 저장소의 암호화 여부, 전송 과정의 암호화 여부 역시 확인이 필요한 부분이다. 참고로 오라클 비즈니스 애플리케이션 데이터는 오라클 클라우드 내부에 유지되고 코히어(LLM 서비스)로 전송되지 않는 구조다. 마찬가지로 외부 AI와 생성 AI 서비스도 사용자의 역할, 그룹, 데이터 및 위치에 따라 역할 및 위치 기반 액세스 제어 등을 고려해야 한다. 즉 애플리케이션 서비스에 있는 데이터 접근 제어와 동일한 정책을 적용해야 한다. 비즈니스 애플리케이션과 동일한 클라우드 인프라를 이용한다면, 이를 관리하기 위한 시간과 비용을 절약하고 위험을 최소화할 수 있게 된다. 클라우드 서비스 제공자는 특정 생성 AI 사용 사례에 대해 선택된 프롬프트 설계, 엔지니어링된 프롬프트 및 데이터 기능에 있어서 환각 현상의 완화 및 응답의 관련도와 유용성 개선을 위해 개발, 테스트, 튜닝 과정을 거치게 된다. 결과적으로 금융기관에서는 클라우드 서비스 공급업체(CSP)안전성 평가 과정에서 이 부분을 세밀하게 살펴볼 필요가 있다. AI 윤리 가드레일 서비스로 표현되는 정확성, 유해성, 감정 및 반복성 등 평가과정을 거치는지도 확인해야 한다. LLM이 제공하는 응답을 검토, 편집 또는 재작성하는 데 항상 우선권을 확보할 수 있는지도 살펴봐야 한다. 최근 금융위는 기업용 SaaS 서비스와 AI 서비스 도입의 한계를 고려해 망분리 요건을 점진적으로 완화할 계획이라고 발표한 바 있다. 그 시기가 미정일 뿐 물리적 망분리가 점차 사라질 것은 기정사실로 보인다. 다만 기존 클라우드 이용가이드로 유추해본다면 외부 서비스를 원천적으로 차단하는 망분리 요건은 완화하되 금융기관에서 통제하고 관리해야 할 부분에 대해서는 요건을 추가할 가능성이 높다. 신규 AI연계서비스를 고려하는 금융 기관에서는 고객데이터와 금융정보에 대한 보안 요건을 세부적으로 확인하고 검증해야 할 것이다. 이의형 한국오라클 상무"
}