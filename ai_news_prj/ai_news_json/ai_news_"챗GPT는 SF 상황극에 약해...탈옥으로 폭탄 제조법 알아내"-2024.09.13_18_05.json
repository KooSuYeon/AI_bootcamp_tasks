{
    "title": "\"챗GPT는 SF 상황극에 약해...탈옥으로 폭탄 제조법 알아내\"",
    "created_at": "2024.09.13 18:05",
    "content": "한 해커가 상황극으로 '챗GPT'를 탈옥시켜 폭탄 제조법을 알아냈다고 주장했다.. 상황극이 탈옥에 효과적이라는 것은 잘 알려진 사실이지만, 이번에는 '공상과학(SF)'이라는 특정 장르를 동원해 성공했다고 전했다. 테크크런치는 12일(현지시간) 아마돈이라는 해커가 오픈Ai가 설정한 가드레일을 우회, 폭발물 제조법을 제공하도록 챗GPT를 속이는 방법을 찾아냈다고 보도했다. 이에 따르면 아마돈은 자신의 발견을 \"챗GPT의 출력에 대한 모든 안전 장치를 완전히 무너뜨리는 사회 공학적 해킹\"이라고 소개했다. 그는 폭탄 제조법을 유도한 프롬프트와 그 결과는 위험성 때문에 공개하지 않는다고 밝혔다. 대신, 챗GPT에게 \"게임을 하자\"라며 폭탄 제조 지침을 생성하도록 속일 수 있었다고 설명했다. 이후 일련의 프롬프트를 사용, 챗봇이 안전 가이드라인이 적용되지 않는 가상의  공상과학(SF) 판타지 세계를 만들도록 유도했다는 것이 핵심이다. 그 결과, 처음에는 거부했지만 몇번의 대화가 진행된 뒤 챗GPT는 응답으로 폭발물을 만드는 데 필요한 재료를 나열하기에 이르렀다. 이어 대화가 진행되며 챗GPT는 재료를 결합해 지뢰나 함정, 즉석 폭발 장치(IED)와 같은 폭발물을 만들 수 있다고 설명했다. 최종적으로는 지뢰밭과 클레이모어 스타일의 폭발물을 만드는 구체적인 지침을 제공했다. 이를 검토한 폭발물 전문가도 결과로 나온 지침은 실제로 폭발 가능한 제품을 만드는 데 사용할 수 있으며, 위험해서 공개해서는 안 된다고 경고했다. 과거에는 챗GPT를 탈옥시키기 위해 할머니 역할을 요청하고 네이팜탄 제조법 설명을 얻어냈다는 사례가 화제가 됐다. 이처럼 상황극은 탈옥의 일반적인 방법으로 지목된다. 아마돈은 “특히 SF 시나리오는 비현실적인 세계를 배경으로 하기 때문에 AI가 검열된 콘텐츠를 찾는 맥락에서 벗어나게 한다”라고 강조했다. 그는 자신의 발견을 챗GPT의 버그 및 보안 취약점 등을 보고하면 보상하는 '버그 바운티 프로그램’을 통해 보고했다. 그러나 오픈AI는 \"모델 안전 문제는 개별적이고 명확하게 수정할 수 있는 버그가 아니기 때문에 버그 바운티 프로그램에 적합하지 않다”라며 “이 문제는 다른 방법으로 보고하라\"라고 전한 것으로 알려졌다. 그 결과, 탈옥법은 매체에 소개됐다. 박찬 기자 cpark@aitimes.com"
}