{
    "title": "GPT-4, EU AI 법 '초강력 규제' 대상에 포함",
    "created_at": "2023.12.10 10:03",
    "content": "유럽연합(EU)의 'AI 법' 합의에 따라, 오픈AI의 'GPT-4'가 가장 높은 수준의 규제 대상에 포함되는 것으로 알려졌다. 또 오픈 소스 모델은 강력 규제를 일단 피했으나, 학습에 사용한 데이터셋을 공개해야 하는 문제가 남은 것으로 밝혀졌다. 결국 나머지 기간 중 세부 사항 조율에 따라 인공지능(AI)  업계에 미칠 영향이 크게 변할 수 있다는 분석이. 블룸버그와 로이터 등은 9일(현지시간) EU가 전날 합의한 AI 법에 따른 향후 영향과 반응, 분석 등을 소개했다. 이에 따르면 생성 AI 모델은 ▲허용할 수 없는 위험 ▲높은 위험 ▲생성 AI ▲제한된 위험의 4가지 위험 등급으로 구분, 규제 범위를 적용받게 된다. 단계별 규정 수위가 어떤지에 대해서는 상세하게 알려진 부분이 없으며, 세부안도 아직 완전 합의가 이뤄진 것은 아니다. 하지만 이제까지 공개된 정보를 종합하면, GPT-4는 가장 강력한 제재 대상에 포함될 것으로 보인다. EU는 생성 AI 중 ▲메일 작성을 돕거나 문서를 요약하는 등 단순한 생산성 애플리케이션은 규제 대상이 아니며 ▲애플리케이션의 기반이 되는 범용 AI(GPAI), 즉 파운데이션 모델은 다양한 투명성 요구 사항을 충족해야 하는 등 규제를 받는다. ▲그중에서도 가장 위험성이 큰 첨단 모델은 별도의 강력한 요구 사항을 충족해야 하는 것으로 합의했다. GPAI에 적용되는 규정은 ▲시스템 카드를 통해 세부 사항을 공개하고 ▲EU에 부합하는 사용 정책을 가져야 하며 ▲모델 훈련 방법에 대한 최신 정보를 공개해야 하고 ▲모델 학습에 사용한 데이터에 대한 자세한 정보를 보고해야 하며 ▲저작권법을 따르는 정책을 가져야 한다는 것 등이다. 여기에는 대부분 빅테크나 스타트업이 자제 개발한 모델이 포함될 것으로 보인다. 알려진 대로 오픈 소스의 경우 투명성을 이유로 상세한 시스템 카드 공개로 이 항목에서 면제된다. 다만 오픈 소스라고 해도 학습 데이터셋에 대한 정보 공개 문제가 남아있다는 점은 문제가 된다. 프리츠-율리 피에퍼 테일러 웨싱 IT 법률 전문가는 \"수정해야 할 영역이 많이 남아 있다. 예를 들어 오픈 소스는 예외를 인정받았으나, 투명성과 저작권 의무가 있다\"라며 \"최종 합의안이 어떤 형태가 될지, 심지어 합의할 수 있을지는 지 아무도 모른다. 진짜 '악마'는 최종 텍스트의 세부 사항에 있을 것\"이라고 지적했다. '시스템적 위험'을 초래하는 것으로 간주하는 첨단 모델에는 더 엄격한 추가 규칙이 적용된다. EU는 모델을 훈련하는 데 사용되는 컴퓨팅 성능의 양을 기반으로 해당 위험을 결정할 예정인데, 기준값은 누적 컴퓨팅양이 엑사플롭스(EP)의 10만배에 달하는(Septillion) 모델이다. 전문가들은 현재 이 수치에 도달한 유일한 모델로 GPT-4를 지목했다. EU 행정부는 이 밖에도 데이터셋의 크기, EU에 등록된 비즈니스 사용자가 1만명 이상인지 여부, 등록된 최종 사용자 수 등 기타 항목을 기준으로 다른 모델을 초위험군으로 지정할 수도 있다. 이래저래 오픈AI가 빠져나갈 길은 없을 것으로 보인다. 이런 능력을 갖춘 모델은 EU가 제시한 행동 강령에 서명해야 한다. 여기에는 ▲에너지 소비 보고 ▲내부 및 외부 레드팀 구성을 통한 적대적 테스트 수행 시스템적 위험 평가 및 모든 사고 내용 보고 ▲적절한 사이버 보안 조치 확인 ▲모델 미세조정에 사용한 데이터셋 보고 ▲더 에너지 효율적인 표준이 개발되는 이를 반영 등이 포함돼 있다. 서명하지 않을 경우에도 AI 법을 준수하고 있다는 것을 증명해야 한다. 또 강력 규제에서 면제된 오픈 소스 모델이라고 해도 시스템적 위험을 초래하는 것으로 간주하면 여기에 포함될 수도 있다. AI 법을 어길 시에는 750만유로(약 100억원) 또는 매출액의 1.5%부터 3500만유로(약 500억원) 또는 전 세계 매출액의 7%까지 다양한 벌금을 부과하기로 했다. 이에 따라 오픈AI는 물론 구글이나 앤트로픽, 인플렉션AI, 코히어 등 미국기업의 폐쇄형 모델은 대부분 GPAI에 포함, 강력한 규제를 받게 될 것으로 보인다. 특히 학습에 사용된 데이터셋의 저작권 문제 공개 여부는 상당히 심각한 문제로 확대될 수 있다. 이 때문에 샘 알트먼 오픈AI CEO는 지난 5월 \"과잉 규제 시 유럽을 떠나겠다\"라고 말했다가, EU의 거센 비난을 받고 하루 만에 말을 바꾸기도 했다. 또 미국 빅테크들은 말을 아끼며 AI 법 진행 상황을 주시하고 있었다. 그러나 이 법안이 최종 통과되면 당장 데이터셋 공개 문제에 따라 대부분 파운데이션 모델 기업은 큰 곤란을 겪을 수밖에 없다. 데이터셋 내용을 상세하게 파악하는 것은 기술적으로 힘들뿐더러 저작권자들의 줄소송을 일으킬 수 있다. 이에 따라 AI 법이 어떤 형태로 최종 확정될지, 주요 빅테크들이 어떻게 대응할지 큰 관심이 모인다. 다만 AI 법은 실제 시행까지 2년여를 남겨두고 있다. 임대준 기자 ydj@aitimes.com"
}