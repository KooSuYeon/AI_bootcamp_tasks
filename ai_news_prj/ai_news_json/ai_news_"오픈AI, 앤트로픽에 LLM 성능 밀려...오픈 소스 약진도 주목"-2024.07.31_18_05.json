{
    "title": "\"오픈AI, 앤트로픽에 LLM 성능 밀려...오픈 소스 약진도 주목\"",
    "created_at": "2024.07.31 18:05",
    "content": "갈릴레오라는 AI 스타트업이 실시한 대형언어모델(LLM) 모델 성능 측정에서 앤트로픽의 '클로드 3.5 소네트'가 오픈AI의 'GPT-4o'를 제치고 최고의 LLM에 선정됐다. 또 알리바바의 '큐원 2'나 메타의 '라마 3' 등 오픈 소스도 빠른 속도로 성능을 끌어 올린 것으로 확인됐다. AI 스타트업 갈릴레오는 30일(현지시간) 'LLM 환각 지수 RAG 스페셜'이라는 LLM 벤치마크 결과를 발표했다. 이는 지난해 11월에 이은 두번째 발표로, 22종의 주요 모델을 대상으로 환각 여부를 측정한 것이다. 여기에는 폐쇄형 모델 10개와 오픈 소스 12개가 포함됐다. 이 중 전체 1위인 '가장 성능이 좋은 모델'에는 클로드 3.5 소네트가 올랐다. '모든 작업에서 뛰어난 성능을 보였으며, 최대 200k의 컨텍스트 지원이 가능했다'라는 설명이다. '비용 대비 최고의 성능' 분야는 구글의 '제미나이 1.5 플래시'가 선정됐다. 또 '가장 우수한 오픈소스 모델'은 알리바바의 '큐원2 72B'를 꼽았다. 이 벤치마크는 컨텍스트 크기에 따라 분야를 구분했다. 짧은 컨텍스트(5000 토큰 이하)와 중간 컨텍스트(5000~2만5000 토큰), 긴 컨텍스트(4만~10만 토큰) 등이다. 이중 클로드 3.5 소네트는 짧은 컨텍스트와 긴 컨텍스트 두 분야에서 최고 성능을 발휘했다. 중간 크기에서는 제미나이 1.5 플래시가 1위였다. 오픈AI는 10개월 전 이 순위에서는 전 분야 1위에 올랐다. 하지만 이번에는 단 한 분야에서도 최고를 기록하지 못했다. 갈릴레오는 이번 벤치마크에 대해 오픈 소스의 약진을 가장 큰 특징으로 꼽았다. \"폐쇄형 모델이 독점적인 훈련 데이터 덕분에 여전히 최고의 성능을 제공하지만, 제미나이나 라마, 큐원 등 오픈 소스 모델이 폐쇄형에서 발생하는 비용 장벽 없이 환각 성능이 지속적으로 개선되고 있다\"라고 설명했다. 또 전반적으로 품질이나 정확성을 잃지 않고도 확장된 컨텍스트에서 좋은 성능을 보였다며, 모델 학습과 아키텍처가 얼마나 발전했는지를 보여준다고 전했다. 특히 제미나이 1.5 플래시 같은 작은 모델이 큰 모델보다 성과가 좋은 경우가 있었다며, 이는 모델 설계의 효율성이 규모보다 더 중요할 수 있음을 시사한다고 분석했다. 그리고 앤트로픽의 클로드 3.5 소네트와 '클로드 3 오퍼스'가 반복적으로 완벽에 가까운 점수를 받았으며, 특히 짧은 맥락 시나리오에서 GPT-4o와 'GPT-3.5'를 앞질렀다고 밝혔다. 이번 벤치마크 결과는 최근 LLM 트렌드를 반영하는 것으로 보인다. 또 오픈AI는 더 이상 최고가 아니라는 것을 보여 줬으며, 이에 따라 GPT-5 출시 필요성이 더 커진 것으로 볼 수 있다. 임대준 기자 ydj@aitimes.com"
}