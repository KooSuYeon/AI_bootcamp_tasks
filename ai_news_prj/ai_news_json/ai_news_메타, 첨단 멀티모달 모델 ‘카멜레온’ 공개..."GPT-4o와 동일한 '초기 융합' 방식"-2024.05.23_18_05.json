{
    "title": "메타, 첨단 멀티모달 모델 ‘카멜레온’ 공개...\"GPT-4o와 동일한 '초기 융합' 방식\"",
    "created_at": "2024.05.23 18:05",
    "content": "메타가 텍스트나 이미지 등 다른 양식을 처리하기 위해 복수의 모델을 하나로 결합하는 대신, 단일 모델에서 한꺼번에 처리하는 첨단 멀티모달 언어모델(LMM)을 공개했다. 이 방식을 사용하는 것은 'GPT-4o'와 '제미나이' 정도인데, 메타는 제미나이보다 구조적으로 앞섰다고 설명했다. 벤처비트는 22일(현지시간) 메타는 다중 양식을 단일 요소에서 처리하는 LMM ‘카멜레온(Chameleon)’에 관한 논문을온라인 아카이브에 게재했다고 전했다. 기존 LMM들은 다양한 양식이 입력되면 이를 텍스트나 이미지를 처리하는 개별 모델로 인코딩한 뒤 추론을 위해 인코딩을 융합하는 ‘후기 융합(late fusion)’ 방식을 사용한다. 다른 양식에 대해 훈련된 모델들을 연결, 이미지 및 코드와 같은 다른 양식을 텍스트로 변환한 후 다시 토큰으로 변환하는 식이다. 이 방식은 잘 작동하는 편이지만, 모델이 양식 간의 정보를 통합하고 이미지와 텍스트가 혼합된 시퀀스를 생성하는 능력을 제한되는 약점이 있다. 반면, 카멜레온은 처음부터 단일 모델에서 이미지, 텍스트, 코드 등 다중 양식이 혼합된 데이터로 훈련하는 ‘초기 융합 토큰 기반 혼합 모달(early-fusion token-based mixed-moda)’ 방식을 사용한다. 카멜레온은 이미지도 단어를 처리하는 방식처럼 개별 토큰으로 변환한다. 또 텍스트, 코드, 이미지 토큰이 통합된 단일 체계의 어휘를 사용한다. 이를 통해 텍스트, 코드, 이미지 토큰이 모두 포함된 시퀀스에 동일한 '트랜스포머' 아키텍처를 적용할 수 있다. 단일 모델에서 처음부터 다중 양식이 통합된 토큰으로 훈련, 텍스트로 변환하지 않고도 이미지와 코드를 직접 분석하고 해석할 수 있다는 설명이다. 메타에 따르면 카멜레온과 가장 유사한 모델은 구글 제미나이로, 이 역시 초기 융합 접근 방식을 사용한다. 다만 제미나이는 생성 단계에서 별도의 '이미지 디코더'를 사용하는 반면, 카멜레온은 토큰을 처리하고 생성하는 엔드 투 엔드 모델이다. 최근 공개된 오픈AI의 GPT-4o도 초기 융합 접근 방식을 사용하는 것으로 알려졌다. GPT-4o 역시 단일 모델에서 처음부터 멀티미디어 토큰으로 훈련, 텍스트로 변환하지 않고도 비전과 오디오를 직접 분석하고 해석할 수 있는 엔드 투 엔드 모델이다. 메타는 4.4조개의 토큰으로 구성된 텍스트, 이미지-텍스트 쌍, 텍스트와 이미지가 혼합된 시퀀스를 포함하는 데이터셋으로, 엔비디아 'A100' 80GB GPU를 사용해 7억 및 340억 매개변수 버전의 카멜레온을 500만 시간 이상 훈련했다. 그 결과 시각적 질문 답변 및 이미지 캡션 벤치마크에서 카멜레온-34B는 플라멩고, IDEFICS 및 라바-1.5와 같은 모델을 능가하는 성능을 기록했다. 또 단일 양식 요청에서 성능 저하가 발생하는 기존 LMM의 단점도 극복했다는 설명이다. 일반적으로 비전-언어 모델은 텍스트만으로 이뤄진 프롬프트에서 성능이 낮아지는 경향이 있다. 그러나 카멜레온은 텍스트만으로 이루어진 벤치마크에서도 경쟁력을 유지하며, 상식 추론 및 독해 과제에서 '믹스트랄 8x7B' 및 '제미나이 프로'와 같은 성능을 보였다. 특히 인간 선호도 평가에서 제미나이 프로나 GPT-4V 등 훨씬 모델과 일치하거나 그 이상의 점수를 받았다고 강조했다. 메타는 \"카멜레온은 멀티모달 통합 모델링에서 중요한 진전을 이뤘다\"라고 자평했다. 박찬 기자 cpark@aitimes.com"
}