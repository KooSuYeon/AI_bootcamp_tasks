{
    "title": "메타, 온디바이스 AI 언어모델 ‘모바일LLM’ 공개",
    "created_at": "2024.07.09 18:00",
    "content": "메타가 스마트폰이나 소형 장치용으로 설계된 효율적인 온디바이스 인공지능(AI) 모델을 선보였다. 벤처비트는 8일(현지시간) 메타가 온디바이스 애플리케이션을 위해 최적화된 소형언어모델 ‘모바일LLM(MobileLLM)’ 연구 결과를 아카이브에 게재했다고 보도했다. 이에 따르면 메타는 10억개 미만의 적은 매개변수를 가진 모델을 최적화하기 위해 네트워크 깊이 조정, 임베딩 공유 및 가중치 공유 기술을 적용했다. 일반적으로 매개변수가 작은 소형 모델의 경우, 모델의 레이어의 수를 늘리는 것이 성능을 향상한다. 또 입력 임베딩 가중치를 출력 연결 레이어 가중치로 재사용하는 임베딩 공유를 통해 효율적이고 컴팩트한 모델 아키텍처를 얻을 수 있으며, 공유 가중치를 캐시에 배치하고 이를 즉시 두번 계산하면 SRAM과 DRAM 간에 가중치를 전송할 필요가 없어 추론 실행 속도가 빨라진다. 이런 설계를 통해 모바일LLM은 벤치마크에서 비슷한 크기의 다른 모델보다 2.7~4.3% 더 나은 성과를 낼 수 있었다. 한자릿수 개선은 사소해 보일 수 있지만, 경쟁이 치열한 언어 모델 개발 분야에서 의미 있는 진전이라는 평가다. 특히, 모바일LLM의 매개변수 3억5000만개 버전은 특정 API 호출 작업에서 70억 매개변수 '라마2'와 비슷한 정확도를 보였다. 이는 일부 애플리케이션의 경우, 더 작은 모델이 훨씬 적은 계산 리소스를 사용하면서도 유사한 성능을 제공할 수 있다는 설명이다. 메타는 모바일LLM을 아직 공개하지 않았지만, 사전 훈련 코드를 오픈 소스로 공개할 계획이다. 박찬 기자 cpark@aitimes.com"
}