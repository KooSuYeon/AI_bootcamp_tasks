{
    "title": "텐센트, 오디오 생성 AI 모델 ‘이지오디오’ 오픈 소스 공개",
    "created_at": "2024.09.19 18:00",
    "content": "중국 텐센트가 텍스트 프롬프트에서  빠르고 효율적이며 현실감 넘치는 음향 효과를 생성하는 새로운 텍스트-오디오 생성 모델을 공개했다. 벤처비트는 18일(현지시간) 텐센트와 존스홉킨스대학교 연구진이 텍스트 프롬프트로부터 고품질 음향 효과를 높은 효율로 생성할 수 있는 텍스트-오디오 생성 모델 ‘이지오디오(EzAudio)’에 관한논문을 발표했다고 보도했다. 이지오디오는 이미지 생성 AI에 사용하는 '확산 모델(diffusion model)'을 사용한다. 이는 의도적으로 오류를 도입한 훈련 데이터셋으로 구축한 신경망으로, 노이즈를 줄여가면서 의미있는 오디오 파일을 생성하는 방식이다. 일반적으로 확산 모델은 생성하는 오디오 품질, 계산 비용, 확산 샘플링, 데이터 준비 등에서 어려움을 겪는다. 이를 해결하기 위해 이지오디오는 '잠재 확산 모델(latent diffusion models)'로 알려진 특수 확산 모델을 사용한다. 잠재 확산 모델은 '오토인코더(autoencoder)'라는 신경망을 함께 사용, 2D 스펙트로그램 표현을 다루는 복잡성을 피하고 추가적인 신경 음성 변환기(vocoder)의 필요성을 제거했다. 데이터 부족 문제를 해결하기 위해 라벨이 없는 데이터를 활용해 음향 종속성을 학습하고, 오디오-언어 모델로 주석을 단 오디오 캡션 데이터를 텍스트-오디오 정렬 학습에 사용하며, 인간이 라벨링한 데이터로 미세조정했다. 이를 통해 데이터셋의 품질을 높였기 때문에, 이를 학습한 잠재 확산 모델은 큰 용량의 고품질 결과물을 생성할 수 있다. 잠재 공간에는 기반이 되는 데이터셋의 가장 중요한 세부 정보만 포함된다. 관련성이 낮은 세부 정보가 제거, 훈련 중에 AI 모델이 처리해야 하는 총 정보량이 줄어든다. 이런 데이터 양의 감소는 AI 훈련에 필요한 하드웨어의 양을 줄여 비용을 절감한다. 오디오 잠재 표현과 확산 모델링에 특화된 최적화된 확산 변환기 아키텍처 ‘이지오디오-DiT’를 설계해 수렴 속도, 학습 안정성, 메모리 사용을 개선하고, 학습 과정을 더 쉽고 효율적으로 만들었다. 이지오디오는 객관적 지표와 주관적 평가에서 기존 오픈 소스 모델을 능가하며, 간소화된 모델 구조, 낮은 학습 비용, 쉽게 따를 수 있는 학습 파이프라인을 유지하면서 사실적인 청취 경험을 제공한다는 설명이다. 벤치마크에서 이지오디오는 프레셰 거리(Frechet Distance), 쿨백-라이블러(Kullback-Leibler) 발산, 인셉션 점수(Inception Score) 등 여러 지표에서 뛰어난 성능을 보였다. 현재 이지오디오의 코드, 데이터, 사전 학습된 모델은깃허브에서제공된다. 박찬 기자 cpark@aitimes.com"
}