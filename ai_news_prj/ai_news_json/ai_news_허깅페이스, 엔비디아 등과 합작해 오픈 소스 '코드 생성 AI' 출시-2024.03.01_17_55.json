{
    "title": "허깅페이스, 엔비디아 등과 합작해 오픈 소스 '코드 생성 AI' 출시",
    "created_at": "2024.03.01 17:55",
    "content": "허깅페이스가 엔비디아, 서비스나우 등 빅테크들과 협력, 오픈 소스 코드 생성 대형언어모델(LLM) '스타코더2(StarCoder2)' 시리즈를 출시했다. 각 회사가 미세조정한 3가지 라인업을 갖춘 것은 물론, 성능과 효율성을 높이고 투명성을 강화해 경쟁력을 갖췄다고 강조했다. 테크크런치는 28일(현지시간) 허깅페이스가 ▲서비스나우가 훈련한 30억 매개변수 ‘스타코더2 3B’ ▲자체적으로 훈련한 70억 매개변수 ‘스타코더2 7B’ ▲엔비디아가 훈련한 150억 매개변수 ‘스타코더2 15B’ 등 코드 생성에 특화된 오픈 소스 LLM을 동시에 출시했다고 보도했다. 이 모델은 지난해 허깅페이스가 공개한 '스타코더'의 후속 버전이다. 사전 훈련에는 이전 세대 데이터셋 ‘스택 v1’에서 사용했던 데이터보다 7배 이상 규모가 큰 ‘스택v2’라는 코드 데이터셋을 활용했다. 여기에 ‘코볼(COBOL)’ 같이 온라인 리소스가 거의 없는 언어 처리나 프로그램 소스 코드의 수학적 처리를 돕는 새로운 학습 기법을 도입, 성능을 높였다. 이를 통해 기존 80개의 프로그래밍 언어를 훌쩍 뛰어넘는, 최대 619개의 프로그래밍 언어를 지원한다. 3가지 모델은 허깅페이스의 'TRL'이나 엔비디아의 '네모' 등을 통해 각 회사 데이터로 미세조정한 결과다. 이를 통해 \"성능은 획기적으로 향상했고, 운영 비용은 저렴하게 만들었다\"라며 \"엔비디아 'A100'과 같은 GPU에서 몇시간 만에 맞춤형 챗봇이나 코딩 어시스턴트를 제작할 수 있다\"라고 전했다. 기업은 각자 상황에 따라 적절한 규모의 모델을 선택, 컴퓨팅 비용을 조절할 수 있다는 것이 장점이다. 코드 완성, 코드 요약, 코드 스니펫 검색 등 다양한 목적으로 사용할 수 있다. 벤치마크에서도 경쟁력이 있는 것으로 나타났다. 스타코더2 15B는 기존 오픈 소스 최강인 '코드 라마' 중 33B 모델보다 두배 빠른 속도를 보였다고 밝혔다. 사용 허가를 받은 소스 코드를 학습, 법적 문제를 해결했다고도 밝혔다. 스타코더2는 가장 큰 규모의 공개 소스 코드 컬렉션을 호스팅하는 빅코드 '오픈레일-M(OpenRAIL-M)' 라이선스에 따라 로열티 없이 사용할 수 있다. 이 라이선스는 상업적 용도에 대해서는 자유롭지만, 의료용 챗봇 제작을 금지하는 등 책임감 있는 사용 면에서는 제약이 따르는 편이다. 레안드로 폰 베라 허깅페이스 기계 학습 엔지니어이자 빅코드 공동 리더는 \"최근 코드 생성 모델이 늘어나고 있지만, 훈련에 사용한 데이터 정보가 동반된 경우는 거의 없다\"라며 \"우리는 훈련 데이터를 포함해 전체 파이프라인을 공개한 완전 개방형 모델\"이라고 강조했다. 스타코더2 중 규모가 작은 모델 2개는 허깅페이스에서 바로 다운로드 가능하며, 150억개의 매개변수의 가장 큰 모델은 '엔비디아 AI 기반 모델(Nvidia AI Foundation Model)' 플랫폼을 통해 사용할 수 있다. 한편 코드 생성 AI는 최근 치열한 경쟁이 벌어지는 분야다. 특히 메타는 지난 1월 ‘코드 라마 70B’를 오픈 소스로 출시, 기존 유료 서비스와의 경쟁을 예고했다. 반면 MS는 전날, 기존 코드 생성 기능을 확장해 기업용으로 적합하게 만든 '코파일럿 엔터프라이즈'를 월 39달러의 유료 모델로 출시했다. 박찬 기자 cpark@aitimes.com"
}