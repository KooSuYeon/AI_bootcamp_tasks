{
    "title": "스태빌리티AI, 오픈소스 LLM ‘프리윌리’ 출시",
    "created_at": "2023.07.25 18:20",
    "content": "스태빌리티 AI가 새로운 오픈소스 대형언어모델(LLM)을 공개했다. 이번에 공개한 LLM은 오픈소스 LLM을 기반 모델로 사용해 합성 데이터를 포함하는 소규모 데이터세트로 미세조정한 것이 특징이다. 특히 방대한 데이터세트로 훈련하는 기존 LLM들과 달리 작은 데이터세트로 훈련한 규모가 작은 오픈소스 모델로도 뛰어난 성능을 보여줬다는 점에서 비용 효율적이고 환경 친화적인 LLM의 방향성을 제시한 것으로 평가된다. 벤처비트는 24일(현지시간) 스태빌리티 AI가 2개의 오픈소스 대형언어모델(LLM) ‘프리윌리1(FreeWilly1)’과 ‘프리윌리2(FreeWilly2)’를 비상업적 라이선스로 공개했다고 보도했다. 이 모델은 비즈니스 또는 엔터프라이즈 목적으로 사용할 수 없지만 인공지능(AI) 커뮤니티에서 연구 목적으로 활용 가능하다. 보도에 따르면 프리윌리1은 메타의 라마-65B를 기반으로 한 합성 데이터세트를 사용해 감독 미세조정(SFT)을 통해 조정됐으며 프리윌리2는 라마2 70B를 통해 개발됐다. 특히 두 모델은 다양한 벤치마크 테스트에서 GPT-3.5 기반의 챗GPT를 능가하는 성능을 기록한 것으로 나타났다. 상식과 추론 능력을 검증하는 헬라스웩 테스트에서 챗GPT와 프리윌리2는 86.4%의 성능을 기록해 챗GPT의 85.5%를 능가했다. 또한 AI 언어 능력을 검증하는 MMLU 테스트에서 프리윌리2가 68.8%의 성능을 기록했고 챗GPT는 70%의 성능을 기록해 근소하게 앞섰다. 미국판 수능인 SAT 시험에서는 프리윌리2가 수학 과목을 제외한 모든 항목에서 GPT-3.5와 동등하거나 더 높은 성능을 보여줬다. 프리윌리1와 프리윌리2는 소규모 모델이 제한된 데이터를 사용해 대규모 모델에 필적하는 성능을 달성할 수 있도록 하는 마이크로소프트(MS)의 ‘오르카(Orca)’ AI 훈련 방법론을 채택했다. 그에 따라 스태빌리티 AI는 기존의 주요 LLM에 비해 작고 비용이 적게 들며 에너지 소모와 탄소 배출량을 줄이는 환경 친화적인 모델을 구축할 수 있었다. 프리윌리 모델의 또 다른 흥미로운 측면은 합성 데이터를 사용한다는 것이다. 스태빌리티 AI는 두 개의 다른 LLM을 활용해 50만개의 예시와 10만개의 합성 예시를 생성했다. 이 접근 방식은 AI 생성 데이터에 대해 훈련된 LLM에서 관찰되는 ‘모델 붕괴’ 문제를 해결할 가능성을 보여준다. 모델 붕괴는 AI 모델들이 생성하는 콘텐츠가 시간이 갈수록 인터넷에 쌓이면서 인간이 만든 콘텐츠의 양을 능가하게 되면 인터넷 상의 글과 이미지를 훈련 데이터로 쓸 수 밖에 없는 차기 생성 AI 모델들은 성능이 저하되고 콘텐츠에서 더 많은 오류가 나오는 현상을 일컫는다. 합성 데이터를 사용하면 저작권 또는 독점 데이터의 사용을 피할 수 있을 뿐만 아니라 모델 붕괴를 방지하는 데에도 도움이 될 수 있다. 스태빌리티 AI는 프리윌리1과 프리윌리2가 오픈소스 LLM 영역에서 새로운 표준으로 자리 잡음으로써 연구를 촉진하고 자연어 이해를 향상하며 복잡한 작업을 가능하게 할 것으로 기대하고 있다. 두 모델은 현재 허깅페이스 오픈소스 LLM 리더보드에서 선두를 지키고 있다. 박찬 기자 cpark@aitimes.com"
}