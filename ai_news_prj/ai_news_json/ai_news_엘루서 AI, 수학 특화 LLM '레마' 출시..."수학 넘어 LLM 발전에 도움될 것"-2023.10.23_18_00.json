{
    "title": "엘루서 AI, 수학 특화 LLM '레마' 출시...\"수학 넘어 LLM 발전에 도움될 것\"",
    "created_at": "2023.10.23 18:00",
    "content": "비영리단체인 엘루서 AI가 그간 대형언어모델(LLM)의 약점으로 지적된 수학 문제를 해결하기 위해 새로운 오픈 소스 모델을 공개했다. 오픈 소스 진영답게 '라마(Llama)'를 변형한 '레마(Llemma)'라는 이름을 붙였다. 벤처비트는 20일(현지시간) 엘루서 AI 연구원들이 레마 모델에 대한 논문을 온라인(arXiv)에 게재하고 관련 소스를 공개했다고 보도했다. 이에 따르면 레마는 성능면에서 구글의 '미네르바(Minerva)'를 비롯한 다른 주요 수학 중심 LLM을 능가하며, 추가 연구를 위한 강력한 플랫폼을 제공한다. 연구진은 레마가 완벽하게 모든 수학 문제를 해결할 수 있는 것은 아니지만, 이 분야에서 새로운 연구 방향성을 제시한다고 밝혔다. 연구진은 레마를 메타의 오픈 소스 코딩 전문 LLM인 '코드 라마'를 기반으로 구축했다. 매개변수에 따라 70억개(7B)와 340억개(34B) 모델 두가지로 개발했다. 이 모델의 핵심은 연구진이 직접 구축한 미세조정에 사용한 과학 논문과 수학 전문 웹 데이터, 수학 코드의 혼합으로 구성된 데이터셋(Proof-Pile-2)이다. 이를 통해 레마가 수학 벤치마크에서 다른 개방형 모델보다 우수한 성능을 보였다고 전했다. 더불어 같은 매개변수 기준으로 미네르바를 능가한다고 밝혔다. 연구진은 \"레마-7B는 '미네르바-8B'보다 뛰어나며, 레마-34B는 '미네르바-62B'와 거의 동등하다는 것을 의미한다\"라며 \"레마는 동일한 계산 비용에서 더 우수한 성능을 보이거나 일정한 수준의 기능에서 더 낮은 계산 비용을 제공할 수 있다\"라고 설명했다. 2022년 출시된 미네르바는 구글의 '팜(PaLM)'을 기반으로 한 모델로, 이제까지 등장한 수학 전문 LLM 중 가장 뛰어난 성능을 보이는 것으로 알려져 있다. LLM이 수학 문제 해결에 적합한지에 대해서는 사실 논란이 많다. 또 LLM의 수학 능력, 즉 양적 추론 능력을 측정하는 방법도 까다롭다. 예를 들어 벤치마크 테스트에 사용하는 예제의 '데이터 오염'으로 인해 모델이 높은 점수를 받는 경우가 많다. 즉 모델이 학습을 통해 이미 답을 기억하는 경우가 빈번하다는 의미다. 또 LLM이 약간 다른 방식으로 공식화되면 동일한 질문에 대해 다른 답변을 내놓는다는 연구 결과도 있다. 일부 과학자들은 LLM이 확률론적 특성 때문에 근본적으로 수학에 적합하지 않다고도 주장한다. 레마 연구진은 데이터 오염 여부를 확인하기 위해 꼼꼼한 확인 절차를 거쳤다고 밝혔다. 훈련 데이터와 테스트 데이터에서 비슷한 예를 일부 발견했지만 \"사소한 일치가 모델이 기억된 정답을 생성했다는 것을 의미하지는 않는다\"라고 결론내렸다. 수학 문제를 안정적으로 해결할 수 있는 모델의 개발은 보상 모델링, 추론을 위한 강화 학습, 알고리즘 추론 등 LLM의 능력을 전반적으로 향상하는 데 영향을 미칠 수 있다. 특히 특정 도메인에 대한 전문 모델 개발에 유용하다는 분석이다. 연구진은 \"수학 문제를 해결하려면 대규모의 전문화된 사전 지식에 대한 패턴 일치가 필요하므로 도메인 적응을 위한 이상적인 설정 역할을 한다\"라며 \"레마가 수학 문제 해결을 위한 궁극적인 도구가 되지는 않더라도 다른 유형의 모델과 AI 연구의 기초를 형성할 수 있다\"라고 강조했다. 임대준 기자 ydj@aitimes.com"
}