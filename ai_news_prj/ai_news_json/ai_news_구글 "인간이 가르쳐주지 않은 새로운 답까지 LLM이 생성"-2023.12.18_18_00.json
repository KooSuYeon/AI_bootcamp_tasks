{
    "title": "구글 \"인간이 가르쳐주지 않은 새로운 답까지 LLM이 생성\"",
    "created_at": "2023.12.18 18:00",
    "content": "구글 딥마인드가 대형언어모델(LLM)을 활용해 이전에 존재하지 않았던 지식을 내놓는 새 인공지능(AI) 도구를 선보였다. LLM이 내놓는 답 중 가치 있는 것을 가려내고 이를 통해 답을 고도화하는 과정에서, 인간이 미처 발견하지 못한 새로운 지식을 찾아낸 '획기적인 발견'이라는 주장이다. 구글 딥마인드는 14일(현지시간) 수학과 컴퓨터 과학 등에서 새로운 솔루션을 찾아내는 AI 도구 ‘펀서치(FunSearch)’의 연구 결과를 과학 저널 네이처에 게재했다고 블로그를 통해 소개했다. LLM이 학습하지 않은 완전히 새로운 지식을 생성한다는 것은 어려운 일이다. 만약 새 지식을 내놓았다고 해도, 잘못된 결과인 환각일 가능성이 크다. 알후세인 파우지 딥마인드 연구원은 “LLM이 내놓은 결과 중 90%는 유용하지 않을 것”이라며 “답이 나오면 이를 평가하기는 쉽지만, 새로운 답을 내놓기란 정말 어렵다\"라고 말했다. 구글 딥마인드가 공개한 펀서치는 ‘함수 공간에서의 검색(searching in the function space)’의 약자로, 컴퓨터 프로그램 형식으로 문제 해결책을 작성할 수 있는 AI 도구로 구축됐다. 펀서치는 필터를 사용해 LLM이 생성하는 수많은 응답 가운데 정확하다고 검증할 수 있는 응답만을 최종적으로 가려낸다. 이를 위해 사용자에게 최종 응답을 전달하기 전에 정확성을 확인하는 레이어를 LLM 위에 추가한다. 광범위한 주제를 논의하도록 훈련을 받은 기존 LLM의 경우, 이러한 종류의 별도 안전망을 구축하기가 어렵다. 핀서치는 구글의 LLM ‘팜 2(PaLM 2)’를 미세조정한 ‘코디(Codey)’라는 LLM을 구축하고, 그 위에 ‘평가자(Evaluator)’라 불리는 오답 및 환각을 거부하는 ‘평가자(Evaluator)’ 레이어를 결합했다. 코디 모델은 여전히 ​​환각에 취약하고 부정확하거나 오해의 소지가 있는 결과를 생성하지만, 평가자는 이를 필터링해 사용자가 신뢰할 수 있는 응답만 생성하도록 할 수 있다. 코디가 문제와 기본적인 소스 코드를 입력으로 받아 문제 해결을 위한 솔루션 코드를 생성하면, 평가자는 생성된 새로운 솔루션 코드의 내용을 확인하고 점수를 매긴다. 정확하지 않더라도 가장 좋은 점수의 코드는 데이터베이스에 저장되고 코디에 재입력해 솔루션 코드를 개선할 수 있다. 사용자가 데이터베이스에서 지금까지 생성된 최고의 솔루션 코드를 검색, 개선을 요청하는 메시지로 피드백해 솔루션 코드를 개선하는 식이다. 이 과정을 반복 적용함으로써 펀서치는 솔루션 코드를 새로운 지식을 제공하는 강력한 솔루션 코드로 꾸준히 발전시킬 수 있었다는 설명이다. 구글 딥마인드는 이를 입증하기 위해 수십년간 수학 난제로 여겨져 온 캡 세트(Cap set)에 펀서치를 적용했다.  캡 세트는 원 안에서 어떤 3개의 점도 직선으로 연결되지 않는 가장 큰 점 집합을 찾는 문제다. 점의 수가 늘어날수록 문제는 복잡해진다. 펀서치는 8차원에 걸쳐 512개의 점으로 구성된 솔루션을 만들 수 있었는데, 이는 인간 수학자들이 만든 것보다 더 큰 규모였다. 수학의 또 다른 난제인 ‘빈 패킹(bin-packing)’에도 펀서치를 적용했다. 빈 패킹은 다양한 크기의 개체를 작은 공간에 가장 효율적으로 배치하는 문제다. 펀서치는 이 특정 문제를 해결하기 위해 만들어진 현존 최고의 알고리즘보다 성능이 뛰어난 솔루션을 찾을 수 있었다. 푸시미트 콜리 딥마인드 과학 AI 책임자는 \"프로젝트를 시작했을 때만 해도 완전히 새로운 답을 생산할 것이라는 조짐은 없었다\"라며 “우리가 아는 한 LLM이 진정한 새로운 과학적 발견을 이룬 것은 이번이 처음”이라고 말했다. 테렌스 타오 캘리포니아대학교 교수는 “펀서치는 잠재적으로 다른 많은 수학 문제에 적용될 수 있기 때문에 매우 유망한 패러다임”이라고 전했다. 특히 다른 LLM과 달리 사용자가 출력 생성 과정을 실제로 보면서 학습할 수 있다는 점에서 주목할 만하다. 이는 펀서치가 ‘블랙박스’에 가까운 다른 LLM과 차별화되는 점이기도 하다. 박찬 기자 cpark@aitimes.com"
}