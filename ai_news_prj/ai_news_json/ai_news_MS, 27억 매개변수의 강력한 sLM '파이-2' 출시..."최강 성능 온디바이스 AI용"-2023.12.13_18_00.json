{
    "title": "MS, 27억 매개변수의 강력한 sLM '파이-2' 출시...\"최강 성능 온디바이스 AI용\"",
    "created_at": "2023.12.13 18:00",
    "content": "마이크로소프트(MS)가 27억개의 매개변수로 구성된 경량언어모델(sLLM) ‘파이-2(Phi-2)’를 공개했다. MS는 이 새로운 모델이 130억개 미만의 매개변수를 사용하는 언어 모델 중에서 최고 성능을 제공하며 최대 25배 더 큰 모델과 일치하거나 성능이 뛰어나다고 주장했다. MS는 12일(현지시간) 파이-2를 오픈 소스로 출시했다고 블로그를 통해 발표하며, ‘라마-2(Llama-2)’, ‘미스트랄 7B(Mistral 7B)’, 구글의 ‘제미나이 나노-2(Gemini Nano-2)’ 등 다른 모델과 추론, 언어 이해, 수학, 코딩 및 상식 능력을 비교하는 벤치마크에서 더 뛰어난 성능을 제공한다고 밝혔다. 지난 11월 ‘MS 이그나이트 2023’ 컨퍼런스에서 사티아 나델라 CEO가 처음 공개한 파이-2는 놀라울 정도로 강력한 성능을 제공한다. 트랜스포머(Transformer) 기반의 자체 모델에서 자연어 처리 및 코딩을 위한 합성 데이터와 웹 데이터를 혼합한 1조4000억 토큰 분량의 고품질 데이터셋을 학습한 결과다. 96개의 엔비디아 'A100' GPU에서 14일 동안 훈련한 것으로 알려졌다. 특히 파이-2는 27억개의 매개변수에도 불구하고 130억개 미만의 매개변수를 사용하는 파운데이션 모델보다 성능이 가장 뛰어나다고 강조했다. MS는 70억 매개변수의 ‘미스트랄 7B’ 및 ‘라마-2 7B’, 130억 매개변수의 ‘라마-2 13B’, 32억 매개변수의 ‘제미나이 나노-2’와 성능을 비교하는 벤치마크 결과를 공개했다. 파이-2는 언어 이해, 추론, 수학, 코딩 과제 등의 벤치마크에서 ‘미스트랄 7B’, ‘라마-2 7B’ ‘라마-2 13B’의 성능을 대부분 능가하는 것으로 나타났다. 지난주에 발표된 구글의 제미나이 중 가장 작고 효율적이라고 알려진 나노의 성능을 능가한 것으로 나타났다. 제미나이 나노는 '온디바이스 AI'용으로 제작, 스마트폰에서 텍스트 요약, 교정, 상황별 답변 등의 기능을 로컬로 실행할 수 있다. MS에 따르면 파이-2는 인간 피드백 기반 강화 학습(RLHF)이나 명령 미세 조정(Instructional fine-tuning)과 같은 기술을 사용하지 않고도 강력한 성능을 달성할 수 있었다. 세심하게 선별한 '교과서 수준의 데이터'로 훈련한 맞춤형 데이터 큐레이션의 결과로 다른 오픈 소스 모델에 비해 편향 및 독성 완화 측면에서 탁월한 성능을 보였다고 주장했다. 앞서 6월에는 13억개의 매개변수만으로 코드에 최적화된 트랜스포머 기반 언어 모델인 '파이-1'을 발표했다. 이 모델은 고품질 데이터로만 학습, 벤치마크에서 최대 10배 더 큰 모델보다 성능이 뛰어났다. 지난 11월에는 다양한 AI 생성 텍스트로 구성된 추가 데이터에 대해 훈련받은 13억 매개변수의 '파이-1.5'를 출시했다. 이 모델은 특히 이미지를 분석할 수 있는 멀티모달 기능도 제공한다. 상식, 언어 이해 및 추론에 대한 벤치마크 일부 영역에서 최대 100억개의 매개변수를 가진 모델을 따라잡았다는 결과도 공개했다. 이번에 출시한 파이-2는 기존 버전보다 크기가 2배로 늘었지만, 다른 모델에 비해서는 여전히 작은 편이다. 또 파이-1.5에 비해 논리적 추론과 안전성이 획기적으로 향상됐으며, 온디바이스 및 엣지 애플리케이션을 위한 강력한 도구라고 설명했다. 또 이날 MS는 X(트위터)를 통해 \"랩톱이나 모바일에서도 충분히 구동할 만큼 작다\"라고 밝혔다. 즉 온디바이스 AI용이라는 뜻이다. 다만 파이-2는 당분간 상업적 사용이 아닌 연구 목적으로만 사용할 수 있다. 박찬 기자 cpark@aitimes.com"
}