{
    "title": "\"특정 데이터 잊게하는 '언러닝' 사용하면 모델 자체가 멍청해져\"",
    "created_at": "2024.07.30 18:00",
    "content": "인공지능(AI) 모델에서 학습한 데이터 중 문제가 있는 일부분만 삭제하는 ‘언러닝’ 기술이 오히려 모델의 성능을 저하시킨다는 연구 결과가 나왔다. 테크크런치는 29일(현지시간) 워싱턴 대학(UW), 프린스턴 대학, 시카고 대학, USC, 구글 연구진이 생성 AI 모델이 훈련 데이터에서 수집한 특정 정보를 잊도록 하는 데 사용되는 ‘언러닝’ 기술이 기본적인 질문에 대답하는 모델의 성능을 저하시킨다는연구 결과를 아카이브에 게재했다고 전했다. 언러닝 기술은 생성 AI 모델이 훈련 데이터에서 수집한 민감한 개인 데이터나 저작권이 있는 자료와 같은 특정하고 바람직하지 않은 정보를 잊도록 하는 데 사용하는 망각 기술이다. 일반적으로 망각 기술은 모델을 잊어야 할 데이터에서 이탈하도록 설계된 알고리즘에 의존한다. 모델의 예측에 영향을 미쳐 특정 데이터를 절대 출력하지 않거나 매우 드물게 출력하도록 만드는 방식이다. 대표적인 것이 지닌해 12월 마이크로소프트(MS) 연구진이 공개한 방법이다. 당시 MS 연구진은 메타의 오픈 소스 LLM '라마 2 7B' 모델에 포함된 해리포터에 대한 모든 지식을 삭제하는 데 성공했다고 밝힌 바 있다. 하지만 이번 연구에서는 망각 알고리즘의 효과를 평가하기 위해 벤치마크 ‘뮤즈(MUSE)’를 설계, 8개의 오픈 소스 모델을 대상으로 테스트했다. 뮤즈는 알고리즘이 모델이 훈련 데이터를 그대로 뱉어내는 ‘역류’을 방지하는 능력과 모델이 특정 데이터나 관련 지식으로 훈련했다는 증거를 제거하는 능력을 측정한다. 예를 들어, 해리포터 책과 뉴스로 훈련한 모델이 뮤즈에서 좋은 점수를 받으려면 구체적인 지식, 즉 책 속에 등장하는 문장을 암기하는 것 등은 피해야 한다. 반면, 학습 제거 후에도 관련 일반 지식을 유지하고 있는지, 예를 들어 J.K. 롤링이 해리포터의 저자라는 사실을 여전히 알고 있어야 한다. 연구진은 이를 모델의 '유용성'이라고 불렀다. 유용성이 낮을수록 모델이 잃은 관련 지식이 많아져 모델이 질문에 올바르게 답할 수 있는 능력이 떨어진다는 해석이다. 테스트 결과, 망각 알고리즘이 모델이 특정 정보를 잊게 만들었지만, 모델의 일반적인 질문-응답 능력에도 부정적인 영향을 미쳤다는 것을 발견했다. 망각 기술 적용으로 인해 모델의 유용성이 낮아졌다는 설명이다. 연구진은 “모델내 지식이 복잡하게 연결돼 있기 때문에 효과적인 망각 알고리즘을 설계하는 것은 매우 어려운 일”이라고 설명했다. 예를 들어, 모델은 저작권 대상인 해리포터 서적과 자유롭게 사용할 수 있는 ‘해리포터 위키’ 두가지를 모두 학습한 경우, 망각 알고리즘이 책을 제거하면서 해리포터 위키에 대한 지식에도 큰 영향을 미칠 수 있다. 연구진은 \"모델이 상당한 유용성 손실 없이 특정 데이터를 잊을 수 있도록 하는 효율적인 방법은 현재 없다\"라고 단정했다. 결국 기존의 언러닝 기술을 사용할 경우, 대형언오모델(LLM)의 기본적인 질문에 대답하는 능력이 훨씬 떨어질 수 있다는 의미다. 박찬 기자 cpark@aitimes.com"
}