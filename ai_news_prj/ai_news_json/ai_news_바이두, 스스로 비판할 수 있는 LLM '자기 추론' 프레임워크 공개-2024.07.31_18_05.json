{
    "title": "바이두, 스스로 비판할 수 있는 LLM '자기 추론' 프레임워크 공개",
    "created_at": "2024.07.31 18:05",
    "content": "바이두가 검색 증강 생성(RAG) 방식의 대형언어모델(LLM)이 출력한 답을 스스로 검증할 수 있도록 하는 프레임워크를 공개했다. 이를 통해 환각 현상을 줄이겠다는 의도로, 학습 과정에 들어가는 리소스도 크게 줄였다고 강조했다. 주장대로라면 LLM의 큰 발전을 이끌만한 연구 결과다. 벤처비트는 30일(현지시간) 바이두 연구진이'자기 추론을 통한 검색 증가 언어모델의 향상(Improving Retrieval Augmented Language Model with Self-Reasoning)'이라는 논문을 온라인 아카이브에 게재했다고 소개했다. 이 연구는 AI의 주요 과제인 사실적 정확성 보장, 즉 환각 현상을 줄이는 것을 목표로 한다. 연구진은 \"우리는 LLM 자체에서 생성된 추론 경로를 활용하는 것이 핵심 아이디어인 검색 증강 언어모델의 신뢰성과 추적성을 개선하는 것을 목표로 한다\"라고 밝혔다. 이 프레임워크는 ▲관련성 인식 프로세스(relevance-aware process) ▲증거 인식 선택 프로세스(evidence-aware selective process) ▲경로 분석 프로세스(trajectory analysis process) 등 3단계로 추론 경로를 스스로 탐색하는 것이 핵심이다. 즉, LLM은 먼저 검색된 정보의 관련성을 주어진 쿼리와 평가한다. 그다음 인간 연구자가 하듯 관련 문서를 선택해 인용한다. 마지막으로 추론 경로를 분석해 최종적이고 근거가 확실한 답을 출력한다. 이는 정보를 생성할 뿐만 아니라, 이를 검증하고 맥락화할 수 있는 시스템이다. 자체 추론 메커니즘을 통합, 단순한 정보 검색 및 생성을 넘어 자체 출력을 비판적으로 평가할 수 있다. AI 모델을 단순한 예측 엔진에서 더 정교한 추론 시스템으로 전환할 수 있다는 평가다. 스스로 추론할 수 있는 능력은 정확도뿐만 아니라, 의사 결정 프로세스의 투명성을 확보하고 시스템 신뢰를 구축하는 데 중요한 단계라고 강조했다. 벤치마크에서 바이두 모델은 다른 최첨단 모델보다 뛰어난 성능을 보였다. 특히 'GPT-4'와 비슷한 성능을 달성했지만, 훈련에 사용한 샘플은 2000개에 불과했다고 전했다. 즉, 훨씬 적은 데이터로 뛰어난 성능을 발휘, 모델 개발에 들어가는 리소스를 크게 줄일 수 있다는 설명이다. 따라서 바이두는 이 프레임워크가 금융이나 의료 등 높은 정확도와 신뢰성이 필요한 산업에 적합하다고 주장했다. 또 기술 거대 기업과 경쟁할 리소스가 부족했던 소규모 회사와 연구 기관에도 큰 도움이 될 것으로 내다봤다. 벤처비트는 \"바이두의 획기적인 진전은 AI 기술의 급속한 발전 속도와 이 분야에서 오랜 과제를 해결하기 위한 혁신적인 접근 방식의 잠재력을 강조한다\"라고 평했다. 임대준 기자 ydj@aitimes.com"
}