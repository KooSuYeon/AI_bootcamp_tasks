{
    "title": "아르시, LLM 지식을 온디바이스 모델로 전달하는 '증류' 도구 출시",
    "created_at": "2024.08.12 18:05",
    "content": "대형언어모델(LLM)의 지식을 소형언어모델(sLM)로 이전해 주는 오픈 소스 도구가 등장했다. sLM의 성능을 더 끌어 올려, 이를 통해 다양한 온디바이스 인공지능(AI)용 모델 배포를 지원하다는 의도다. 마크테크포스트는 최근 AI 스타트업 아르시 AI(Arcee AI)가 sLM의 생성 및 배포를 지원하도록 설계한 '디스틸킷(DistillKit)'을 오프 소스로 출시했다고 보도했다. 이 도구는 모델 '증류(Distillation)' 기술을 기반으로 한 도구다. 증류란 큰 모델(teacher)에서 작은 모델(student)’을 훈련할 데이터셋을 구축하고 지식을 전달하는 과정을 말한다. 그 결과 성능이 강화된 모델은 적은 계산 리소스로 효율적인 구동이 가능해진다. 아르시는 노트북이나 스마트폰과 같은 덜 강력한 하드웨어에서 사용하도록 최적화되면서도 더 큰 모델의 성능과 정교함을 유지하는 것이 목표라고 밝혔다. 이를 위해 두가지 증류 방법을 도입했다. 첫번째는 '로짓 기반 증류(Logit-based Distillation)'으로, 교사 모델이 학생 모델에 출력 확률(로짓)을 제공하는 것이다. 학생 모델은 정답뿐만 아니라 교사 모델의 예측에 대한 신뢰 수준도 학습한다. 즉, 교사 모델의 출력 분포를 모방해 학생 모델의 일반화 및 효율적인 수행 능력을 향상한다. 두번째는 '숨겨진 상태 기반 증류(Hidden States-based Distillation)'라는 방식이다. 학생 모델은 교사 모델의 중간 표현(숨겨진 상태)을 복제하도록 훈련한다. 교사 모델과 내부 처리를 일치시킴으로써 학생 모델이 데이터에 대한 더 깊은 이해를 얻는다는 것이다. 이는 다른 토크나이저의 모델 간에 지식 전달을 허용하기 때문에 교차 아키텍처 증류에 유용하다는 설명이다. 성능 평가를 위해 교사 모델로는 '아르시-스파크(Arcee-Spark)'를 활용, 오픈소스 모델 '큐원2(Qwen2-1.5B-Base)'를 증류했다. 그 결과 증류된 모델(1.5B Distilled)는 BBH, MUSR 및 MMLU-PRO와 같은 주요 벤치마크에서 이전보다 성능이 향상됐다. 특히 일반 성능 향상은 물론, 특정 도메인별 성능 향상이 두드러졌다는 설명이다. 즉 교사 모델과 동일한 데이터셋을 사용해 증류하면 성능 향상이 더 크다는 뜻이다. 이 밖에도 개발자는 특정 요구 사항에 맞게 증류 프로세스를 조정할 수 있어 모델 아키텍처 선택에 유연성을 제공한다고 설명했다. 또 이를 통해 더 작고 효율적인 모델을 구축할 수 있어 AI 배포에 필요한 컴퓨팅 리소스와 에너지를 줄인다고 덧붙였다. 앞으로 기능을 추가하고 성능을 높여 디스틸킷을 지속 업그레이드하겠다고 밝혔다. 차기 업데이트에는 '지속적 사전훈련(CPT)'과 '직접 선호 최적화(DPO)와 같은 미세조정 기술을 통합할 예정이다. 아르시는 \"디스틸킷은 모델 증류의 중요한 이정표로, sLM을 만드는 데 강력하고 유연하며 효율적인 도구를 제공한다\"라며 \"오픈 소스로 기술을 공개, 끊임없이 변화하는 AI 기술의 요구 사항을 충족하기 위해 새로운 기술과 최적화를 통합할 수 있도록 보장한다\"라고 밝혔다. 특히 이는 최근 미국에서 주요 트렌드인 도메인별 맞춤형 sLM에 유용하다는 설명이다. 마크 매쿼이드 아르시 공동 창립자는 블룸버그와의 인터뷰에서 \"비즈니스 사용 사례의 99%는 1968년 올림픽 금메달을 딴 사람이 누구인지 알 필요가 없을 것\"이라며 \"작은 모델은 세무 관련 질문만 처리하는 서비스를 구축하는 것과 같이 많은 데이터가 필요하지 않은 일상적인 기업 업무에 도움이 된다\"라고 말했다. 자세한 내용 및 기술 문서는아르시 공식 블로그에서 확인할 수 있다. 임대준 기자 ydj@aitimes.com"
}