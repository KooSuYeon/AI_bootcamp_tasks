{
    "title": "삼성, 챗GPT 데이터 유출 후 임직원 AI 사용 금지",
    "created_at": "2023.05.03 12:46",
    "content": "블룸버그는 2일(현지시간) 삼성전자가 기업 비밀 유출을 방지하기 위해 챗GPT 등 생성 인공지능(AI) 사용을 금지했다고 보도했다. 이에 따르면 삼성전자는 지난달 28일 디바이스경험(DX) 부문 임직원을 대상으로 \"생성 AI에 입력된 내용은 외부 서버에 전송·저장된 뒤 AI 학습에 활용되므로 한번 업로드된 내용은 회수, 삭제가 불가능해 회사의 중요 정보가 타인의 질문에 대한 답변으로 활용될 수 있는 등 심각한 보안 위험이 있다\"고 경고했다. 삼성전자는 지난달 내부 AI 도구 사용에 대한 설문 조사를 실시, 응답자의 65%가 보안 위험을 초래한다는 의견을 얻었다. 특히 4월 초 일부 직원이 실수로 내부 소스 코드를 챗GPT에 업로드, 유출하는 사태가 발생한 것으로 알려졌다. 여기에 포함된 정보가 무엇인지는 밝혀지지 않았다. 삼성 관계자는 지난주 생성 AI 서비스 사용을 금지하는 메시지를 보냈다고 확인했다. 이를 통해 직원들에게 “챗GPT와 같은 생성 AI 플랫폼에 대한 관심이 대내외적으로 높아지고 있다”라며 \"이러한 관심은 이러한 플랫폼의 유용성과 효율성에 초점을 맞추고 있지만, 생성 AI가 제공하는 보안 위험에 대한 우려도 커지고 있다\"고 전했다. 새로운 규칙에 따라 회사 소유의 PC, 태블릿, 휴대폰 및 내부 네트워크에서 생성 AI 시스템의 사용을 금지한다. 안드로이드 스마트폰 및 윈도 노트북과 같이 소비자에게 판매하는 장치에는 영향을 미치지 않는다. 또 개인 기기에서 챗GPT 및 기타 도구를 사용하는 직원에 회사 관련 정보나 지적 재산을 노출할 수 있는 개인 데이터를 입력하지 말 것을 요청했다. 이 정책을 위반하면 해고될 수 있다고 경고했다. “보안 지침을 성실히 준수해 주시길 부탁드리며, 이를 준수하지 않을 경우 회사 정보가 유출되거나 손상돼 최대 해고를 포함한 징계 조치를 받을 수 있다”라는 내용이다. 더불어 삼성은 소프트웨어 개발뿐만 아니라 문서 번역 및 요약을 위한 자체 AI 도구를 자체적으로 만들고 있는 것으로 알려졌다. 또 민감한 회사 정보가 외부로 빠져나가는 것을 차단하는 방법도 연구 중이다. 메시지에는 “본사는 직원의 생산성과 효율성을 높이기 위해 생성 AI를 안전하게 사용할 수 있는 환경 조성을 위한 보안 조치를 검토하고 있다”고 밝혔다. \"다만 이러한 대책이 마련될 때까지 일시적으로 생성 AI 사용을 제한하고 있다”고 말했다. 임대준 기자 ydj@aitimes.com"
}