{
    "title": "AI 이미지 학습 방해하는 저작권 방어 도구 추가...\"데이터셋 포함 원천 방지\"",
    "created_at": "2024.01.24 18:00",
    "content": "인공지능(AI) 학습에 사용하는 데이터 저작권 문제가 이슈로 떠오른 가운데, 인터넷에서 이미지를 수집하는 자체를 방해하는 도구가 등장했다. 지난해 등장해 화제가 됐던 시카고대학교의 '나이트쉐이드'만큼 유용하다는 설명이다. 벤처비트와 테크크런치 등은 23일(현지시간) 킨아트(Kin.art)라는 스타트업이 이미지를 인터넷에 올릴 때마다 '자동방어' 기능을 추가하는 새로운 플랫폼을 공개했다고 보도했다. 이에 따르면 킨아트 기술은 ▲이미지 세그멘테이션(image segmentation)과 ▲라벨 퍼징(label fuzzing) 두가지로 구성된다. 우선 세그멘테이션은 이미지에서 픽셀 단위로 객체를 추출하는 방법이다. 킨아트의 경우는 인간의 눈에는 이상이 없어 보이지만, 기계의 눈에는 무질서하게 보이도록 픽셀을 어지럽게 섞어놓는다. 즉 기계가 특정한 이미지로 인식하지 못하게 만든다. 라벨 피징은 이미지에 포함된 제목이나 설명, 메타데이터 등 AI 학습을 위한 라벨을 뒤섞는 방법이다. 이에 따라 기계는 이미지 내용을 학습하는 것이 어려워지기 때문에 학습 대상에서 이미지를 아예 제외하게 된다는 설명이다. 특히 이 기술을 적용하는 데에는 1초도 걸리지 않는다고 전했다. 또 이 도구는 무료로,킨아트 웹사이트에서 계정을 만들고 이미지를 업로드하면 된다. 이때 AI 보호를 받을 지 선택할 수 있다. 론스먼 드 브리 킨아트 공동창립자는 \"이중 보호 방식을 통해 허락하지 않은 AI 학습으로부터 아티스트를 완벽하게 보호할 수 있다\"라며 \"다른 도구는 이미 학습용 데이터셋에 포함된 이미지의 피해를 줄이기 위해 노력하지만, 킨아트는 처음부터 데이터셋에 포함될 가능성을 없앤다\"라고 강조했다. 브리 창립자가 말한 '다른 도구'란 나이트쉐이드를 말한다. 지난해 10월 발표된 나이트쉐이드는 동의 없이 이미지 가져다 학습한 AI를 '붕괴'시키는 기술로 큰 주목을 받았다. 즉 아티스트가 픽셀에 보이지 않는 변형 데이터를 주입, 이 이미지를 사용한 데이터셋을 오염시킨다는 내용이다. 그 결과 이를 학습한 AI 모델은 전반적으로 정확도가 떨어지는 등 바이러스를 투입하는 것과 같은 원리다. 공교롭게도 시카고대학 연구팀은 이틀 전나이트쉐이드 1.0 버전을 오픈 소스로 정식 공개했다. 임대준 기자 ydj@aitimes.com"
}