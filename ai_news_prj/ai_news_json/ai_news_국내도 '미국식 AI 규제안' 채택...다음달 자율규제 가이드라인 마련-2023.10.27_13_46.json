{
    "title": "국내도 '미국식 AI 규제안' 채택...다음달 자율규제 가이드라인 마련",
    "created_at": "2023.10.27 13:46",
    "content": "국내도 미국식 인공지능(AI) 규제안을 채택한다. 정부 주도하에 업체들이 자율규제안을 내놓는 방식으로, 산업 보호에 무게를 둔 방식이다. 다음달 '자율규제 가이드라인'을 발표, AI 생성물에 워터마크를 포함하는 안 등을 포함할 예정이다. 과학기술정보통신부(장관 이종호)는 AI 분야 주요 기업 및 개인정보보호위원회(위원장 고학수) 등과 '제4차 AI 최고위 전략대화'를 개최, 자율규제에 대한 기본안을 마련했다. 이날 행사에는 이종호 과기정통부 장관과 고학수 정보보호위원회 위원장 등 정부 측과 학계 대표인 임용 서울대학교 교수를 비롯해 대형언어모델(LLM) 기업인 네이버·SKT·KT·카카오·LG AI 연구원과 전문 AI 기업인 이스트소프트, JLK, 셀렉트스타, 스냅태그, 코난 테크놀로지 등이 참가했다. 과기정통부는 그동안 간담회와 현장방문 등으로 모은 업계 의견을 바탕으로 ‘AI 윤리·신뢰성 확보 추진계획’을 수립, 발표했다. 이는 ▲민간 자율 AI 윤리·신뢰성 확보 지원 ▲세계를 선도하는 AI 윤리·신뢰성 기술·제도적 기반 마련 ▲사회 전반 책임 있는 AI 의식 확산 등 AI 윤리·신뢰성 모범국가를 위한 내용이다. 세부적으로 11월부터 생성 AI 기반 서비스 등 분야별 가이드라인을 마련·확대하고 민간 자율 신뢰성 검·인증을 추진할 계획이다. 특히 고위험 영역 AI 개발·실증 사업을 수행하는 기업을 일부 선정하여 12월에 시범 인증을 추진할 예정이다. '차세대 생성 AI 기술개발'에는 2024년부터 2027년까지 220억원을 투입할 계획이다. 이는 편향성, 불투명성 등 기술적 한계와 환각 등 위험요인에 대응하기 위해 기존 AI의 한계를 극복하고 신뢰성을 확보하기 위한 새로운 기술을 개발한다는 내용이다. 더불어 AI가 생성한 결과물에 대한 워터마크 도입의 제도화를 검토하고, 고위험 AI에 대한 해설서를 마련하는 등 신뢰성 확보를 위한 제도 정립 과제를 추진할 방침이다. 이런 방식은 지난 7월 미국 백악관에서 오픈AI와 마이크로소프트, 구글, 앤트로픽 등 주요 7개 AI 기업이 발표한 'AI 안전 서약'과 흡사한 방식이다. 당시 기업들은 ▲워터마크 포함 ▲외부 모니터링 팀 구성 ▲안전 정보 공유 ▲최첨단 모델에 대한 사회문제 해결 우선 투입 등 8개안을 발표했다. 이는 개인정보 보호와 규제 중심인 유럽연합(EU)의 'AI 법'과는 달리 자국 산업을 보호하고 자율적인 규제를 우선하는 접근법이다. 미국에서도 한때는 'AI 라이선스제' 도입 등 강력한 정부 주도의 규제안에 대한 요청이 등장했으나, 미국 정부는 결국 글로벌 주도권을 가진 자국 기업을 보호하기 위한 조치를 택했다. 국내도 비슷한 맥락이다. 특히 국내는 미국과 중국에 이어 LLM 보유 기업 수에서 세계 3위권을 달리고 있으며, 특히 주요 IT 기업이 AI를 주요 비전으로 추진하는 상황이기 때문이다. 해외에서도 최근에는 자국 산업을 의식, 실질적인 위협을 가져올 수 있는 첨단 AI 모델에 규제를 집중하고, 나머지 생산성 위주의 대부분 모델과는 차별을 두는 실정이다. 과기정통부의 발표에도 이에 해당하는 고위험 모델에 대한 부분이 포함돼 있다. 한편 이날 행사에서는 김유철 LG AI 연구원 부문장과 김동민 JLK 대표의 발표를 비롯해 간담회를 진행, 이번 발표 내용에 대한 컨센서스를 도출하는 과정을 거쳤다. 이종호 장관은 “AI는 디지털 심화 시대의 핵심기술로서 신뢰성과 안전성을 확보하기 위한 노력이 무엇보다 중요하다”라며 “민간 자율 AI 신뢰성 검·인증 지원을 비롯한 윤리 생태계 기반 조성과 적합한 규제 체계를 정립해가는 데 힘쓰고, 관계부처와 함께 윤리·신뢰성을 확보할 수 있는 정책방안을 보완하여 새로운 디지털 질서의 모범이 되기 위하여 최선을 다하겠다”라고 밝혔다. 임대준 기자 ydj@aitimes.com"
}