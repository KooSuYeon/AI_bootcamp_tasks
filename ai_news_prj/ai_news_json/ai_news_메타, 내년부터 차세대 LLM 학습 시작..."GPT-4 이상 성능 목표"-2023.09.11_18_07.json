{
    "title": "메타, 내년부터 차세대 LLM 학습 시작...\"GPT-4 이상 성능 목표\"",
    "created_at": "2023.09.11 18:07",
    "content": "메타가 오픈AI의 'GPT-4' 급의 대형언어모델(LLM)을 개발 중인 것으로 알려졌다. 생성 AI 시장에서 후발주자라는 약점을 극복하고 강력한 LLM 기술을 토대로 저변 확대를 꾀하려는 전략으로 풀이된다. 월스트리트저널(WSJ)은 10일(현지시간) 메타가 라마 2보다 몇 배 더 뛰어난 성능의 새로운 오픈 소스 LLM을 내년에 출시할 예정이라고 정통한 소식통을 인용해 보도했다. 이에 따르면 올 초에 구성한 메타의 전담팀이 이를 담당하고 있으며, 특히 내년 초부터 새 LLM의 학습을 시작할 예정이다. 메타는 지난 5월 공개한 데이터센터 구축 계획에 따라 자체 인프라에서 새로운 LLM을 훈련할 계획이다. 이를 위해 엔비디아로부터 'H100' GPU를 추가로 확보하는 것으로 알려졌다. 앞서 메타는 애저 클라우드에서 라마 2를 훈련하기 위해 마이크로소프트(MS)와도 제휴한 바 있다. 새로운 LLM은 이번에도 오픈 소스로 공개할 예정이다. 하지만 개발 중인 LLM이 목표로 하는 오픈AI의 'GPT-4'를 뛰어넘기는 쉽지 않을 것이라는 예측도 나오고 있다. 오픈AI가 밝힌 적은 없지만, GPT-4는 매개변수가 1조~1조5000억개로 추정된다. 반면 메타의 최신 모델인 라마 2는 매개변수가 700억개다. 메타가 매개변수 20배 차이를 단번에 뛰어넘을 기술을 선보일지는 미지수라는 설명이다. 또 메타가 새 LLM은 구글이 개발 중인 첨단 LLM ‘제미니(Gemini)’ 출시 이후에 공개할 가능성이 높다는 예측도 나왔다. 제미니는 세르게이 브린 구글 공동 창업자가 복귀해 개발 중인 모델로, 역시 GPT-4를 능가하는 성능을 목표로 하고 있다. 이르면 올말쯤 출시할 것으로 예측된다. 물론 메타의 모델은 오픈AI나 구글과는 달리 오픈 소스로 제공한다는 차별점이 있다. 오픈AI나 구글과 같은 폐쇄형 모델과 달리 다수 개발자의 손을 거치며 성능을 높이고 운영 비용을 낮출 수 있기 때문이다. 즉 시장 점유율 면에서는 경쟁력이 충분하다는 분석이다. 마크 저커버그 메타 CEO는 “오픈소스는 더 많은 개발자가 새로운 기술을 개발할 수 있게 해주기 때문에 혁신을 주도한다”면서 “더 많은 사람이 소프트웨어를 면밀히 검토해 잠재적인 문제를 식별하고 수정할 수 있기 때문에 안전과 보안이 향상된다”고 말했다. 박찬 기자 cpark@aitimes.com"
}