{
    "title": "MS, LLM보다 추론 능력 뛰어난 sLLM '오르카 2' 출시",
    "created_at": "2023.11.22 17:58",
    "content": "마이크로소프트(MS)가 경량 언어모델(sLLM) ‘오르카 2(Orca 2)’를 공개했다. 놀라운 것은 70억 및 130억개의 매개변수를 가진 경량 모델로, 더 큰 대형언어모델(LLM) 보다 뛰어난 추론 능력을 보인다는 점이다. 벤처비트는 21일(현지시간) MS가 매개변수가 5~10배 더 큰 LLM의 성능을 능가하는 sLLM ‘오르카 2’를 오픈 소스로 출시했다고 전했다. 이에 따르면 오르카 2는 130억 매개변수의 ‘오르카’ 모델을 기반으로 한 ▲70억 매개변수의 ‘오르카 2-7B’와 1▲30억 매개변수의 ‘오르카 2-13B’ 두가지로 출시됐다. MS는 \"오르카 2의 개선된 훈련 방법이 더 작은 언어 모델이 일반적으로 훨씬 더 큰 언어 모델의 추론 능력을 능가할 수 있다는 것을 입증한다\"라고 주장했다. 오르카 2는 ‘라마 2(Llama 2)’ 기반 모델을 고도로 맞춤화된 합성 데이터셋에서 미세조정했다. 데이터셋은 오르카 2에게 단계별, 회상 후 생성, 회상-이유-생성, 직접 답변 등 다양한 추론 기술을 가르치고, 동시에 각 작업에 대해 가장 효과적인 추론 기술을 결정하는 방법을 훈련했다. 오르카 2 모델은 언어 이해, 상식 추론, 다단계 추론, 수학 문제 해결, 독해, 요약 및 진실성 등 15개의 다양한 주제를 다루는 일련의 벤치마크에서 크기가 5~10배 더 큰 ‘라마 2’ 및 ‘위저드LM(WizardLM)’보다 뛰어난 성능을 보였다. 오르카 2 7B 및 13B는 모든 벤치마크 결과에서 평균적으로 '라마-2-챗-13B/70B' 및 '위저드LM-13B/70B'보다 우수한 것으로 나타났다. 8500개의 고품질 초등학교 수학 문제로 구성된 'GSM8K' 벤치마크에서만 위저드LM-70B가 오르카 2 및 라마 2 모델보다 더 나은 성능을 보였다. MS는 “오르카 2의 성능이 비슷한 크기의 모델을 훨씬 능가하고 최소 10배 이상 큰 모델과 유사하거나 더 나은 성능을 달성, 작은 모델도 나은 추론 능력을 제공할 수 있는 가능성을 보여준다”라며 “미세조정을 위해 신중하게 필터링한 합성 데이터를 사용한 것이 개선의 핵심”이라고 설명했다. MS는 오르카 모델을 만드는 데 사용된 기술이 다른 기반 모델에도 사용될 수 있다고 덧붙였다. 한편 최근 AI 전문가인 카이 푸 리가 설립한 중국의 스타트업 01.AI도 700억 매개변수의 라마 2와 1800억 매개변수의 ‘팰컨' LLM을 능가하는 60억 및 340억 매개변수의 sLLM ‘Yi’를 출시했다. 또 지난 9월에는 프랑스의 스타트업 미스트랄 AI가 팰컨과 라마 2를 능가하는 73억 매개변수의 sLLM ‘미스트랄-7B(Mistral-7B)’를 오픈 소스로 출시한 바 있다. 박찬 기자 cpark@aitimes.com"
}