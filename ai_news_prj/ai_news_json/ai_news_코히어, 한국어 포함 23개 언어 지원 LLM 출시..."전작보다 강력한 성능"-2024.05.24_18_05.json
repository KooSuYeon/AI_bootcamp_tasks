{
    "title": "코히어, 한국어 포함 23개 언어 지원 LLM 출시...\"전작보다 강력한 성능\"",
    "created_at": "2024.05.24 18:05",
    "content": "코히어가 한국어를 포함, 23개 언어를 지원하는 강력한 성능의 대형언어모델(LLM)을 오픈 소스로 내놓았다. 지난 2월 출시한 '아야 101(Aya 101)'을 고도화한 것으로, 여기에는 전 세계 인구 절반이 사용하는 언어가 포함된다. 벤처비트는 23일(현지시간) 캐나다 스타트업 코히어가 소속 비영리 연구 기관 C4AI를 통해 '아야 23(Aya 23)'을 출시했다고 보도했다. 매개변수 8B 및 35B 두가지로 개발했다. 여기에는 한국어를 비롯해 중국어, 일본어, 아랍어, 힌디어, 인도네시아, 베트남어 등 아시아권과 영어, 독일어, 프랑스어, 이탈리아어, 스페인어, 포르투갈어, 네덜란드어, 체코어, 페르시아어, 터키어, 러시아어, 우크라이나어 등이 포함됐다. 이전 모델 아야 101은 119개 국가에서 3000명 이상의 연구자가 지난해 1월부터 자발적으로 참여한 '아야 프로젝트'를 바탕으로 한다. 이들은 5억1300만개의 프롬프트로 구성된 데이터셋으로 101개 언어를 포괄하는 LLM을 개발했다. 이후 몇개월이 지나며 지식과 성능을 끌어 올리기 위해 내놓은 것이 이번 모델이다. 특히 너무 많은 언어를 다루다 보니, 특정 언어에서 성능이 떨어지는 단점을 보완했다. 즉 범위를 좁히고 대신, 해당 언어의 성능을 높였다는 설명이다. 벤치마크에서 이를 입증했다. 아야 23은 아야 101에 비해 ▲식별 작업 최대 14% ▲생성 작업 최대 20% ▲다국어 MMLU 최대 41.6% 등 향상됐다고 밝혔다. 특히 다국어 수학적 추론은 6.6배나 증가했다. 또 구글의 '젬마'나 미스트랄AI의 '믹스트랄'보다 일부 영역에서 성능이 뛰어나다고 밝혔다. 코히어는 전작처럼 아야 23도 허깅페이스를 통해8B 모델과35B 모델을 오픈 소스로 공개했다. 연구진은 \"아야 모델군의 가중치를 공개함으로써 연구원과 실무자가 다국어 모델과 응용 프로그램을 발전시킬 수 있기를 희망한다\"라고 밝혔다 임대준 기자 ydj@aitimes.com"
}