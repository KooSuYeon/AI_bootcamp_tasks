{
    "title": "사진보다 자연스러운 '음성 딥페이크'...SNS 타고 가짜뉴스 양산",
    "created_at": "2023.10.16 18:30",
    "content": "인공지능(AI)을 활용한 목소리 합성, 즉 '음성 딥페이크'가 국제적인 문제로 떠오르고 있다. 이미지 딥페이크보다 방법이 쉽고 결과도 어색하지 않아, 사람들을 속이기 쉽다는 점 때문이다. 워싱턴포스트는 15일(현지시간) 정치인과 유명인을 모방한 AI 음성 클론이 새로운 사회 문제로 떠오른다고 보도했다. 뉴욕타임스 역시 13일 'AI 오바마'와 가짜 뉴스캐스터 등이 탁톡을 휩쓸고 있다고 소개했다. 이에 따르면 최근 틱톡에서는 버락 오바마 전 미국 대통령이 전 셰프의 갑작스러운 죽음에 대한 음모론에 맞서 자신을 변호하는 목소리가 퍼지고 있다. 이는 실제가 아니라 AI로 합성한 목소리다. 또 성매매에 관련됐다는 방송인 오프라 윈프리의 목소리와 코로나바이러스 백신을 맞은 뒤 눈이 멀었다는 배우 제이미 폭스의 이야기도 급속도로 퍼져 나갔다. 지난주에는 배우 톰 행크스의 목소리가 치과 광고에 등장, 이를 자신의 목소리가 아니라고 부인하는 공식 발표까지 나왔다. 이는 미국뿐이 아니다. 지난달 슬로바키아에서는 진보당 대표가 투표 조작을 위해 뇌물을 주라고 지시하는 가짜 음성 파일이 돌아다녀 많은 사람들을 분노하게 했으며, 영국에서는 노동당 지도자가 X(트위터)를 통해 직원에게 욕설을 퍼붓는 음성이 퍼져 나갔다. 심지어 아프리카에 위치한 수단에서도 전 국가 수반 아미르 알 바시르의 가짜 음성 녹음이 SNS로 퍼져 나가며 스캔들을 일으켰다. 이 모두가 음성 딥페이크로 밝혀졌다. 가짜뉴스 모니터링 전문 뉴스가드는 지난 9월 틱톡에서 AI 음성복제로 허위 정보를 전달하는 계정을 17개 확인했다고 발표했다. 이를 통해 퍼지나간 파일의 조회수는 무려 3억3600만회, '좋아요'는 1450만회에 달했다. 이런 현상이 빈번한것은 이미지 복제에 비해 음성 복제가 쉽고 자연스럽다는 점 때문이다. 이 분야의 선두인 일레븐랩스의 서비스를 통하면 월 5달러로 일반인이라도 유명인의 음성을 업로드하고 몇초 만에 합성 음성을 얻을 수 있다. 반면 이미지 생성 AI는 손가락 갯수가 비정상이거나 이미지가 뭉개지는 등 이상한 점을 찾아낼 수 있다. 최근에는 외국어 음성 데이터셋이 늘어나며, 외국어 복제 능력도 많이 향상된 것으로 알려졌다. 잭 브루스터 뉴스가드 연구원도 “오바마 대통령의 딥페이크 경우 얼굴은 플라스틱처럼 어색하지만, 목소리는 꽤 그럴듯하다\"라고 밝혔다. 이 때문에 SNS 회사는 음성 복제를 가려내는 데 어려움을 겪고 있으며, 음성 파일이 가짜라는 것을 입증하지 못하는 경우 무단으로 콘텐츠를 삭제할 수 없기 때문에 일부 파일들은 아직도 SNS에서 퍼져 나가는 중이다. 또 음성 복제 소프트웨어 회사 중 불법 사용을 금지하기 위해 가드레일을 갖춘 곳은 거의 없다는 지적도 나왔다. 전문가들은 AI 음성 복제가 향후 선거 등에서 단기간에 결정적인 영향을 미칠 수 있다고 입을 모으고 있다. 딥페이크 전문가인 해니 패리드 UC 버클리 전기공학 및 컴퓨터 과학과 교수는 “가짜 음성 파일이 미국은 물론 전 세계적으로 퍼져 나가고 있다\"라며 \"그리고 정치 상황이 불안정하거나 전쟁 중인 국가에서는 사실 확인이 훨씬 더 어려울 수밖에 없다\"라고 말했다. 또 \"사실 허위 정보를 퍼드리는 SNS 채널은 많은 팔로워를 보유한 소수에 불과하지만, SNS 회사로서는 이를 제거하는 것이 사업에 도움이 되지 않을 것\"이라며 \"결국 이 문제는 SNS 기업에 궁극적인 책임이 있다\"라고 주장했다. 한편 미국 상원 의원 그룹은 지난주 AI가 생성한 이미지나 음성을 동의 없이 제작하거나 배포하는 것을 처벌하는 '가짜 금지법(No Fakes Act)' 초안을 내놓았다. 임대준 기자 ydj@aitimes.com"
}