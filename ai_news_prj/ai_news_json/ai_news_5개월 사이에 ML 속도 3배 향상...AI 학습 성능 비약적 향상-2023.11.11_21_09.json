{
    "title": "5개월 사이에 ML 속도 3배 향상...AI 학습 성능 비약적 향상",
    "created_at": "2023.11.11 21:09",
    "content": "지난 5개월 사이에 머신러닝(ML) 속도가 무려 3배나 빨라진 것으로 나타났다. 이는 '무어의 법칙'을 뛰어넘는 속도로, 인공지능(AI) 칩 업체들이 치열하게 기술 개발에 매달리고 있다는 것을 입증함과 동시에 AI 발전이 가속화되리라는 예상을 가능케 한다. 벤처비트는 9일(현지시간) ML커먼스의 'ML퍼프(MLPerf) 학습 3.1' 결과를 소개하며 대형언어모델(LLM)의 학습 속도가 5개월 전보다 최대 3배 빨라졌다고 소개했다. 이에 따르면 ML커먼스는 엔지니어링 컨소시엄으로, ML퍼프는 AI 모델의 학습과 추론 속도 등을 측정하는 벤치마크다. 데이터센터를 구성하는 하드웨어 인프라의 성능을 측정하는 데스트를 실시한다. LLM의 '학습 속도'를 측정하는 테스트는 지난 6월 신설됐다. 이번에는 19개 업체를 대상으로 ▲기존에 실시했던 'GPT-3' 테스트와 ▲추가한 '스테이블 디퓨전' 테스트를 실시했다. 데이비드 캔터 ML커먼스 전무는 \"이번 벤치마크로 200개 이상의 성능 결과를 얻었으며, 상당한 성능 향상을 확인했다\"라며 \"LLM 학습 속도가 50%에서 최대 3배까지 빨라졌다\"라고 말했다. 최근 5년을 따지면 49배의 성능 향상이다. 그는 \"6월의 1차 테스트에서 가장 빠른 속도를 기록한 결과에 비해 이번의 최고치는 약 2.8배에 달한다\"라며 \"다음과 그다음 테스트에도 추세가 이어질지는 모르겠지만, 이번 결과는 예상을 뛰어넘는 엄청난 성능 향상을 의미한다\"라고 설명했다. 여기에서 '예상'이라고 밝힌 점은 바로 무어의 법칙을 의미한다. 이는 지난 3월 사망한 인텔 창립자인 고든 무어가 1965년 발표한 '2년마다 반도체 회로 집적도가 2배씩 증가한다'는 법칙으로, 즉 2년마다 컴퓨팅 성능이 2배씩 늘어난다는 논리다. 2010년대로 접어들며 컴퓨팅 성능이 비약적으로 발전하며 이 법칙은 사실상 의미를 잃었으나, 이번 결과는 그보다도 더 빠른 5개월 만에 3배 발전을 이뤄냈다는 것을 보여 준다. 인텔이 '하바나 가우디 2'로 속도를 103% 향상한 것을 비롯해 구글과 엔비디아 등 AI 칩을 개발 중인 업체들은 모두 좋은 성적을 얻었다. 구글은 멀티슬라이스 확장 기술을 통해 8월29일 출시한 '클라우드 TPU v5e' 4096개로 최대 1024개 노드까지 확장, 우수한 성능을 얻을 수 있었다고 밝혔다. 이를 통해 데이터 센터의 확장 능력을 입증했다고 밝혔다. 최고의 성능 향상을 보인 것은 역시 엔비디아였다. 지난 2월 세계에서 가장 빠른 슈퍼컴퓨터라고 공개한 'EOS'를 테스트에 투입한 엔비디아는 GPT-3 학습 결과가 6월보다 2.8배 더 빨라졌다. 엔비디아는 EOSdp 초당 400기가비트(Gb)로 실행되는 '퀀텀-2 인피니밴드(InfiniBand)'를 통해 1만752개의 GPU와 연결했으며, 860테라바이트(TB)의 'HBM3' 메모리를 추가하고 소프트웨어 개선에도 노력했다고 강조했다. 데이브 살바토르 엔비디아 가속 컴퓨팅 이사는 \"일부 속도와 피드 수치는 정말 놀랍다\"라며 “AI 컴퓨팅 측면에서 보면 속도가 40엑사플롭스(EF)를 넘는다\"라고 말했다. 엔비디아는 2월 EOS 출시 당시 18.4EF의 AI 컴퓨팅 성능을 제공, 세계에서 가장 빠른 속도를 낼 것으로 예상한다고 밝힌 바 있다. 박찬 기자 cpark@aitimes.com"
}