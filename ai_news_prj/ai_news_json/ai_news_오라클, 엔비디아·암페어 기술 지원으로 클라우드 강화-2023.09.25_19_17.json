{
    "title": "오라클, 엔비디아·암페어 기술 지원으로 클라우드 강화",
    "created_at": "2023.09.25 19:17",
    "content": "오라클이 클라우드 인프라(OCI)에 추가할 엔비디아와 암페어의 최신 기술을 탑재했다. 생성 인공지능(AI)을 위한 컴퓨팅 인프라를 대폭 개선, 클라우드 시장 확장을 위해 모든 수단을 다 동원하겠다는 전략이다. 오라클은 20일(현지시간) 미국 라스베이거스에서 개최한 '오라클 클라우드월드 2023' 컨퍼런스를 통해 AI 인프라와 범용 컴퓨팅의 신규 인스턴스 출시 계획을 발표했다. 신규 인스턴스는 생성 AI 모델 학습과 추론을 위한 전용 클라우드 인프라 옵션으로, 엔비디아 GPU와 암페어컴퓨팅의 최신 ARM 아키텍처 CPU를 AI 인프라로 선택했다. 이를 통해 다양한 AI 워크로드를 간단하게  실행할 수 있게 됐고, 성능 향상과 비용 절감의 이점을 누릴 수 있다는 설명이다. 먼저 엔비디아 H100 텐서코어 GPU로 구동하는 인스턴스는 대형언어모델(LLM)과 추천 시스템용 모델의 학습 시간을 단축한다. 오라클은 이전 세대인 엔비디아 'A100' 텐서코어 GPU에 비해 AI 추론 성능을 최대 30배, AI 모델 학습 성능을 4배 향상할 수 있다고 전했다. AI 모델 학습과 컴퓨팅 워크로드를 실행하는 경우 오라클의 고성능 저지연 클러스터 네트워크를 통해 수만개의 엔비디아 H100 GPU를 상호 연결할 수 있다. 이 인스턴스는 올해 말 런던과 시카고 지역부터 정식 배포하며, 이후 다른 지역도 지원할 예정이다. 이와 함께 엔비디아 L40S GPU로 구동되는 인스턴스도 출시한다. 이는 AI 추론 또는 중소형 AI 모델 학습에 적합하다. 이전 세대 엔비디아 A100 GPU 대비 생성 AI 워크로드의 경우 최대 20%, AI 모델 미세 조정의 경우 최대 70%의 성능 향상을 기록했다. 정식 출시는 2024년이다. 오라클은 ARM 아키텍처 기반의 멀티코어 CPU인 암페어 컴퓨팅의 '암페어원' CPU 인스턴스도 확대한다고 밝혔다. 암페어원 CPU로 구동하는 인스턴스는 베어메탈 형태에서 320개 코어, 가상머신(VM) 형태에서 최대 156코어를 제공한다. 서버, 비디오 트랜스코딩, CPU 기반 AI 추론 요청 서비스를 이용할 수 있다. 높은 코어 수를 기반으로 향상된 성능과 VM 밀도, 확장성을 제공, 기업이 컴퓨팅 워크로드를 효율적으로 관리하고 데이터센터 설치 공간 및 전력 소비를 줄일 수 있도록 지원한다. 동일 전력 소비 환경에서 인텔이나 AMD의 x86 프로세서보다 더 높은 성능을 낸다고 암페어 측은 강조했다. 유연한 VM용 구성을 통해 프로세싱 파워 및 메모리를 미세 조정함으로써, 리소스 활용을 극대화하고 비용을 최소화했다고 전했다. 정식 출시는 역시 2024년이다. 한편 로이터는 22일 오라클이 암페어 컴퓨팅이 만든 ‘암페어원’ CPU를 1억410만달러(약 1900억원)에 구매하기로 합의했다고 보도했다. 이에 따르면 오라클은 2023년 암페어에 4억달러(약 5300억원)를 투자했으며, 2017년 이후 8억5000만달러(약 1조1300억원)의 자금을 쏟아부은 것으로 알려졌다. 암페어는 ARM 기술을 기반으로하는 맞춤형 서버칩을 구축, x86 기반의 인텔 및 AMD가 주도하는 데이터센터 CPU 시장을 공략해 왔다. 로이터는 \"이번 조치는 오라클이 암페어에 대한 투자와 칩 구매를 통해 아마존, 구글 등과 경쟁하는 클라우드 시장에서 경쟁 우위를 확보하려 한다\"고 평했다. 아마존은 암페어와 경쟁하는 자체 서버 칩을 만들고, 구글은 자체 AI 칩을 만든다. 박찬 기자 cpark@aitimes.com"
}