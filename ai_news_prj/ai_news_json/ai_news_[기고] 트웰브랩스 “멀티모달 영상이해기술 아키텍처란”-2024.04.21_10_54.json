{
    "title": "[기고] 트웰브랩스 “멀티모달 영상이해기술 아키텍처란”",
    "created_at": "2024.04.21 10:54",
    "content": "최근인공지능(AI)물결이전 세계를덮치며사람들은그어느 때보다AI와긴밀히연결된삶을살고있다.특히요즘은AI의기반이되는대형언어모델(LLM), 즉파운데이션모델이떠오르고있다. LLM은엄청난양의데이터로자기지도학습(self-supervision)을수행하는머신러닝모델이다.데이터에있는전반적인패턴을학습,다양한패턴과관계성을활용해각종태스크에활용할수있다. 즉여러작업을수행하는LLM의등장으로각태스크를위한모델을따로구축할필요가없어진것이다.결과적으로시간과자원을절약하는것은물론,자연어처리와컴퓨터비전및멀티모달AI분야에서많은발전을이룰수있었다. LLM의기반이되는아키텍처'트랜스포머',그중에서'비전트랜스포머'를소개하며멀티모달영상이해 기술을소개하고자한다. 이는트웰브랩스가보유한핵심기술이기도하다. 트웰브랩스는영상기반멀티모달모델을개발하는국내AI스타트업이다.많은양의데이터를학습해영상의시각정보를이해하는기술을보유했다.이 외에도영상속음성언어,소리,등장인물,문자등다양한정보를총괄적으로이해,영상에서필요한정보를검색할수있는멀티모달기술을개발했다. 수만개의영상속에서‘파도위를달리는남자'나 ‘스티브 잡스가어떻게아이폰을소개했는가'와같은장면을간단히검색해원하는순간을찾을수있다. 영상언어생성모델인‘페가수스-1’은자체개발한800억매개변수규모의언어모델을바탕으로,영상요약과영상기반질의응답등비디오-텍스트(video to text)소통을가능하게한다.트랜스포머아키텍처를사용해특정상황에대한영상별언어모델구축과정을생략,기간을단축했다. 트웰브랩스는영상을이해하는하나의LLM을토대로,관련모든작업의자동화를추구하고있다.향후다양한영역에서영상분석AI의쓰임새가늘어날것으로예상한다. 비전트랜스포머(Vision Transformers) 원래컴퓨터 비전분야에서가장많이사용하는아키텍처는컨볼루션신경망(CNN)이었다.하지만자연어처리(NLP)에서트랜스포머아키텍처가성공을거두자,연구자들은트랜스포머를이미지데이터에도적용하기시작했다.그렇게비전트랜스포머가등장하게됐다. 특히트랜스포머아키텍처의인코더블록을이미지분류문제에적용하는비전트랜스포머(ViT)아키텍처는논문(An Image is Worth 16 x 16 Words: Transformers For Image Recognition at Scale)에서찾아볼수있다. 논문의저자는이미지를패치로나누고(split into patches),이런패치들을펼쳐선형으로만든후,해당임베딩(linear embeddings)을트랜스포머에입력(input)한다고기재했다.이런이미지패치는자연어처리의토큰처럼입력으로다뤄진다는설명이다. ViT아키텍처는이미지를패치화하는단계,멀티-레이어트랜스포머인코더단계,그리고글로벌표현(Representation)을출력라벨(output label)로변환하는멀티-레이어퍼셉트론(MLP)단계를포함한다. ViT는사전학습비용이비교적저렴하고,여러이미지분류데이터셋에서최첨단결과를달성하거나뛰어넘기도한다. ViT의특징및한계점 하지만몇가지문제점도있다.그중하나는고해상도이미지처리에어려움을겪는다는것이다.이미지가커지면엄청나게많은컴퓨팅파워를필요로하기때문이다. ViT의토큰수는고정돼있기때문에,다양한크기의시각적요소를포함하는태스크에는사용하기가애매해진다. ViT의한계적인특징으로는CNN과비교했을때유도편향(inductive bias)이적다는점을꼽을수있다.유도편향은머신러닝문제를더잘풀기위해모델에사전적으로추가하는가정들을일컫는다.예를들어비전,즉시각적인정보를다룰때픽셀 간의집약성(locality)이존재한다고가정하면공간정보를잘뽑아낼수있게된다. 무조건패치를활용해표현에한계가있는CNN과는달리,ViT는모델의자유도가높다는의미다.하지만그만큼제너럴리스트에가까운모델이되기때문에, 더 많은데이터를필요로한다. 트웰브랩스의차별점은대용량데이터를학습,트랜스포머기반에서도성공적으로이미지와영상을이해하도록만들었다는것이다.즉‘비전트랜스포머’의성공적예시다. 트웰브랩스 개발 부서"
}