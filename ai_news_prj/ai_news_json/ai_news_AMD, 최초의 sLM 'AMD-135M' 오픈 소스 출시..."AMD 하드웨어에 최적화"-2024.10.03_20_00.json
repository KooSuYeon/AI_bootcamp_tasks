{
    "title": "AMD, 최초의 sLM 'AMD-135M' 오픈 소스 출시...\"AMD 하드웨어에 최적화\"",
    "created_at": "2024.10.03 20:00",
    "content": "AMD가 처음으로 자체 소형언어모델(sLM)을 출시했다. 엔비디아의 인공지능(AI) 칩 독주를 막기 위해 자사의 칩에 최적화된 온디바이스 모델을 직접 제작한 것이다. AMD는 최근 홈페이지를 통해 'AMD-135M'라는 sLM을 출시했다. 이는 AMD 플랫폼에서 무료로 다운받아 사용할 수 있는 오픈 소스 모델이다. 이는 AMD의 'MI250' 가속기에서 처음부터 학습한 모델로, 메타의 '라마 2'를 미세조정해 개발했다. 학습 코드, 데이터 세트 및 가중치를 오픈 소스로 공개, 개발자가 모델을 재생성하고 다른 sLM이나 LLM을 학습하는 데 도움을 줄 수 있다는 설명이다. 매개변수 0.135B의 온디바이스 모델로, 언어모델(AMD-Llama-135M)과 코딩모델(AMD-Llama-135M-code) 두가지로 출시됐다. 또 670B 토큰의 '슬림파자마' 및 '프로젝트 구텐베르크' 데이터셋으로 언어모델을 훈련했으며, 이후 20B 토큰의 '스타코더' 데이터로 코딩 모델을 추가 훈련했다고 밝혔다. 벤치마크에서는 비슷한 크기의 오픈 소스 모델인 '라마-68M'과 '라마-160M' ​​모델을 능가했다고 밝혔다. 또 'GPT2-124M'이나 'OPT-125M'과 동등한 결과를 냈다. 여기에 '추측 디코딩(Speculative Decoding)'이라는 방식으로 추론 시 모델이 단일 토큰만 생성하는 한계를 해결, 여러 토큰을 생성하는 방식으로 속도를 놓였다고 설명했다. 이 모델은 AMD의 AI 칩에서 고성능을 발휘한다고 덧붙였다. AMD-Llama-135M-code는 MI250 가속기에서 약 2.8 배, '라이젠 AI CPU 1'에서 약 3.88배, '라이젠 AI NPU 2'에서 약 2.98배 속도가 빨라진다고 주장했다. 이처럼 AMD GPU나 라이젠 프로세서에서 학습과 추론을 모두 포함하는 엔드투엔드 워크플로를 구축한다는 설명이다. 즉, 데이터 센터와 엣지 디바이스에서 모두 사용할 수 있다고 전했다.허깅페이스를 통해 다운로드할 수 있다. 이에 앞서 AMD는 지난 7월 ‘어뮤즈 2.0(Amuse 2.0)’ 베타라는 이미지 생성 모델도 출시한 바 있다. 이 역시 AMD 하드웨어 기반 PC에서 온디바이스 AI로 활용할 수 있는 모델이다. 이처럼 AMD는 하드웨어뿐만 아니라, 이를 활용할 수 있는 맞춤형 모델을 잇달아 선보이고 있다. 또 핀란드의 간판 AI 스타트업 사일로 AI를 포함, 유망 소프트웨어 기업을 잇달아 인수하고 있다. 결국 엔비디아처럼 하드웨어와 관련 소프트웨어를 동시에 개발, 관련 생태계를 확장하고 AI 칩 효용성을 끌어올리려는 의도다. 한편, 엔비디아는 지난 1일 매개변수 720억개의 대형멀티모달모델(LMM)을 출시, 오픈AI의 'GPT-4o' 등과 프론티어 모델 경쟁을 선언했다. 임대준 기자 ydj@aitimes.com"
}