{
    "title": "오픈AI, 국제 AI규제기구 설립 제안",
    "created_at": "2023.05.23 19:00",
    "content": "오픈AI가 인공지능(AI) 규제를 위해 국제기구 설립을 제안했다. AI의 혁신 속도가 너무 빨라 한 국가나 기관이 통제하기 어려우니 국제원자력기구(IAEA)와 같은 국제 규제기관을 만들어야 한다는 것이다. 22일(현지시간) 테크크런치 보도에 따르면 오픈AI는 블로그에 \"AI시스템이 10년 이내에 대부분의 영역에서 전문가 수준을 능가, 기술대기업에 필적할 생산 활동을 수행하게 될 것\"이라며 \"이처럼 인간의 지능을 초월하는 '초지능(superintelligence) '이 초래할 수 있는 위험을 관리해야 한다\"고 주장했다. 이를 위한 방안으로는 3가지 아이디어를 제시했다. 오픈AI는 우선 초지능 개발이 안전하게 이뤄지도록 AI 역량의 성장률 개념을 도입해 연간 일정 비율로 제한하면서 개발 속도를 조정하자고 제안했다. 또 IAEA와 같은 국제기구를 설립해 초지능 개발을 관리하는 방안도 내놓았다. 기능의 임계값을 정해 이를 넘어서는 AI를 개발하면 △시스템 검사 △감사 요구 △안전 표준 준수여부 확인 △보안 수준과 배포에 대한 제한 등 제재를 가하자는 내용이다. 세번째로는 인간의 가치를 따르도록 초지능을 ‘정렬(alignment)’하는 기술을 갖추자고 제안했다. 사람의 피드백과 평가를 지원하고, 정렬 연구를 수행하기 위한 AI 시스템 교육을 하자는 것으로 오픈AI가 지난해부터 언급해 온 얘기다. 오픈AI는 이런 내용의 블로그 글을 샘 알트만 CEO와 그렉 브록만 회장, 일리아 슈츠케버 수석 과학자가 공동 명의로 게시했다. 이들은 게시글에서 \"AI 시스템의 범위와 기본값은 전 세계 사람들이 민주적으로 결정해야 한다. 개별 사용자가 제어권을 가져야 한다\"면서 \"초지능을 통제하는 것은 위험하고 어렵기 때문에 글로벌 감시 체제가 필요하다\"고 강조했다. 한편 샘 알트만은 지난 16일 미 상원 청문회에서도 AI의 위험성을 경고하면서 규제를 위한 라이선스제도 도입과 독립적인 감독 기구의 설립이 필요하다고 주장한 바 있다. 정병일 기자 jbi@aitimes.com"
}