{
    "title": "구글, LLM이 스스로 성능 향상하는 '자기 발견' 프롬프트 방식 공개",
    "created_at": "2024.02.13 18:00",
    "content": "대형언어모델(LLM)이 스스로 성능을 향상한다는 '자기 발견(self-discover)' 프롬프트 프레임워크가 등장했다. 구글 딥마인드는 이를 통해 'GPT-4'의 성능을 최대 32% 끌어올렸다고 주장했다. 벤처비트는 최근 구글 딥마인드와 서던캘리포니아대학교(USC) 연구진이아카이브와허깅페이스를 통해 기존 프롬프트 엔지니어링을 능가하는 새 프레임워크를 제안했다고 보도했다. 이에 따르면 이번 연구는 특정 작업에 적합한 추론 기술을 선택하는 동시에 효율적인 추론을 위해 고유한 기본 구조를 자체 발견하는 방식이다. LLM에는 인간이 어떻게 추론하고 문제를 해결하는지에 대한 인지 이론에서 영감을 받은 다양한 프롬프트 기술을 사용한다. 여기에는 ▲문제를 단계별로 해결하는 '생각의 사슬(CoT)' ▲문제를 여러 하위 문제로 나누는 '분해(decomposition prompting)' ▲문제에 대해 피드백을 구하는 '스탭백(step-back prompting)' 등이 포함된다. 또 CoT의 단점을 보완하기 위한 '계획 및 해결(PS, plan-and-solve)'이라는 프롬프트 기술도 등장했다. 특히 CoT는 LLM 정확도를 향상하는 주요 방식으로 수년간 활용됐다. 하지만 연구진은 \"각 작업이 고유한 구조를 갖고 있고 이에 따라 특정 기술이 다른 기술보다 문제를 해결하는 데 더 나을 수 있기 때문에, 일괄적으로 CoT를 적용하는 식이 최선이 아닐 수 있다\"라고 주장했다. 따라서 작업에 적합한 추론 기술을 LLM이 자체 발견하고 선택하는 프롬프트 프레임워크를 제안했다고 밝혔다. “인간이 문제 해결을 위한 추론 프로그램을 내부적으로 고안하는 방식에서 영감을 받았다\"라는 설명이다. 작업은 2단계로 진행된다. ▲우선 LLM과 작업 내용, 원자 추론 모델(Atomic Reasoning Module) 등을 통해 작업에 최적화된 프롬프트 기술을 스스로 찾아낸 뒤 ▲LLM 작업별로 선택한 모듈을 각각 적용하고, 작업을 최종 해결한다. 즉 1단계에서는 LLM이 각 작업에 대한 추론 구조를 생성한다. 2단계에서 LLM은 자체 발견한 구조에 맞춰 추론, 최종 답변에 도달한다. 자기 발견 프레임워크의 성능을 확인하기 위해 연구원들은 GPT-4 및 '팜 2(PaLM 2-L)' 등 여러 모델을 활용, 빅-벤치 하드(Big-Bench Hard, 현재 LLM 기능을 넘어서는 작업 평가), 행동 사고(Thinking for Doing), 수학 등 25가지 추론 작업에 대한 벤치마크를 실시했다. 그 결과 25개 작업 중 21개 작업에서 자기 발견은 CoT나 다른 기술보다 성능이 최대 32% 향상되는 것을 발견했다. 또 추론을 위한 컴퓨팅이 기존보다 10~40배 더 적게 필요하다고 전했다. 구체적으로 GPT-4를 대상으로 빅-벤치 하드에서는 81%, 행동 사고 85%, 수학 추론 73%의 정확도를 보였다. 반면 CoT는 각각 75%, 52%, 71%로 떨어졌다. 계획 및 및 해결 프롬프트와의 비교도 비슷한 양상이었다. 팜 2에서는 67%, 69%, 50.5%의 정확도를 기록했다. 이는 GPT-4보다 낮지만, CoT(60%, 40%, 42%) 및 계획 및 해결(61%, 42%, 49%) 방식보다 훨씬 뛰어나다. 벤처비트는 \"LLM이 스스로 추론 방식을 찾아낸다는 아이디어는 이제 막 제안됐지만, 궁극적으로는 일반인공지능(AGI)을 향해 나아갈 수 있는 잠재력을 가지고 있다\"라고 평했다. 연구진은 “이번 연구를 통해 LLM의 미래와 인간-AI ​​협업의 잠재력을 발견할 수 있어 기쁘게 생각한다”라고 밝혔다. 임대준 기자 ydj@aitimes.com"
}