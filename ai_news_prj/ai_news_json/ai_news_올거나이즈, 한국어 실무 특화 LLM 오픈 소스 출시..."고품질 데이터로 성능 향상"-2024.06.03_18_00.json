{
    "title": "올거나이즈, 한국어 실무 특화 LLM 오픈 소스 출시...\"고품질 데이터로 성능 향상\"",
    "created_at": "2024.06.03 18:00",
    "content": "대형언어모델(LLM) 전문 올거나이즈(대표 이창수)는 한국어 실무에 강한 경량 LLM '알파-인스트럭트(Alpha-Instruct)’ 출시 및 공개를 완료했다고 3일 밝혔다. 올거나이즈는 이 모델을 오픈 소스로 공개, 라이선스 제한 없이 누구나 자유롭게 사용 가능하다. 올거나이즈의 알리 플랫폼 내에서 알파-인스트럭트 모델을 사용할 수 있으며, 기업 맞춤형 특화 모델로 파인튜닝하거나 LLM을 내부 데이터에 연결해서 검색 증강 생성(RAG) 솔루션과 자유롭게 결합해 활용할 수 있다. 알파-인스트럭트 모델은 메타의 매개변수 8B(80억) 규모 오픈소스 LLM '라마3'를 기반으로 제작했다. 한국어를 잘 이해할 수 있도록 개량한 라마3 모델과 지시사항을 따르는 데 특화한 라마3의 인스트럭트 모델을 병합하는 방식으로 제작했다. 이후 보편적인 답변 선호도를 반영한 지시사항 데이터셋 2000개를 추가 학습해 동일 대답 반복과 불필요한 영어 대답 등 오류를 최소화했다. 올거나이즈 관계자는 \"데이터 양보다는 질이 확실히 중요한 것 같다\"라며 \"특히 인스트럭트 모델 튜닝에서 데이터 퀄리티에 공을 들이는 비중이 증가하고 있다\"라고 전했다. 이어 \"물론 메타의 인스트럭트 모델은 1000만건의 인간 주석이 있는 데이터를 사용했기 때문에 양이 중요하지 않다고 할 수는 없다\"라며 \"하지만 퀄리티 관리가 되지 않는 대량의 데이터를 쓰느니 소규모의 질 좋은 데이터로 학습하는 게 더 낫다고 생각한다\"라는 의견을 밝혔다. \"또 올거나이즈가 주력한 OPRO(Optimization by PROmpting) 학습법은 특히나 데이터의 퀄리티가 중요하다\"라며 \"OPRO로 멀티언어 미세조정을 진행한 타 모델의 논문들에서도 비슷한 결론을 내고 있다\"라고 말했다. 그 결과 알파-인스트럭트는 한국어 이해도가 높아 문서 생성 및 요약 등 실무에 특화돼 있다는 설명이다. 실제 한국어 언어모델의 다분야 사고력을 측정하는 '로직kor(Logickor)' 리더보드에서 높은 점수를 기록하고 있다. 로직kor는 한국어 추론, 수학, 글쓰기, 코딩, 이해 등의 요소를 측정한다. 알파-인스트럭트 모델은 글쓰기 및 이해 부분에서 높은 점수를 기록 중이라고 전했다. 라마3를 선택한 이유에 대해서도 \"현재 공개된 오픈소스 모델 중 라마3가 가장 성능이 뛰어나기 때문\"이라고 밝혔다. 특히 이전 버전과 비교했을 때 '일반적인 지시를 잘 따르는(general instruction following)' 성능 및 특성을 가진 만큼, 다양한 직업에도 유용할 것이라고 전망했다. \"경량화 모델이지만, 한국어 성능이 뛰어나서 어떤 산업에서든 유용하게 사용할 수 있을 것\"이라는 설명이다. 이창수 올거나이즈 대표는 “완성도 높은 한국어 모델을 만들기 위해 공들여 데이터셋을 구성, 다양한 방법론에 대해 수많은 테스트를 거쳐 극히 적은 리소스만으로 성능 좋은 모델을 만들 수 있었다\"라며 \"현재는 최근에 출시한 금융 특화 모델 '알파-F(EEVE)'를 라마3 기반으로 만드는 '알파-F(라마3)'를 열심히 개발 중이며 완료하는 대로 공개할 예정\"이라고 말했다. 한편 알파-인스트럭트 모델은허깅페이스 홈페이지에서 만나볼 수 있다. 장세민 기자 semim99@aitimes.com"
}