{
    "title": "허깅페이스, 매개변수 135M에 불과한 ‘스몰LM’ 출시",
    "created_at": "2024.07.17 18:00",
    "content": "허깅페이스가 초경량급 오픈 소스 소형언어모델(sLM)을 출시했다. 모바일 기기에서 인터넷 연결 없이도 완전히 실행되도록 '온디바이스 AI'에 최적화돼 있는 것이 특징이다. 벤처비트는 16일(현지시간) 허깅페이스가 클라우드 서버에 연결하지 않고도 장치에서 로컬로 실행 가능한 온디바이스 인공지능(AI)용 오픈 소스 sLM ‘스몰LM(SmolLM)’을 공개했다고 보도했다. 이에 따르면 스몰LM은 텍스트 생성 작업을 효율적으로 수행하도록 설계된 소형 모델로, 3가지 버전을 출시했다. 매개변수는 각각 1억3500만개(135M), 3억6000만개(360M), 17억개(1.7B)로 현재 공개된 sLM 중 가장 작은 규모다. 허깅 페이스는 데이터 큐레이션부터 훈련 단계에 이르기까지 전체 개발 프로세스를 오픈 소스로 만들어 차별화했다고 밝혔다. 합성 교과서 및 스토리인 코스모피디아 v2(Cosmopedia v2), 교육용 파이썬 샘플인 파이썬-에듀(Python-Edu), 큐레이팅된 교육용 웹 콘텐츠인 파인웹-에듀(FineWeb-Edu)로 구성된 포함하는 코스모-코퍼스(Cosmo-Corpus)를 기반으로 사전훈련했다. 성능 면에서도 큰 모델에 뒤지지 않는 것으로 나타났다. 가장 작은 모델인 스몰LM-135M은 적은 토큰으로 훈련했음에도 불구하고, 메타의 '모바일LM-125M' 보다 성능이 뛰어났다. 스몰LM-360M은 메타의 모바일LM와 알리바바의 '큐원' 등 5억개 미만의 매개변수를 가진 모든 모델을 능가했다. 주력 모델인 '스몰LM-1.7B'는 여러 벤치마크에서 마이크로소프트(MS)의 '파이-1.5', 메타의 '모바일LM-1.5B', 알리바바의 '큐원2-1.5B' 등을 능가했다. 루브나 벤 알랄 허깅페이스 수석 엔지니어는 \"휴대폰이나 PC에서 작고 성능이 뛰어난 모델을 실행할 수 있게 되면, AI를 모든 사람이 사용할 수 있다”라며 “이런 모델은 완전한 프라이버시와 더 낮은 에너지 사용으로 새로운 가능성을 열어준다\"라고 강조했다. 박찬 기자 cpark@aitimes.com"
}