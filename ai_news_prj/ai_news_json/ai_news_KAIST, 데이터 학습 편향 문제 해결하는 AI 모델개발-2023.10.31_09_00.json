{
    "title": "KAIST, 데이터 학습 편향 문제 해결하는 AI 모델개발",
    "created_at": "2023.10.31 09:00",
    "content": "한국과학기술원(KAIST, 총장 이광형)은 황의종 전기및전자공학부 교수 연구팀이 ‘학습 상황과 달라진 새로운 분포의 테스트 데이터’에서도 공정한 판단을 내리도록 돕는 새로운 인공지능(AI) 모델 훈련 기술을 개발했다고 30일 밝혔다. 기존 대부분의 관련 연구에서는 'AI 모델을 훈련시킬 때 사용하는 데이터'와 '실제 테스트 상황의 데이터'가 같은 분포를 갖는다고 가정해 왔다. 하지만 이러한 가정은 대체로 성립하지 않기 때문에 다수 상황에서 편향 현상이 일어났다. 이 경우에는 테스트 환경 데이터와 특정 그룹 정보 간의 편향 패턴을 변경하더라도 AI 모델이 직접적 영향을 받고 다시금 성능이 저하할 수 있다. 예를 들면 과거에는 특정 인종 위주로만 채용하던 기관이 이제는 인종에 제한을 두지 않는다면, 기존 AI 채용 모델이 오히려 현재에 맞지 않는 불공정한 판단을 내릴 수 있다는 것이다. 연구팀은 먼저 `상관관계 변화(correlation shifts)' 개념을 도입했다. 이미 강한 상관관계를 형성한 과거 데이터에 새로운 학습 데이터 샘플링 기법을 제안했다. 테스트 시에 데이터의 편향 패턴이 변화해도 모델을 공정하게 학습할 수 있는새로운 학습 프레임워크를 제시한 것이다. 주요 이점은 데이터 전처리만으로 기존 알고리즘의 공정한 학습 기법을 그대로 활용, 편향 현상만 개선 가능하다는 점이다. 제1 저자인 노유지 KAIST 전기및전자공학부 박사과정 학생은 \"이번 연구로 인공지능 모델이 더욱 신뢰 가능하고 공정한 판단을 할 것으로 기대한다ˮ고 전했다. 황의종 지도 교수는 \"변화하는 데이터에서도 공정성이 낮아지지 않을 것ˮ이라고 말했다. 한편 이 기술은 정보통신기획평가원의 지원을 받은 `강건하고 공정하며 확장가능한 데이터 중심의 연속 학습' 과제와 한국연구재단 지원을 받은 `데이터 중심의 신뢰 가능한 인공지능' 과제로 이뤄낸 성과다. 장세민 기자 semim99@aitimes.com"
}