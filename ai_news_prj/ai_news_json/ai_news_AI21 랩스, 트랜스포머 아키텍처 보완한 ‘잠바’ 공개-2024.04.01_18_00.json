{
    "title": "AI21 랩스, 트랜스포머 아키텍처 보완한 ‘잠바’ 공개",
    "created_at": "2024.04.01 18:00",
    "content": "이스라엘 스타트업 AI21 랩스가 새로운 오픈 소스 대형언어모델(LLM)을 출시했다. 트랜스포머 기반 아키텍처를 활용한 기존 LLM들과 달리, 이 모델은 트랜스포머 아키텍처에 'SSM(State Space Model)' 아키텍처를 결합한 것이 특징이다. 벤처비트는 28일(현지시간) AI21 랩스가 SSM을 기반으로 하는 ‘맘바(Mamba)’와 트랜스포머 아키텍처의 최고의 특성을 결합한 LLM ‘잠바(Jamba)’를 오픈 소스로 출시했다고 보도했다. 이에 따르면 잠바는 컨텍스트 창이 커짐에 따라 추론이 느려지고 메모리 공간이 많이 필요한 트랜스포머 아키텍처의 약점을 보완하기 위해  맘바 SSM 아키텍처를 트랜스포머 아키텍처에 결합했다. 2017년 구글이 개발해 공개한 트랜스포머는 LLM 대중화를 가능케 한 주역으로 꼽힌다. 하지만 트랜스포머는 한계도 명확하다. 트랜스포머 기반 모델은 입력되는 모든 정보를 처리하기 때문에  컨텍스트 창이 커질 때 느려지는 문제가 있다. 또 컨텍스트 길이가 커질수록 훨씬 더 큰 메모리 공간을 필요로 하기 때문에 하드웨어 리소스 없이 긴 컨텍스트 창을 실행하기 어렵다. 카네기 멜론 및 프린스턴대학교 연구진이 공개한 맘바는 트랜스포머보다 AI 성능을 키우고 단점은 줄이는데 초점이 맞춰져 있다. 맘바는 언어, 오디오 등 다양한 유형들을 커버하는 SSM을 활용, 입력된 정보 중 중요 데이터에 선택적으로 집중할 수 있다. 이를 위해 맘바는 각 단계들에서 어떤 정보에 집중하거나 무시할지 선택할 수 있는 특화된 레이어를 제공한다. 잠바는 채택한 맘바-트랜스포머 아키텍처는 SSM과 트랜스포머 하이브리드로, 25만6000 토큰 길이의 컨텍스트 창을 제공하며 동일한 크기 트랜스포머 모델 ‘믹스트랄 8x7B(Mixtral 8x7B)’에 비해 긴 컨텍스트에 대해 3배의 처리량을 제공할 수 있다. AI21 랩스는 잠바는 최대 14만 토큰 길이의 컨텍스트 창을 80GB 메모리를 가진 단일 GPU에서 처리할 수 있는 유일한 LLM이라고 주장했다. 또 잠바는 맘바-트랜스포머 아키텍처에 ‘전문가 혼합(MoE)’ 모델을 채택했다. MoE는 여러 모델 중 일부만을 사용해 효율을 높이는 방식으로, 잠바에 MoE를 도입하면 520억 매개변수 가운데 120억개만 사용할 수 있다. 즉 동일한 크기의 트랜스포머 전용 모델보다 더 효율적이다. 하지만 잠바가 트랜스포머를 대체할 수 있을지 여부는 좀 더 두고 봐야할 것 같다는 평이다. 잠바는 헬라스웩(HellaSwag)과 같은 추론 작업에선 기존 트랜스포머 기반 모델들을 능가하는 결과를 보여주고 있지만, AI 모델 문제 해결 능력을 측정하는 MMUL와 같은 벤치마크에서는 트랜스포머 기반 모델보다 성능이 뛰어나지 않은 것으로 나타났다. 벤처비트는 \"잠바가 트랜스포머 기반 LLM을 대체할 가능성은 없지만, 특정 영역에서는 보완책이 될 가능성이 높다\"라고 평가했다. AI21랩스는 잠바가 대형기업에서 특히 유용할 것으로 기대하는 모습이다. 예전에도 기업 톤과 브랜드에 맞춰 콘텐츠를 생성할 수 있도록 지원하는 생성 AI 모델 ‘워드튠(Wordtune)’을 개발, 2023년 11월 2억800만달러 규모 투자를 유치했다. 현재까지 AI21 랩스의 LLM 기술은 다른 LLM과 마찬가지로 트랜스포머 아키텍처에 뿌리를 두고 있다. 여기에는 AI21랩스 서비스형 자연어 처리 플랫폼을 통해 이용할 수 있는 LLM ‘쥬라기-2(Jurassic-2)’도 포함됐다. AI21랩스는 잠바가 쥬라기-2 후속 버전이라기 보다는, 맘바-트랜스포머 하이브리드 기술에 기반한 완전히 새로운 모델임을 강조하고 있다. 잠바는 아파치 2.0 라이선스 하에 허깅페이스에 공개돼 있으며, 엔비디아 AI 엔터프라이즈 소프트웨어 플랫폼 내 엔비디아 NIM 추론 마이크로서비스를 통해 API로 액세스할 수 있다. 지금은 상용화를 위한 안전장치가 갖춰지지 않은 연구 모델로 릴리스됐지만, 4월 중 미세조정한 안전한 버전을 출시할 예정이다. 박찬 기자 cpark@aitimes.com"
}