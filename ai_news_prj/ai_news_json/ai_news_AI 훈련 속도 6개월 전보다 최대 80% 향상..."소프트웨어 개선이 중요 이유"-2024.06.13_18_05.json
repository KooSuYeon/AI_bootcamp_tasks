{
    "title": "AI 훈련 속도 6개월 전보다 최대 80% 향상...\"소프트웨어 개선이 중요 이유\"",
    "created_at": "2024.06.13 18:05",
    "content": "6개월 사이에 인공지능(AI) 칩의 훈련 속도가 최대 2배 가까이 빨라진 것으로 나타났다. 하드웨어는 물론, AI 모델의 알고리즘이나 관련 소프트웨어의 행상이 결정적인 역할을 했다는 분석이다. 벤처비트는 12일(현지시간) ML커먼스가 'ML퍼프(MLPerf) 4.0' 훈련 벤치마크 결과를 발표했다고 전했다. 이는 지난해 11월 ML퍼프 3.1 훈련 벤치마크 결과가 공개된 이후 반년 만의 업데이트다. 이번 ML퍼프 4.0 훈련 벤치마크에는 ▲'라마 2 70B' 모델을 문서 요약에 맞춰 미세조정하는 새로운 '로라(LoRA)' 워크로드 ▲GNN(그래프 신경망) 워크로드 등이 추가됐다. 또 ML퍼프에는 처음으로 ▲전력 측정 옵션 등이 새로 추가됐다. 엔비디아, 인텔, 구글, 오라클, HPE, 코어위브 등 17개 회사가 참여, 205개 이상의 성능 결과가 나왔다. 모델 학습 속도는 전반적으로 개선됐다. 특히 지난번 벤치마크와 비교해 이미지 생성 모델 ‘스테이블 디퓨전’ 훈련 속도는 1.8배, 'GPT-3' 훈련은 최대 1.2배 빨라졌다. ML커먼스는 훈련 성능 향상이 하드웨어도 중요하지만, 클러스터를 서로 연결하는 네트워크와 소프트웨어에 기인한다고 분석했다. 데이비드 칸터 ML 커먼스 창립자는 \"AI 훈련의 경우, 성능과 효율성을 향상하기 위해 다양한 주요 레버에 접근할 수 있다\"라며 \"훈련을 위해 대부분 시스템은 여러 프로세서나 가속기를 사용하며, 작업이 어떻게 분할되고 전달되는지가 매우 중요하다\"고 설명했다. 따라서 \"공급업체들이 더 나은 실리콘을 활용할 뿐만 아니라, 더 나은 알고리즘과 더 나은 스케일링을 사용해 점차 더 높은 성능을 제공하고 있다”라고 분석했다. 엔비디아는 이번에도 인상적인 결과로 ML퍼프 벤치마크를 장악했다. 9개의 워크로드에서 모두 1위를 차지했으며, 그 중 5개에서는 신기록을 세웠다. 인상적인 점은 새 기록 대부분이 지난해 6월에 사용했던 'H100' 기반의 하드웨어 플랫폼을 그대로 사용했다는 점이다. 대신 ML퍼프 4.0 훈련 성능을 향상하기 위해 전체 스택 최적화, 고도로 튜닝된 FP8 커널, FP8 인식 분산 최적화 도구, 고급 수학 및 통신 실행, 그리고 지능형 GPU 전력 할당 등 다양한 기술을 사용했다. 데이비드 살바토르 엔비디아 AI 이사는 “소프트웨어 혁신을 통해 동일한 아키텍처에서 2~2.5배 더 많은 성능을 얻을 수 있었다”라고 말했다. 새로운 칩 출시로 하드웨어의 성능도 계속해서 좋아지고 있지만, 소프트웨어 개선을 통해 동일한 하드웨어에서도 성능을 높일 수있다고 강조한 것이다. 박찬 기자 cpark@aitimes.com"
}