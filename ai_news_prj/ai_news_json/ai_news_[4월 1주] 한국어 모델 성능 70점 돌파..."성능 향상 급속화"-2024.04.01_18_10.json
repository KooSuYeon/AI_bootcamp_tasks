{
    "title": "[4월 1주] 한국어 모델 성능 70점 돌파...\"성능 향상 급속화\"",
    "created_at": "2024.04.01 18:10",
    "content": "한국어 언어모델의 성능이 비약적으로 향상하고 있다. 지난달 9일 60점을 처음 넘긴 데 이어, 한달도 안 돼 70점까지 넘어섰다. 1일 현재 오픈 Ko-LLM 리더보드에서는 소속 미상 개발자의 모델(hwkwon/S-SOLAR-10.7B-v1.5, 70.35)이 평균 70.35점으로 1위에 오르며 신기록을 세웠다. 이어 2위에는 3월 4주차에 1위를 차지했던 티쓰리큐(대표 박병훈)가 자리했다. 2위 모델(chihoonlee10/T3Q-ko-solar-dpo-v5.0, 70.3) 역시 70점을 넘었다. 1~2위 간 점수 차이는 0.05점에 불과하다. 티쓰리큐는 10위권 내에서도 무려 5개 모델을 올렸다. 그만큼 다양한 방법의 데이터전처리와 미세조정의 방법을 테스트했다는 증거다. 특히 직접 선호 최적화(DPO) 및 가독미세조정(SFT) 기법을 사용한 모델이 70.3을 달성하며 가장 좋은 성능을 입증했다. 기술 리더를 담당하는 이치훈 티쓰리큐 부대표는 “상징적 의미가 있는 70점 대의 벽을 넘어서게 돼서 기쁘다\"라며 \"이번 모델은 SFT 학습과 DPO 학습을 순차적으로 수행해 특히 상식능력(HellaSwag), 환각방지능력(TruthfulQA) 테스트에서 점수를 대폭 개선하게 됐다\"라고 설명했다. 이 외에도 10위 해당 모델의 점수가 67점대에 달하는 등 전체적인 평균치가 대폭 상승했다. 갑작스러운 점수 상승에 의혹의 눈초리도 모이는 것으로 알려졌다. 리더보드 운영을 맡은 업스테이지 관계자는 \"요즘 리더보드 점수 조작 등 의혹이 떠도는 경우가 있다\"라며 \"이는 전혀 사실이 아니다\"라고 못 박았다. \"상위권 모델의 기반이 되는 솔라 모델의 경우 최근 논문으로 인정받기도 했다\"라며 전반적인 모델 성능 향상의 계기가 됐다는 점을 강조했다. 또 \"리더보드 운영진이라고 해도 차트의 인터페이스 구축이나 관리 자체를 맡는 것뿐이지, 모델에 대해서는 자세히 알 수 없는 게 현실\"이라고 강조했다. 리더보드 상세 내용은NIA 홈페이지나허깅페이스 홈페이지에서 확인할 수 있다. 장세민 기자 semim99@aitimes.com"
}