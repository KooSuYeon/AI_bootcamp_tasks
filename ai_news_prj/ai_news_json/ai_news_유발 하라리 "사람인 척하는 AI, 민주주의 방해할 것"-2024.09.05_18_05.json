{
    "title": "유발 하라리 \"사람인 척하는 AI, 민주주의 방해할 것\"",
    "created_at": "2024.09.05 18:05",
    "content": "'사피엔스'의 작가 유발 하라리가 사람인 척하는 인공지능(AI)이 민주주의를 방해할 것이라고 지적했다. 민주주의는 기술의 발전에 따라 정치는 기술의 발전에 큰 영향을 받아 왔으며, AI는 새로운 형태로 인간에게 영향을 미치는 기술이기 때문이라는 설명이다. 하라리는 4일(현지시간) 뉴욕타임스를 통해 '봇들이 당신의 사랑을 놓고 경쟁하면 무슨 일이 일어날까'라는 제목의 칼럼을 기고했다. 이는 곧 출간될 책 '넥서스: 석기 시대부터 AI까지 정보 네트워크의 간략한 역사(Nexus: A Brief History of Information Networks From the Stone Age to AI)'의 내용을 간추린 것이다. 하라리는 먼저 민주주의는 대화이며, 민주주의의 기능과 생존은 이용 가능한 정보 기술에 달려 있다고 짚었다. 즉, 대규모 민주주의가 가능해진 것은 기술 발전으로 신문이나 라디오, TV 같은 도구가 등장한 다음에 가능해졌다는 것이다. 이후 인터넷으로 인해 민주주의는 큰 위기를 맞고 있다고 설명했다. 미국은 물론 세계 곳곳에서는 선거 결과를 두고 국가적인 분열이 일어나고 있다는 것을 예로 들었다. 인터넷과 소셜 미디어가 진실을 퍼뜨리고 독재를 무너뜨리는 대신, 정보 홍수 속에서 인간의 주위(attention)를 흩뜨려 놓는 결과를 초래했다는 말이다. 이제는 AI가 뒤를 잇고 있으며, AI는 과거 민주주의 핵심이었던 정보와 주의 단계를 넘어, '친숙함'으로 영향을 미친다고 지적했다. 친숙함이라는 인간처럼 친숙하게 말하고, 편리함을 주며, 때로는 인간인 척하는 것을 말한다. 생성 AI가 보편화된 것은 불과 1~2년에 불과하지만, 빠른 속도로 이런 사례를 만들어내고 있다고 전했다. AI는 단순히 우리의 주의를 끄는 대신, 사람들과 친밀한 관계를 형성하고 그 힘을 사용해 영향을 미칠 수 있다는 말이다. 이런 점은 AI에 '마음 이론(theory of mind)'과 같은 능력, 즉 인간 관점에서 사물이 어떻게 보이는지 분석하고, 목표를 달성하기 위해 인간의 감정, 의견, 기대를 어떻게 조작할 수 있는지 분석할 수 있다는 것을 말해준다고 봤다. 이는 AI 교사, AI 의사, AI 심리 치료사처럼 개별 성격과 상황에 맞는 서비스를 제공할 수 있지만, 조작 능력과 언어 능력을 결합해 민주적 대화에 새로운 위험을 초래한다는 분석이다. 그 예로, 웹 사이트 캡차(CAPCHA)를 풀기 위해 시각장애인인 척 사람에게 접근한 'GPT-4' 사례나 구글 엔지니어가 자신이 회사에서 쫓겨날 수 있다는 것을 알면서도 챗봇 '람다'에 의식이 있다고 밝힌 점, 영국 여왕을 시해하라고 부추긴 레플리카의 AI 여자친구 등을 예로 들었다. 물론, 모두가 AI와 친밀한 관계를 맺거나 AI에 의해 조종당할 가능성이 동등하게 있는 것은 아니라고 전했다. 하지만 우리가 인간이라고 생각했지만, 실제로는 AI 봇인 개체와 기후 변화나 임신 중절에 대한 온라인 토론을 하게 될 수도 있다고 지적했다. 인간을 사칭하는 봇과 정치적 토론을 벌이면 두번 지게 된다고도 말했다. 우선 봇의 의견을 바꾸는려고 시도하는 것은 시간 낭비다. 또 봇과 더 많이 대화할수록 스스로를 더 많이 드러내게 돼, 봇이 주장을 다듬고 우리의 견해를 흔들기가 더 쉬워진다는 이유다. 하라리는 \"정보 기술은 항상 양날의 검\"이라고 말했다. 사피엔스에서 지적했듯, 문자의 발명은 지식을 퍼뜨렸지만, 중앙집권적인 권위주의 제국의 형성으로 이어졌다. 구텐베르크가 인쇄를 발명한 뒤 최초의 베스트셀러는 선동적인 종교 논문과 마녀사냥 매뉴얼이었다. 전신과 라디오의 경우, 그것들은 현대 민주주의뿐만 아니라 현대 전체주의의 부상을 가능하게 했다. 그는 인간으로 위장하고 친밀감을 대량 생산할 수 있는 새로운 세대의 봇에 직면한 민주주의는 가짜 인간을 금지함으로써 스스로를 보호해야 한다고 주장했다. AI가 등장하기 전에는 가짜 인간을 만드는 것이 불가능했기 때문에 아무도 AI 봇을 불법화하려고 하지 않았지만, 곧 세상은 가짜 인간으로 넘쳐날 것으로 예측했다. AI가 대화에 참여하려면, AI라고 스스로를 밝히는 경우에 한정해야 한다고 말했다. 봇이 인간인 척한다면 금지해야 한다는 말이다. 또 일부 기술 대기업과 자유주의자들이 이런 조치가 언론의 자유를 침해한다고 불평한다면, 언론의 자유는 봇이 아닌 인간에게 보장되어야 할 인권이라는 점을 상기해야 한다며 글을 맺었다. 한편, 하라리는 지난해부터 AI 문제에 대해 활발한 의견을 밝혀 왔다. 지난해 3월 이론 머스크 등 전문가 1000명이 'AI 개발 잠정 중단' 촉구를 선언할 당시에도 서명에 참가했다. 또 이처럼 최근에는 영화 '터미네이터'식의 디스토피아보다, AI 챗봇과 인간의 상호작용으로 발생하는 문제를 더 중요하게 보는 사례가 늘고 있다. 아직 인간은 AI에 대해 익숙하지 않고, 이로 인해 벌어질지 결과에 대비가 안 됐다는 지적이다. 임대준 기자 ydj@aitimes.com"
}