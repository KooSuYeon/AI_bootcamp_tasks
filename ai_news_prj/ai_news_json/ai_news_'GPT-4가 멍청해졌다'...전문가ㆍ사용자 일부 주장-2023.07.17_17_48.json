{
    "title": "'GPT-4가 멍청해졌다'...전문가ㆍ사용자 일부 주장",
    "created_at": "2023.07.17 17:48",
    "content": "'GPT-4'가 멍청해졌다는 주장이 나왔다. 오픈AI의 '모델 쪼개기' 작업이 원인인 것으로 지목됐다. 오픈AI는 \"더 똑똑해졌다\"고 반박했다. 비즈니스인사이더는 13일(현지시간) 최근 일부 전문가와 사용자 사이에서 \"GPT-4의 성능이 떨어졌다\"는 지적이 일자 오픈AI는 \"성능이 떨어진 것이 아니라 더 높아졌다\"고 대응했다고 보도했다. 이에 따르면 오픈AI의 온라인 개발자 포럼과 트위터 등에는 GPT-4의 논리 약화와 늘어난 오답률, 입력정보 이해 불가, 가장 최근 프롬프트 이외에는 모두 잊어버리는 현상 등을 지적하는 글이 쏟아졌다. 더불어 GPT-4가 \"게을러졌다\" 혹은 \"멍청해졌다\"는 혹평이 이어졌다. 피터 양 로블럭스 제품책임자는 \"글을 더 빨리 출력해 내지만, 내용은 더 나빠졌다\"고 지적했고, 크리스티 케네디라는 개발자는 \"자꾸 똑같은 내용의 코딩을 반복한다\"며 \"GPT-4가 마치 죽었다 되살아났다를 반복하는 것 같다\"고 말했다. 한 개발자는 \"페라리를 운전하다가 고장난 픽업 트럭을 모는 기분\"이라고 전했고, 일부 사용자는 구독을 취소했다고도 밝혔다. 지난 3월 출시된 GPT-4는 출력은 비교적 느리지만 정확도가 뛰어나다는 평가를 받았다. 그러나 몇주전 눈에 띄게 속도가 빨라지더니, 이후 품질 저하에 시달렸다는 불평이 이어졌다. 이에 대해 관게자들은 '전문가 믹스(MOE, Mixture of Expert)'라는 방식 때문이라고 입을 모았다. 샤론 저우 라미리 CEO는 오픈AI가 GPT-4를 여러 개의 작은 모델로 분리하고, 상황에 맞춰 혼합해서 쓰는 것 같다고 지적했다. 오렌 에지오니 앨런 AI 연구소 CEO도 같은 의견을 피력했다. 즉 GPT-4를 생물, 물리, 수학 등 각 분야를 담당하는 작은 전문 모델(Expert)로 쪼개고, 질문에 따라 전문 모델을 연결하거나 몇 종류를 섞는다는 것이다. 이 경우 전체 큰 모델을 돌리는 것보다 비용과 시간이 훨씬 적게 들어간다. 그렉 브록만 오픈AI 회장 역시 지난 2022년 논문을 통해 MOE 접근 방식의 장점에 대해 기술한 바 있다. 저우 CEO는 '어떤 사람은 이전과 별 차이가 없다고 느낄 수 있으며, 실제로는 같은 모델\"이라며 \"MOE 모델은 시간이 지나며 개선될 것\"이라고 말했다. 오픈AI도 입장을 내놓았다. 벤처비트에 따르면 피터 웰린더 제품 부사장은 트위터를 통해 \"GPT-4를 바보로 만들지 않았을뿐더러, 각 버전이 이전 버전보다 더 똑똑하다\"고 주장했다. MOE를 시인한 셈이다. 또 \"제품을 더 많이 사용하면 원래 안 보이던 문제도 나타난다\"고 지적했다. 이에 대해 일부 사용자는 동의했지만, 일부는 여전히 GPT-4가 멍청해졌다고 주장하는 중이다. 무엇보다 오픈AI가 GPT-4 출시 당시 기술보고서를 통해 자세한 사항을 밝히지 않았기 때문에 이런 일이 생겨도 믿을 수 없다는 반응이다. 모델에 변경이 생겼는지 아닌지 외부에서는 확인할 근거가 없다는 말로, 일부 사용자는 오픈AI의 폐쇄성을 거듭 비난하고 있다. 임대준 기자 ydj@aitimes.com"
}