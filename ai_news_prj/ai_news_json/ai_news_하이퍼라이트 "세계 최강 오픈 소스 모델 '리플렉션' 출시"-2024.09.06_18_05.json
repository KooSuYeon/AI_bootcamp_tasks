{
    "title": "하이퍼라이트 \"세계 최강 오픈 소스 모델 '리플렉션' 출시\"",
    "created_at": "2024.09.06 18:05",
    "content": "인공지능(AI) 글쓰기로 유명한 미국 스타트업 하이퍼라이트가 역대 최고 성능의 오픈 소스 대형언어모델(LLM)을 공개했다고 주장했다. 추론 과정에서 발생한 오류를 식별하고 수정할 수 있는 기술을 적용하고 고품질 합성 데이터로 훈련한 결과라고 설명했다. 벤처비트는 5일(현지시간) 하이퍼라이트가 12만8000 토큰 컨텍스트 창을 제공하는 700억 매개변수의 LLM ‘리플렉션 70B(Reflection 70B)’를 오픈 소스로 출시했다고 보도했다. 이에 따르면 리플렉션 70B는 메타의 '라마 3.1-70B 인스트럭트' 모델을 미세조정해 구축했다. 이 모델은 추론 과정에서 발생한 오류를 스스로 감지하고 최종 응답을 내리기 전에 오류를 수정할 수 있는 '반사 튜닝(Reflection Tuning)' 기술을 적용했다. 반사 튜닝은 추론 및 오류 수정을 위해 몇가지 새로운 특수 토큰을 도입했다. 이를 통해 모델은 추론 중 특수 태그 내에서 추론을 출력해 실수가 감지되면 실시간으로 수정할 수 있다는 설명이다. 실제로 리플렉션 70B는 ‘Strawberry’라는 단어에서 ‘r’이 몇번 나오는지, 그리고 9.11과 9.9 중 어느 숫자가 더 큰지를 묻는 문제에 대해 처리 속도는 느렸지만 정확한 응답을 제공했다. 이런 문제들은 LLM의 추론 성능을 따질 때 등장하는 대표적인 질문이다. 반사 튜닝을 기반으로, 추론을 여러 단계로 분리해 처리하기 때문에 높은 정확도가 요구되는 작업에 특히 유용하다고 강조했다. 또 특정 사용 사례에 맞춘 데이터셋을 생성하는 스타트업 글레이브의 합성 데이터로 미세조정했다. 글레이브 기술을 활용해 리플렉션 70B를 미세조정하기 위한 고품질의 합성 데이터를 몇시간 만에 생성할 수 있었다고 전했다. 맷 슈머 하이퍼라이트 CEO는 “전체 훈련 과정은 3주가 걸렸으며, 3주 동안 모델을 5번 반복 훈련했다\"라며 \"데이터셋은 전적으로 맞춤 제작했으며, 글레이브의 합성 데이터 생성 시스템을 사용했다\"라고 밝혔다. https://twitter.com/mattshumer_/status/1831767014341538166?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1831767014341538166%7Ctwgr%5Edf84280a5c8723c3c6503224d34feb3aca0fa0d2%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fventurebeat.com%2Fai%2Fmeet-the-new-most-powerful-open-source-ai-model-in-the-world-hyperwrites-reflection-70b%2F 리플렉션 70B가 세계 최고의 성능이라는 주장은 MMLU와 휴먼이벨을 포함한 벤치마크 6개 항목에서 메타의 '라마 3.1 405B'를 모두 능가했기 때문이다. 또 'GPT-4o'와 '제미나이'를 모두 뛰어 넘었으며, '클로드 3.5 소네트'에는 4개 분야에서 앞섰다. 현재허깅페이스를 통해 다운로드할 수 있으며, API 액세스는 GPU 서비스 제공업체하이퍼볼릭 랩스를 통해 제공될 예정이다 . 한편, 하이퍼라이트는 4050억 매개변수의 '리플렉션 405B' 모델을 다음 주 출시할 예정이다. 슈머 CEO는 \"이 모델은 GPT-4o와 같은 폐쇄형 LLM의 성능을 상당한 차이로 능가할 것\"이라고 예고했다. 박찬 기자 cpark@aitimes.com"
}