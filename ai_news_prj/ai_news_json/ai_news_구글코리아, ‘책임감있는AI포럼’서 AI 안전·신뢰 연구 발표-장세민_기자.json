{
    "title": "구글코리아, ‘책임감있는AI포럼’서 AI 안전·신뢰 연구 발표",
    "created_at": "장세민 기자",
    "content": "구글코리아는 최근 법조계, 학계, IT업계 및 스타트업 등 분야별 전문가를 초청해 제1기 ‘책임감있는AI포럼’ 3회차를 개최, 설명가능한 AI(XAI)를 통한 안전하고 유익한 AI 활용 방향을 논의했다고 22일 밝혔다. 이번 3회차 포럼은 안전한 온라인 환경 조성을 위한 토론 ‘세이퍼 위드 구글’ 행사와 연계해 진행했다. 먼저 최재식 한국과학기술원(KAIST) 김재철AI대학원 교수 겸 KAIST XAI 연구센터 센터장은 설명가능한 AI의 작동 원리와 의료, 금융, 제조, 정부 등 분야별 활용 사례를 소개했다. 전세계적으로 활발히 논의 중인 AI 규제 동향과 윤리적 문제, 기대 효과 등 설명가능한 AI의 향후 전망 및 시사점도 전했다. 최재식 교수는 “설명가능한 AI는 AI 기술의 투명성과 신뢰성을 한층 개선할 것”이라며 “전 세계적으로 AI 안전성 확보를 위해 주력하는 가운데, 앞으로도 ‘책임감있는AI포럼’에서 의미있는 논의를 이어나갈 수 있기를 바란다”라고 말했다. 구글 딥마인드도 언어 해석 도구(LIT) 등 책임감 있는 AI 활용을 위한 툴킷과 향후 전망을 발표했다. 루도빅 페란 구글 딥마인드 프로덕트 매니저는 “구글은 더 많은 개발자들이 책임감 있는 생성 AI 의 모범 사례를 구현할 수 있도록 ‘책임감 있는 생성형 AI 툴킷’을 개발했다”라며 “표준화된 정책 준수, 다양한 문화와 의견을 존중하는 콘텐츠 제작, 유해 콘텐츠의 적절한 감지와 제어, 정교한 성능 평가 및 리스크 측정, 투명한 피드백 등을 할 수 있게 됐다”라고 말했다. 발표 후 이어진 토론에서는 포럼 멤버로 참석한 전문가 17명이 ▲설명가능성과 AI 기술 혁신의 관계 ▲설명가능한 AI가 가져올 윤리적-사회적 영향력 ▲법제도 및 정책 영역 내 설명가능한 AI의 적용 방안 ▲설명가능한 AI 강화와 AI 기술 혁신의 동시 달성 방향 등 최근 화두가 되고 있는 안건들을 논의했다. 신경자 구글 아태지역 플랫폼-디바이스 마케팅 및 구글코리아 마케팅 총괄은 “생성 AI의 등장으로 더욱 중요해진 ‘설명가능한 AI’는 책임감 있는 AI 기술의 개발과 혁신에서 주목받고 있는 주제 중 하나”라며 “앞으로도 AI의 신뢰성과 안전성을 확보하는 동시에 혁신을 이어가기 위한 한층 구체적이고 심도 있는 논의가 지속되기를 기대한다”라고 말했다. 장세민 기자 semim99@aitimes.com"
}