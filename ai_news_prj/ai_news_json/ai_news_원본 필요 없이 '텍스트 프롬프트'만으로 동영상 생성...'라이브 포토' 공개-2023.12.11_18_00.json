{
    "title": "원본 필요 없이 '텍스트 프롬프트'만으로 동영상 생성...'라이브 포토' 공개",
    "created_at": "2023.12.11 18:00",
    "content": "텍스트 프롬프트만으로 사진을 만들고 이를 동영상으로 변환할 수 있는 기술이 등장했다. 이는 기존에 원본 이미지를 동영상으로 변환하거나 동영상에서 모션을 추출해 사진에 적용하는 방법보다 훨씬 간단하게 동영상을 생성할 수 있다는 설명이다. 마크테크포스트는 9일(현지시간) 홍콩대학교와 알리바바, 앤트그룹의 연구원들이 '라이브포토(LivePhoto)'라는 인공지능(AI) 모델 연구 결과를 온라인(arXiv)으로 공개했다고 보도했다. 이에 따르면 라이브포토는 기존 이미지-애니메이션의 한계를 해결하기 위해 등장했다. 즉 기존 대부분 모델은 원본 이미지를 따로 구하거나 생성 AI로 이미지를 만든 뒤, 이를 동영상 생성 AI에 적용하는 2단계를 거쳤다. 또는 기존 동영상에서 모션 부분을 추출, 이를 이미지에 적용하는 방식이다. 반면 라이브포토는 텍스트 프롬프트로 이미지 생성과 동시에 비디오 애니메이션을 지정하는 도구다. \"참조 비디오나 참조 이미지에 의존했던 이전 작업과 달리, 라이브포토에서 동영상 생성에 필요한 것은 텍스트 프롬프트뿐\"이라고 강조했다. 더불어 사용자가 모션 강도를 정밀하게 제어하는 텍스트 지침을 내릴 수 있다고 전했다. 이 시스템은 스테이블 디퓨전에 추가 모듈과 레이어를 도입, 강화한 방식이다. 효과적인 텍스트-모션 매핑을 위해 모션 모듈, 모션 강도 추정 모듈, 텍스트 재가중 모듈 등을 통합했다. 시간 모델링 및 강도 추정을 위한 모션 모듈은 텍스트 지침을 비디오로 디코딩, 다양한 동작과 카메라 움직임 등을 효과적으로 구현한다는 설명이다. 연구진은 \"스테이블 디퓨전을 최신 모델인 'SD-XL'과 같은 더 높은 해상도와 강력한 기능을 갖춘 모델로 대체하면 전반적인 성능을 크게 향상할 수 있을 것\"이라고 밝혔다. 즉, 텍스트의 모션 속도 및 크기 설명 문제를 해결하면 동영상의 움직임을 향상시킬 수 있다. 또 초해상도 네트워크를 후처리로 활용하면 비디오의 부드러움과 해상도를 향상할 수 있다. 더불어 훈련 데이터 품질을 개선하면 생성 비디오의 이미지 일관성이 향상될 수 있다고 전했다. 연구진은 깃허브를 통해 연구 내용과 소스를 공개했다. 향후 작업에서는 훈련 파이프라인을 개선하고 동작 강도 추정 모듈을 최적화하겠다고 밝혔다. 한편 정지 이미지, 즉 사진 한장으로 짧은 동영상을 만드는 생성 AI 기술은 최근 대세를 이루고 있다. 스태빌리티와 메타, 피카랩스는 물론 지난주에는 알리바바의 다른 연구팀도 관련 기술을 선보였다. 전문가들도 2024년에는 이런 기술로 인해 생성 AI로 만든 영화가 트렌드를 이룰 것이라고 예측하고 있다. 임대준 기자 ydj@aitimes.com"
}