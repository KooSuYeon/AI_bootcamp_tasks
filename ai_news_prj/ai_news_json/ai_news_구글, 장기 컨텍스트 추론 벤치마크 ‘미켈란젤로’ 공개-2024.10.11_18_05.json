{
    "title": "구글, 장기 컨텍스트 추론 벤치마크 ‘미켈란젤로’ 공개",
    "created_at": "2024.10.11 18:05",
    "content": "구글 딥마인드가 긴 컨텍스트 창을 가진 대형언어모델(LLM)의 추론 능력을 평가하기 위해 새로운 벤치마크를 공개했다. 벤치마크는 10일(현지시간) 구글 딥마인드가 벤치마크 ‘미켈란젤로(Michelangelo)’에 관한논문을 아카이브에 게재했다고 보도했다. LLM의 역량을 평가하기 위한 대부분의 벤치마크는 모델이 대규모 컨텍스트 내에 숨겨진 특정 정보를 찾는 ‘건초더미 속의 바늘’ 평가와 같은 검색 작업에 초점이 맞춰져 있다. 그러나 검색 작업이 전체 컨텍스트에서 추론할 수 있는 모델의 능력을 반영하지는 않는다. 모델이 컨텍스트에서 특정 정보를 찾을 수는 있지만, 텍스트의 서로 다른 부분들 간의 관계를 이해하지 못할 수도 있다는 설명이다. 특히 최근에는 12만8000개에서 100만개 이상의 토큰을 처리할 수 있는 매우 긴 컨텍스트 창을 가진 LLM이 보편화되며, 기존 벤치마크들은 모델의 장기 컨텍스트에서의 추론 능력을 평가하는 데 한계가 있다는 지적이 나온다.. 키란 보드라할리 구글 딥마인드 연구 과학자는 \"모델의 가중치에 저장된 정보와 검색만을 사용해 해결할 수 있는 장기 추론 평가를 개발하는 것은 쉽다. 하지만 이로 인해 모델이 장기 컨텍스트를 사용하는 능력을 잘못 평가할 수도 있다\"라고 말했다. 벤치마크 한계를 해결하기 위해 구글 딥마인드는 단순히 고립된 사실을 검색하는 것이 아니라, 문맥 창 안에서 정보의 관계와 구조를 이해하는 모델의 능력을 평가하는 장기 컨텍스트 추론 평가를 도입했다. 미켈란젤로는 ▲잠재 리스트(Lastent List) ▲다중 라운드 공동 참조 해결(MRCR) ▲모른다(IDK) 등 3가지 핵심 작업으로 구성된다. 먼저 잠재 리스트는 코드 명령어 스트림에서 데이터 구조의 속성을 추적하는 모델 능력을 측정한다. 예를 들어 모델은 파이썬 코드 리스트에서 수행된 긴 연산 시퀀스를 처리하고, 관련이 없거나 중복된 문장을 걸러내어 리스트의 최종 상태를 결정해야 한다. MRCR은 ▲자연스러운 텍스트에서 순서를 이해하는 모델의 능력 ▲유사한 초안을 구별하는 능력 ▲어려운 질문에 직면했을 때 이전 컨텍스트의 특정 부분을 재현하는 능력 등을 측정한다. 모델은 사용자와 LLM 간의 긴 대화 일부를 생성할 수 있어야 한다. 이는 모델이 대화의 구조를 이해하고, 혼란스럽거나 주의를 분산시키는 요소가 있더라도 이전 대화에 대한 참조를 해결하는 것을 요구한다. IDK는 주어진 문맥을 기반으로 모델이 모르는 것을 인지하는 능력을 측정한다. 모델은 긴 이야기를 읽고 그에 대한 객관식 질문에 답해야 한다. 일부 질문에서는 컨텍스트에 답이 없기 때문에, 모델은 자신의 지식 한계를 인식하고 \"모르겠다\"라고 답할 수 있어야 한다. 미켈란젤로의 작업들은 새로운 프레임워크인 '잠재 구조 질의(LSQ)'를 기반으로 한다. LSQ는 장기 컨텍스트 추론 평가를 설계하는 일반적인 접근 방식을 제공하며, 이를 임의의 길이로 확장할 수 있다. 또 단순한 사실 검색이 아닌, 모델이 암시된 정보를 이해하는 능력을 테스트할 수 있다. 테스트 데이터가 학습 코퍼스에 유출되는 문제를 피하기 위해 합성 테스트 데이터도 활용한다. 미켈란젤로는 모델이 키에서 값을 추출하는 것이 아니라 구조에서 정보를 추출하도록 요구함으로써, 검색을 넘어 언어 모델의 컨텍스트 이해를 더 깊이 테스트할 수 있다. 건초 더미에서 바늘을 찾는 것이 아니라, 대리석 원석에서 조각을 찾는 식이다. 미켈란젤로에서 '제미나이' 'GPT-4' 'GPT-4o' '클로드'의 다양한 변형을 포함해 10개의 프론티어 LLM을 최대 100만개의 토큰 컨텍스트에 대한 컨텍스트에 대해 평가했다. 그 결과, 제미나이는 MRCR에서, GPT 시리즈는 잠재 리스트에서, 클로드 3.5 소네트은 IDK에서 가장 높은 점수를 받았다. 하지만 모든 모델은 추론 작업의 복잡성이 증가함에 따라 성능이 크게 떨어지는 경향을 보였다. 연구진은 \"이는 매우 긴 컨텍스트 창을 가지고 있더라도 현재 LLM들이 대량의 정보를 추론하는 능력에서 여전히 개선의 여지가 있음을 시사한다\"라고 다. 박찬 기자 cpark@aitimes.com"
}