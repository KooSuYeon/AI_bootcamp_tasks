{
    "title": "국내 AI 기업들 \"라마 3, 성능 좋아졌지만 한국어는 아직 부족\"",
    "created_at": "2024.04.24 18:05",
    "content": "국내 주요 인공지능(AI) 기업들이 메타의 '라마 3'에 대한 인상을 내놓았다. 라마 2보다 전반적인 성능이 좋아진 것은 확실하지만, 한국어 능력은 여전히 아쉽다는 평가다. 메타는 19일 라마 3 시리즈 중 매개변수 80억개(8B)와 700억개(70B)의 소형 버전을 공개했다. 라마 3는 사전 훈련과 미세조정 과정을 고도화, 성능이 대폭 향상됐다고 밝혔다. 15조개 이상의 토큰을 동원, 학습량이 라마 2 대비 7배 이상 많으며 코드량은 4배 더 많다고 강조했다. 벤치마크에서는 구글의 '젬마'나 '제미나이 프로 1.5', 미스트랄 AI의 '미스트랄 7B', 엔트로픽의 '클로드 3 소네트'와 같은 모델들을 능가한다고 주장했다. 상당수 국내 AI 기업들은 라마 3 출시 직후부터 테스트에 들어간 것으로 알려졌다. 물론 본격적인 테스트를 마친 것이 아니라, 초반 인상에 불과하다는 의견이 많았다. 대부분은 라마 2보다 성능이 개선됐다고 입을 모았다. 그리고 가장 먼저 한국어 능력을 테스트해본 곳이 많았다. 이 점에 대해서는 만족도가 높지 않았다. 가장 좋은 평을 내놓은 곳은 글쓰기에 특화한 뤼튼테크놀로지스다. 김재민 LM옵스 리드는 \"라마 3는 영어 타깃으로만 만들어지긴 했으나, 커뮤니티 등에서 비공식적으로 돌아다니는 KMMLU와 같은 한국어 벤치마크에 대해서 나쁘지 않은 성능을 보여준다\"라며 \"실제 '챗 인스트럭트' 모델 사용 시 약간의 프롬프팅만으로 간단한 한국어 채팅은 가능하다\"라고 밝혔다. 또 \"특히 이번에는 실제 기업이 사용하는 13B에 못 미치는 8B 모델이 기존 라마 2 13B의 성능을 뛰어 넘는다\"라며 \"충분히 현장 투입을 고려할 수 있을 정도\"라고 전했다. 이어 \"라마 3의 설계는 사용자의 질문에 윤리적인 답변을 제공하는 데 특화됐다고 하는데, AI 기술을 활용한 제품과 서비스가 인간의 복지와 사회적 가치를 증진시키는 방향으로 발전해야 한다는 원칙에 부합한다고 본다\"라고 덧붙였다. 반면 신기빈 올거나이즈 CAIO는 “8B 모델만 테스트해봤다”라며 “성능이 좋은데, 한국어 이해도는 아직 떨어지는 느낌\"이라고 밝혔다. 또 \"정말 빠른 시간 안에 한국어 파인튜닝한 라마3 기반의 모델들이 쏟아져 나오고 있다\"라며 \"라마 3를 기업 고객을 위해 사용할 수 있을지 AI팀원들과 함께 더 자세히 들여다볼 예정”이라고 전했다. 페르소나AI도 비슷한 평을 남겼다. “8B 모델은 모든 면에서 기존의 성능을 뛰어넘었다고 생각하며, 70B 모델은 상용 API보다 좋다고 느꼈다'라며 \"다만 한국어 성능에 있어서는 아직 개선할 부분이 많다”라는 말이다. 최근 LLM 기업으로 전환을 선언한 파수는 \"현재 아직 라마 3 테스트 중에 있으며, 한국어를 떠나 언어 능력이 매우 뛰어난 것은 확실하다”라고 말했다. 실제로 라마 3는 미국의 인간 선호도 평가 사이트인 '챗봇 아레나'에서는 기존 모델보다 좋은 평가를 받고 있다. 한 LLM 전문 기업은 라마 3 성능보다는 규모에 집중했다. \"결국 파운데이션 모델은 점점 규모를 키우는 양상으로 치닫는 것 같다\"라며 \"이에 따라 모델을 가져다가 제 3의 서비스나 미세조정 모델을 만드는 기업들이 비용 효율적으로 잘 대처해야할 것으로 보인다\"라는 내용이다. 또 “한국어 관련해서 많이 부족한 부분이 있지만, 라마 2보다 확실히 좋아진건 사실\"이라고 말했다. S2W는 주로 한국어 성능, 그 중에서도 코드 생성 능력에 대해서 테스트를 해봤다며 “아직까지는 한국어의 유창성은 조금 아쉽다\"라고 전했다. 다만 사용자 지시를 잘 이해하지 못한 경우 추가적인 질문을 통해서 정보를 얻는 로직을 강화해 보완한 것으로 보인다고 분석했다. 반면, 예상보다 성능 향상이 체감되지 않는다는 곳도 적지 않았다. 셀렉트스타는 \"단기간 사용한 결과라 단정할 수는 없지만, 부정확하거나 디테일이 부족한 현상을 일부 보이기도 했다\"라며 \"다만, 라마 2에 비해서는 무해성(Harmless), 정보정확성(Honesty), 도움적정성(Helpfulness) 등이 개선된 것으로 보인다\"라고 밝혔다. 자세한 검증을 위해 벤치마크 데이터셋 '코낫(KorNAT)'을 활용한 벤치마크 테스트도 계획 중이라고 덧붙였다. 또 한 에듀테크는 메타가 성능을 높이는 데 주력했다고 강조한 '지시 미세조정(insturction tuning)'이 한글로 되어 있지 않아, 소규모 업체는 사용하기 어렵다고 지적했다. 지시 미세조정에 들어가는 하드웨어 리소스와 데이터량이 많기 때문이다. 서비스에 라마 3 도입을 염두에 두고 테스트 중인 곳도 있다. 그리드원은 최근 출시한 국내 첫 AI 에이전트 ‘고두(Go;Do)'에 적용을 검토 중이라고 밝혔다. LG CNS와 일부 기업은 성능 평가보다는 의의에 중점을 뒀다. \"오픈 소스로  향후 활용도가 높아질 것으로 기대하고 있다”, “오픈 소스 기반의 LLM의 기술적 진보는 전체 LLM 생태계의 발전에 긍정적인 영향이 있을 것으로 생각한다” 등의 의견을 냈다. 최근 국내에 호랑이 리더보드를 출시한 W&B의 케이 카마타 엔지니어도 비슷한 의견을 내놓았다. \"현재 라마 3만의 출력보다 그 응용 결과를 살펴보는 것이 진정한 잠재력을 보는 데 중요하다고 생각한다\"라며 \"적용 사례에 관심이 있고, 그런 사례의 창출을 지원하겠다\"라고 밝혔다. 한편 해외 커뮤니티는 분위기가 국내와 좀 다르다. 가장 중요한 자국어 문제가 없다보니, 컨텍스트 창의 크기와 전문가 혼합(MoE) 방식이 아닌 관계로 비용이 많이 든다는 것을 지적하고 있다. 한편 메타는 라마 3 소형 버전을 출시하며 \"향후 멀티모달, 다국어 대화, 더 길어진 컨텍스트 창 등 더 강력한 기능을 갖춘 여러 버전의 새로운 라마 3 버전들이 출시할 것\"이라고 밝혔다. 장세민 기자 semim99@aitimes.com 박수빈 기자 sbin08@aitimes.com"
}