{
    "title": "\"GPU 구하기 쉬워졌다...3개월 전과는 달라\"",
    "created_at": "2024.02.26 18:28",
    "content": "한때는 웃돈을 줘도 구하기 어렵다던 엔비디아 GPU 수급이 용이해졌다는 소식이다. 디 인포메이션은 23일(현지시간) 젠슨 황 엔비디아 CEO가 인공지능(AI) 칩 ‘H100’ GPU의 공급이 “향상되고 있다”라고 말한 것과 관련, 시장에서 GPU 수급이 나아졌다고 보도했다. 이에 따르면 AI 칩을 사용하는 6개 이상의 회사가 엔비디아의 최첨단 AI 칩 ‘H100’ GPU를 클라우드 공급업체로부터 임대하는 것이 3개월 전에 비해 더 쉬워졌다고 밝혔다. AWS도 클라우드 내의 H100 서버 가격은 떨어지지 않았지만, 지난해에 비해 임대하기가 더 쉽다고 말했다. 실제로 AWS와 구글 클라우드에서 서버를 임대하는 대규모 소비자 회사는 지난해 말까지만 해도 엔비디아 칩을 사용하는데 몇주가 걸렸지만, 최근에는 대기 시간이 길지 않다고 밝혔다. GPU 생산량이 늘어난 것 외에도 다양한 요인으로 인해 수요가 감소할 수 있다고 전했다. 클라우드 제공업체는 고객이 장기 계약이나 수요에 따라 GPU를 임대하는 대신, 한번에 며칠 또는 몇주 단위로 GPU 임대할 수 있는 서비스를 도입해 칩의 회전율을 높였다. 또 GPU를 임대하는 회사는 칩 사용이 익숙해짐에 따라 실제로 필요한 최적의 GPU 수만 임대할 수 있게 됐다는 분석이다. 결과적으로 몇달 전보다 더 작은 GPU 클러스터를 임대하기 시작했다. AI 칩 수요가 학습용에서 추론용으로 이동하고 있다는 점도 주목할 만하다. 월스트리트저널(WSJ)에 따르면 지난해 매출 470억달러를 돌파한 엔비디아 데이터센터 사업 중 40% 이상이 AI 학습이 아니라 추론 작업을 수행하는 시스템 배치에서 발생했다. 추론용 반도체는 엔비디아를 AI 붐의 선두 주자로 이끈 학습용 반도체보다는 덜 강력하며 저렴하다. 추론 작업이 학습 AI 모델에 새로운 정보를 처리하고, 응답하도록 요청하는 가벼운 일이기 때문이다. 추론 작업을 수행할 때는 엔비디아의 고가 최첨단 H100 AI 칩 사용 여부는 그다지 중요하지 않다는 설명이다. 스위스 금융그룹 UBS 애널리스트들은 올해 초 AI 반도체 수요의 90%가 학습에서 비롯된 것으로 추정했으며, 추론이 내년까지 시장의 20%를 차지할 것으로 내다봤다. 추론용 칩의 중요성이 커짐에 따라 인텔이나 AMD와 같은 엔비디아의 주요 경쟁자들뿐 아니라 많은 AI 칩 스타트업들도 추론용 반도체 개발에 집중하고 있다. 메타·마이크로소프트(MS)·구글·아마존 같은 대형 기술기업들도 이러한 변화를 인식하고 추론용 반도체 개발을 서두르고 있다. 추론을 위해 GPU에 액세스하는 것이 많은 개발자에게 훨씬 쉬워졌지만, 자체 대형언어모델(LLM)을 훈련하려는 개발자는 여전히 공급에 어려움을 겪고 있다. LLM과 기업용 AI 도구를 개발하는 라이터의 와심 알쉬크 CFO는 “LLM을 훈련하려면 개발자가 최대 120개의 개별 GPU를 포함할 수 있는 GPU 클러스터에 액세스해야 한다”라며 “이러한 대규모 GPU 클러스터에 액세스하는 것은 쉬운 일이 아니다”라고 말했다. 실제로 엔비디아는 라이터 경영진에게 “필요한 칩의 일부만 제공하는 데 3~4개월이 걸릴 것”이라고 전했다. 다만 AI 칩 시장 점유율이 80%를 넘는 엔비디아에 대한 심각한 도전은 아직 없고, AI 시스템 학습에 사용되는 엔비디아 칩은 당분간 높은 수요를 유지할 것이라는 예상이다. 이에 팻 겔싱어 인텔 CEO는 “AI 칩에 대한 수요가 둔화될 것 같지는 않지만, 기업들이 칩에 지출하는 금액에 대해 좀 더 신중해질 것”이라며 “수백억달러를 주요 데이터센터에 투자하고 이를 지원하는 경제 모델을 만들기는 쉽지 않을 것”이라고 예상했다. 박찬 기자 cpark@aitimes.com"
}