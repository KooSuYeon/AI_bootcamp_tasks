{
    "title": "구글, '초인공지능' 구분 기준 공개...\"챗GPT는 레벨 1\"",
    "created_at": "2023.11.21 18:15",
    "content": "구글이 인공일반지능(AGI)인지를 측정하는 기준을 내놓았다. 의식이나 이해와 같은 추상적 개념보다 실제적인 능력을 기준으로 삼아야 한다는 내용이다. 그리고 0~6 레벨 중 '레벨 2'를 넘는 현존 AI 모델은 없다는 결론을 내렸다. 벤처비트는 최근 구글 딥마인드 연구진이 성능과 일반성, 자율성 수준 등을 기준으로 AGI 여부를 구분할 수 있는 프레임 워크를 공개했다고 보도했다. 이에 따르면 AGI에 대해서는 여러 의견이 등장하고 있다. 10년 내로 등장할 것이라는 예측부터 이미 현존하는 대형언어모델(LLM)이 AGI에 해당한다는 의견, 절대 인간과 같은 의식을 가질 수 없다는 의견 등이 뒤섞여 있다. 연구진은 가장 먼저 AGI의 정의에 집중했다. 이를 설명하기 위해 가장 흔하게 사용하는 ▲튜링 테스트(기계와 사람을 비교하는 방식) ▲커피 테스트(커피 머신을 찾아 커피를 투입하고 물을 넣고 머그잔을 찾아 버튼을 누르는 복잡한 과정 테스트) ▲대학 시험 ▲취업 시험 ▲이케아 테스트(조립식 가구 설명서를 보고 실제 조립하는 테스트) 등을 포함한 9가지 분석법이 모두 충분한 것은 아니라고 설명했다. 즉 AI가 커피 만들기에 실패하면 AGI가 아니라는 것을 입증할 수는 있어도, 이를 통과했다고 AGI라고 말할 수는 없다는 설명이다. 따라서 연구진은 더 포괄적인 프레임워크를 제공하기 위해 6가지 기준을 제안했다. 여기에는 ▲AGI의 측정은 인간과 같은 이해, 의식, 감각과 같은 특성보다 '능력'에 초점을 맞춰야 한다 ▲AGI 측정은 일반성과 성능을 모두 고려해야 한다. 즉  AGI 시스템은 광범위한 작업을 수행할 수 있을 뿐만 아니라 실행 면에서도 뛰어나야 한다 ▲AGI에는 인지 및 메타인지 작업이 필요하지만, 구체화 및 물리적 작업이 AGI의 전제 조건으로 간주해는 안 된다 등이 담겼다. 또 ▲법적, 사회적 고려 사항은 물론 잠재적인 윤리적 및 안전 문제와 같은 비기술적 장애물로 능력 발휘를 저하하는 것을 막기 위해 배포를 고려하지 않은 능력치를 측정해야 한다 ▲AGI 지표는 사람들이 가치 있게 여기는 실제 작업, 즉 '생태학적으로 타당한' 작업 수행에 초점을 맞춰야 한다고 밝혔다 마지막으로 ▲이를 통해 정해진 AGI의 수준을 정하는 것은 최종 결론이 아닌, 다양한 수준으로 확대하는 '과정'으로 이해해야 한다는 것이다. 연구진은 이를 통해 '레벨 0(AI가 아닌 상태)'부터 '레벨 5(인간 능력을 모두 넘는 초인공지능)'까지 6단계로 AI를 구분했으며, 단계별로 특정 작업에서만 탁월한 '좁은 의미의 사례(Narrow)'와 전반적인 능력을 갖춘 '범용적인 예(General)'를 구분했다. 모든 조건을 충족하는 레벨 5 모델, 즉 AGI 또는 ASI(초인공지능)은 현존하지 않는다고 밝혔다. 특정 부분에서 AGI의 요건을 충족하는 모델로는 ▲ 단백질 생성 AI인 '알파폴드' ▲알파고의 후속 모델로 바둑은 물론 체스와 일본 장기(쇼기)까지 학습한 '알파제로' ▲컴퓨터 체스대회를 휩쓴 세계에서 가장 강력한 체스 엔진 '스톡피시' 등을 예로 들었다. 또 '챗GPT'와 '바드' '라마 2' 등 현재 최고 성능을 보이는 대형언어모델(LLM)은 레벨 1, 즉 '유망한(Emerging)' 단계로 봤다.  이는 '능숙하지 않은 인간과 비슷하거나 조금 나은 수준'을 뜻한다. 다음 단계인 레벨 2 '능숙한(Competent)'부터는 아직 단 하나도 해당하지 않는다고 정의했다. 연구원들은 이런 매트릭스가 실제 수준과 일치하지 않을 수 있다고 지적했다. \"이론적인 수준보다 실제로는 낮은 레벨이 나올 수 있는데, 이는 현재 프롬프트 스킬로는 실제 성능을 끌어내기 어렵기 때문\"이라고 설명했다. 딥마인드는 이번 AGI 벤치마크가 하나의 기준으로 유용하다는 점을 강조하면서도 모든 과정을 포함하는 것은 불가능하다는 점을 인정했다. “따라서 AGI 벤치마크는 '살아있는 벤치마크'가 되어야 한다\"라며 \"새로운 작업을 더 하고 합의하기 위한 프레임워크가 포함돼야 한다\"라고 밝혔다. 또 우리가 AGI를 위험 요소로 보는 것은 '자율성'에 달렸다고 지적했다. AI가 인간 작업을 보조하는 낮은 자율성 수준에서도 인간의 숙련도를 떨어뜨리고 현 산업 구조를 붕괴할 위험이 있다고 지적했다. 자율성이 증가하면 콘텐츠 조작, 광범위한 사회적 혼란 등 심각한 피해를 일으킬 수 있다고 밝혔다. 이에 대해 벤처비트는 \"AGI와 관련된 다른 기준과 마찬가지로 딥마인드의 프레임워크에도 AI를 비방하는 요소와 자체적인 단점이 있다\"라며 \"이는 AGI 개발을 향한 과정에서 우리가 어디에 서 있는지를 측정하기 위한 포괄적인 가이드라인이라는 점에서 의미 있다\"라고 평했다. 임대준 기자 ydj@aitimes.com"
}