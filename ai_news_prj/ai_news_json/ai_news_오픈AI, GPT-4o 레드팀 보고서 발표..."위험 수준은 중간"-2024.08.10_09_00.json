{
    "title": "오픈AI, GPT-4o 레드팀 보고서 발표...\"위험 수준은 중간\"",
    "created_at": "2024.08.10 09:00",
    "content": "오픈AI가 5월에 공개된 최첨단 멀티모달 모델 'GPT-4o'에 대한 안전성 평가 결과를  발표했다. 자체 평가 프레임워크에 따라 GPT-4o의 위험 수준을 ‘중간’으로 평가했다. 더 버지는 8일(현지시간) 오픈AI가 GPT-4o에 대한 시스템 카드를 공유했다고 보도했다. 시스템 카드와 함께 GPT-4o에 대한 안전성 평가를 제공하는 '준비 프레임워크(Preparedness Framework)' 스코어카드를 공개했으며, 여러 범주에 걸친 모델의 기능, 한계 및 안전성 평가에 대한 세부 정보를 공유했다. 모델 시스템 카드는 오픈AI가 모델을 출시하기 전에 외부 레드팀이나 보안 전문가 그룹을 사용하여 해당 모델에 대해 수행한 안전 조치와 위험성 평가를 설명한 연구 보고서다. 'GPT-4' 'GPT-4V' 및 '달리 3'도 비슷한 방식으로 테스트됐으며, 시스템 카드가 공개됐다. 오픈AI는 GPT-4o의 오디오 기능에 초점을 맞춰 더 많은 안전 작업을 수행했다. 평가된 위험에는 허가받지 않은 음성 생성, 화자 식별, 근거 없는 추론, 저작권이 있는 오디오 재생산, 허용되지 않는 오디오 콘텐츠 생성, 에로틱하고 폭력적인 발언 생성가 포함된다. 이러한 평가 결과에 따라 오픈AI는 모델 및 시스템 수준 모두에서 보호 조치를 구현했다. GPT-4o는 준비 프레임워크 범주 중 사이버 보안, 생물학적 위협, 모델 자율성에서 ‘낮음’ 위험 점수를 받았고, 설득에서만 ‘중간’ 위험 점수를 받았다. 오픈AI의 준비 프레임워크에 따르면, ‘중간’ 이하의 점수를 받은 모델만 배포할 수 있으며, ‘높음’ 이하의 점수를 받은 모델만 추가로 개발할 수 있다. 이번 평가를 위해 모델 평가 및 위협 연구(METR)와 아폴로 리서치(Apollo Research) 등 100명 이상의 외부 레드팀과 협력했다. 레드팀은 모델의 잠재적 위험을 평가하고, 완화책에 대한 스트레스 테스트를 실시한다. 오픈AI는 \"우리는 GPT-4o 개발 및 배포 프로세스 전반에 걸쳐 다양한 안전 측정 및 완화책을 구현했다”라며 “반복적 배포 프로세스의 일환으로 진화하는 환경에 따라 완화책을 계속 모니터링하고 업데이트할 것”이라고 밝혔다. GPT-4o의 시스템 카드는 PDF 버전으로도 다운로드할 수 있다. 박찬 기자 cpark@aitimes.com"
}