{
    "title": "세레브라스, 새 AI 추론 서비스 출시...\"엔비디아보다 20배 빠르고 100배 저렴\"",
    "created_at": "2024.08.28 18:00",
    "content": "인공지능(AI) 반도체 스타트업 세레브라스가 세계에서 가장 빠르고 저렴한 AI 추론 서비스를 출시했다. '챗GPT'와 같은 생성 AI 애플리케이션이 대중화되며 AI 추론과 관련한 수요가 기하급수적으로 증가할 것으로 판단, 자신들의 장점을 내세워 엔비디아에 도전장을 내민 것이다. 로이터는 27일(현지시간) 세레브라스가 엔비디아보다 최대 20배 빠른 AI 추론 서비스 '세레브라스 인퍼런스(Cerebras Inference)'를 출시했다고 보도했다. AI 추론(인퍼런스)은 이미 훈련된 AI 모델을 작동해 챗봇의 답변과 다양한 작업 해결 등의 출력을 얻는 프로세스다. 세레브라스는 “추론은 클라우드 컴퓨팅에서 전체 AI 관련 워크로드의 40%를 차지하는 등 AI 업계에서 가장 빠르게 성장하는 부문”이라며 “고속 추론 서비스가 AI 산업의 전환점이 될 것”이라고 말했다. 세레브라스 인퍼런스는 대형언어모델(LLM) '라마 3.1 8B'에서 초당 1800 토큰, '라마 3.1 70B'에서 초당 450 토큰을 처리한다. 이는 마이크로소프트(MS) 애저를 포함한 하이퍼스케일 클라우드에서 제공되는 엔비디아 GPU 기반 AI 추론 서비스보다 약 20배 빠른 속도다. 획기적인 성능 향상뿐만 아니라, 가격 경쟁력도 갖췄다. 예를 들어 100만 토큰 당 고작 10센트의 가격으로 이용할 수 있어, 기존 GPU 클라우드 대비 최대 100배 높은 가격 대비 성능을 제공한다. 세레브라스는 20배 빠른 추론 속도를 통해 AI 앱 개발자가 정확도나 비용 손실 없이 차세대 AI 애플리케이션을 구축할 수 있다고 설명했다. 이 혁신적인 가성비는 세레브라스 'CS-3' 시스템과 웨이퍼 스케일 엔진 3(WSE-3) AI 프로세서를 통해 가능했다. 접시만큼 큰 세레브라스의 WSE-3 칩은 초당 1000개의 토큰을 처리할 수 있는데, 이는 광대역 인터넷과 맞먹는 수준이다. 앤드류 펠드만 세레브라스 CEO는 \"WSE-3 칩은 엔비디아 GPU보다 훨씬 나은 성능을 제공한다\"라고 주장했다. 특히 CS-3는 엔비디아 'H100'보다 메모리 대역폭이 7000배 넓어 생성 AI의 메모리 대역폭 문제를 해결했다. 세레브라스 인퍼런스는 무료 티어, 개발자 티어, 엔터프라이즈 티어 등 세가지 형태로 제공된다. 무료 티어는 로그인하는 모든 사용자에게 무료 API 액세스와 충분한 사용량 제한을 제공한다. 개발자 티어는 유연한 서버리스 배포를 위해 설계됐으며, 라마 3.1 8B 및 70B 모델의 경우 100만 토큰 당 각각 10센트, 60센트의 가격으로 API 엔드포인트를 제공한다. 엔터프라이즈 티어는 미세조정된 모델, 맞춤형 서비스 수준 계약(SLA), 전담 지원을 제공한다. 세레브라스는 클라우드를 통해 여러 유형의 추론 서비스를 제공하지만, 자체 데이터 센터를 운영하는 것을 선호하는 기업에게는 AI 시스템을 판매할 계획이다. 현재 AI 시장은 엔비디아가 장악하고 있지만, 세레브라스와 그로크 같은 기업들의 등장은 업계 역학 변화를 예고한다. 특히 더 빠르고 비용 효율적인 AI 추론 서비스에 대한 수요가 증가하는 추세다. 박찬 기자 cpark@aitimes.com"
}