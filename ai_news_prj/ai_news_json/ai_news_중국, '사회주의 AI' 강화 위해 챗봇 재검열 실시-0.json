{
    "title": "중국, '사회주의 AI' 강화 위해 챗봇 재검열 실시",
    "created_at": "0",
    "content": "중국이 최근 인공지능(AI) 챗봇의 검열을 강화하는 것으로 알려졌다. '사회주의 AI'를 강화하기 위해 기존 정부 허가를 받은 챗봇에도 재검열을 강요한다고 전해졌다. 파이낸셜 타임스는 17일(현지시간) 중국 사이버공간 관리국(CAC)이 바이트댄스와 알리바바, 문샷, 01.AI를 포함한 대형 기술 기업과 AI 스타트업에 AI 모델에 대한 의무적인 정부 검토에 참여하도록 강요했다고 보도했다. 이에 따르면 이번 검열은 이들 기업의 대형언어모델(LLM)을 테스트, '핵심 사회주의 가치를 구현하는지를 확인하는 작업이다. LLM이 수많은 질문에 답한 내용을 검토하는 것으로, 많은 부분은 중국의 정치적 민감성과 시진핑 주석에 관한 내용이다. 이 작업은 전국의 CAC 지역 지부 소속 공무원들에 의해 수행되고 있으며, 여기에는 모델의 훈련 데이터와 안전 프로세스에 대한 검토도 포함됐다. 중국에서는 AI 챗봇을 서비스하기 위해 정부으 검열을 먼저 거쳐야 한다. 바이트댄스나 알리바바 등은 이미 지난해 정부의 호가를 받고 챗봇을 서비스 중이다. 그럼에도 최근 검열을 강호하며 재검사를 받고 있는 셈이다. 익명을 요구한 항저우 소재 AI 회사의 한 직원은 \"CAC의 특별팀이 사무실을 찾아 회의실에서 감사를 진행했다\"라고 밝혔다. 그는 \"우리는 첫번째 시도에 통과하지 못했다\"라며 \"이유를 명확하게 찾지 못해 고생했다. 두번째 시도에는 통과했지만, 전체 과정이 몇 달이나 걸렸다\"라고 설명했다. 정부의 까다로운 승인 절차로 인해 중국 AI 기업들은 LLM을 통제하는 방법에 대해 빠른 학습이 필요했다는 증언이다. 많은 관계자는 LLM이 방대한 양의 영어 콘텐츠를 학습하기 때문에, 이 작업이 어렵고 복잡하다고 말했다. 베이징의 한 유명 AI 스타트업 직원은 \"우리의 기본 모델은 매우 제한이 없는 답을 출력하기 때문에 보안 필터링이 매우 중요하다\"라고 전했다. 필터링 작업은 훈련 데이터에서 문제가 있는 정보를 걸러내고 민감한 키워드 데이터베이스를 구축하는 것으로 시작된다. 2월에 발표된 중국의 AI 기업 운영 지침에 따르면 \"국가 권력 전복을 선동하거나 국가적 통일을 훼손하는 것과 같은 핵심 사회주의적 가치를 위반하는\" 수천개의 민감한 키워드와 질문을 수집해야 한다. 또 이는 매주 업데이트돼야 한다. 그 결과로 중국 AI 챗봇 사용자는 천안문 사태나 시진핑 주석의 곰돌이 푸 밈 등에 대한 질문에 답을 받지 못한다. 바이두의 어니 챗봇은 \"다른 질문을 시도해 보세요\"라고 말하고, 알리바바의 퉁이첸원은 \"아직 이 질문에 대답하는 방법을 배우지 못했습니다. 더 나은 서비스를 제공하기 위해 계속 공부하겠습니다\"라고 답한다. 반면 CAC는 지난 5월 '시진핑 신시대 중국 특색 사회주의 사상'이 핵심 콘텐츠로 담겨있는 AI 챗봇을 출시한 바 있다. 이 모델은 시진핑 주석이 직접 쓴 것으로 알려진 12권 이상의 책 등으로 훈련됐다. 하지만 중국 관리들은 모든 정치적 주제를 회피하는 AI를 만드는 것도 피하고 싶어 하는 것으로 알려졌다. 테스트에 참가한 한 직원에 따르면 LLM이 거부할 수 있는 질문 수에 제한을 도입했다. 2월에 공개된 중국의 표준에는 LLM이 질문의 5% 이상을 거부해서는 안 된다고 명시됐다. 상하이에 있는 인터넷 회사의 개발자는 \"잠재적인 문제를 피하기 위해 일부 LLM은 시진핑 주석과 관련된 주제에 대한 답변 자체를 모두 금지했다\"라고 전했다. 그 예로 스타트업 문샷의 '키미'를 꼽았는데, 이 챗봇은 시 주석에 관련된 대부분의 질문에 답변을 거부한다. 파이낸셜 타임스는 유명 스타트업 01.AI가 만든 챗봇에 시 주석 관련 질문을 던졌는데, 처음에는 \"시진핑의 정책은 언론의 자유와 인권을 더욱 제한하고 시민 사회를 억압했다\"라는 답변을 내놓았다고 전했다. 그러나 얼마 지나지 않아 답변은 사라지고 \"죄송합니다. 원하시는 정보를 제공해 드릴 수 없습니다\"라는 내용으로 변했다. 리 후안이라는 개발자는 \"LLM이 생성하는 텍스트를 제어하는 ​​것은 매우 어렵기 때문에, 다른 계층을 구축하는 방법을 사용한다\"라고 밝혔다. 즉 시스템이 민감한 사안에 대해 쿼리를 받으면, 별도의 안전한 모델로 교체 연결한다는 설명이다. 이런 검열 기술은 바이트댄스가 가장 능숙하다는 평이다. 푸단대학교의 한 연구실에서 사회주의 가치에 대한 어려운 질문을 한 결과, 바이트댄스의 두바오 모델은 66.4%의 안전 준수율로 LLM 중 최고 순위를 차지했다. 이 테스트에서 오픈AI의 'GPT-4o'는 고작 7.1%를 기록했다. '중국 방화벽의 아버지'로 알려진 판빈싱은 최근 베이징에서 열린 기술 컨퍼런스에서 중국의 AI 기업에서 채택되기를 바라는 LLM 안전 프로토콜 시스템을 개발하고 있다고 말했다. 그는 \"대중을 대상으로 하는 대규모 예측 모델은 안전 신고 이상의 것이 필요하다\"라며 \"중국은 자체적인 기술적 경로가 필요하다\"라고 말했다. 임대준 기자 ydj@aitimes.com"
}