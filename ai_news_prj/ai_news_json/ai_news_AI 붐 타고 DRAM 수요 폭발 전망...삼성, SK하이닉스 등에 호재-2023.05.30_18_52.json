{
    "title": "AI 붐 타고 DRAM 수요 폭발 전망...삼성, SK하이닉스 등에 호재",
    "created_at": "2023.05.30 18:52",
    "content": "인공지능(AI) 붐이 이어지면서 DRAM 수요가 폭발적으로 늘어나는 등 메모리 반도체 기업들도 호황을 누릴 것이라는 전망이 나왔다. AI용 반도체 수요가 더 가파르게 증가할 것으로 분석되면서 삼성전자와 SK하이닉스 등 국내 반도체 기업에도 긍정적인 메시지로 작용할 것을 보인다. AI 서비스를 위한 데이터센터에는 이들 기업이 생산하는 메모리 반도체도 대거 탑재된다. 월스트리트저널은 29일(현지시간) 지난 분기에 시장 전망치를 10% 가량 웃돈 71억9000만달러(약 10조원) 매출을 기록한 엔비디아가 2분기에는 당초 예상했던 시장 전망치를 50% 이상 뛰어넘는 110억달러(약 14조5827억원) 안팎의 매출을 기록할 것으로 예상, AI용 반도체 생산을 늘리고 있다고 보도했다. 콜레트 크레스 엔비디아 CFO는 \"AI 수요 증가로 데이터센터 부문의 실적을 향후 몇 분기 이후까지 더 내다볼 수 있게 됐다\"면서 \"하반기에는 훨씬 더 많은 공급을 할 수 있는 만큼 실적도 크게 개선될 것\"이라고 자신했다. 결론부터 말하면 엔비디아와 메모리 업체는 윈윈 관계다. 모든 칩은 기본적으로 혼자 돌아가지 않는다. 메모리가 같이 있어야 한다. GPU가 연산을 동시에 빨리할 수 있도록 도와주는 고사양 메모리가 있어야 한다는 뜻이다. 챗GPT 같은 AI 분야 데이터 처리에 쓰이는 GPU에 고대역폭 메모리(HBM)를 비롯한 DRAM이 대거 탑재되기 때문이다. AI가 학습을 잘하려면 데이터 처리와 저장 기능이 중요하다. 이 역할은 HBM이 담당한다. HBM은 DRAM 여러 개를 수직으로 연결해 기존 DRAM보다 데이터 처리 속도를 대폭 끌어올린 제품이다. AI가 고도화될수록 더 많은 GPU가 필요하고, 이에 따라 HBM 수요도 늘어나 선순환 구조를 예상할 수 있다. 현재 전 세계에서 HBM을 생산하는 곳은 삼성전자와 SK하이닉스 밖에 없다. 특히 SK하이닉스는 고대역폭 DRAM 제품 HBM3를 양산해 엔비디아에 납품한다. HBM3는 엔비디아의 H100 GPU에 탑재돼 첨단기술 분야에 쓰인다. 삼성전자도 메모리 반도체와 AI 프로세서를 하나로 결합한 '지능형 메모리(HBM-PIM)’, 고용량 AI 모델을 위한 CXL DRAM 메모리 기술 등을 잇달아 내놓았다. 삼성과 SK하이닉스로서는 후발주자의 추격에 맞서 고부가가치 제품으로 ‘포트폴리오 조정’에 힘써야 한다. HBM 같은 고마진 제품의 매출 비중이 더 커져야 초격차가 가능하다. 정리하면 GPU 업체가 성장하면 메모리 업체도 동반 성장할 수 있다. AI는 GPU와 메모리가 함께 있어야만 확산될 수 있다는 뜻이다. 박찬 기자 cpark@aitimes.com"
}