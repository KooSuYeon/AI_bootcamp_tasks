{
    "title": "엔비디아, 오픈AI·앤트로픽 능가하는 LLM 공개...모델 중심 생태계 구축하나",
    "created_at": "2024.10.18 18:05",
    "content": "이달 초 대형멀티모달모델(LMM)을 공개하며 오픈AI 등과 모델 경쟁을 선언한 엔비디아가 이번에는 대형언어모델(LLM)을 내놓았다. 이번에는 벤치마크에서 오픈AI의 'GPT-4o'와 앤트로픽의 '클로드 3.5 소네트'를 제치고 최고 점수를 기록했다고 밝혔다. 벤처비트는 16일(현지시간) 엔비디아가 별 홍보 없이허깅페이스를 통해 '라마 3.1-네모트론-70B-인스트럭트(Llama-3.1-Nemotron-70B-Instruct)'를 출시했다고 보도했다. 이 모델은엔비디아 전용 플랫폼에서 무료로 사용해 볼 수 있다. 엔비디아는 모델 개발에 인간 피드백을 통한 강화 학습(RLHF)과 고품질 데이터셋을 사용, 라마 3.1을 미세조정했다고 밝혔다. 추가 프롬프트나 특수 토큰 없이 복잡한 쿼리를 처리할 수 있는 능력도 강조했다. 선보인 데모에서는 '스트로베리(strawberry)에는 r이 몇개 있나요'라는 질문에 정확하게 답했다. 특히 인간 선호도 평가인 '아레나 하드벤치'에서 85.0을 기록했으며, '알파카이벨 2 LC(AlpacaEval 2 LC)'에서 57.6, 'GPT-4- 터보 MT-벤치'에서 8.98 등 주요 평가에서 오픈AI의 GPT-4o와 앤트로픽의 클로드 3.5 소네트를 제치고 최고 점수를 기록했다. 이대로라면 현존 최강의 성능을 갖춘 모델이라는 말이다. 이에 앞서 지난 1일에는 'NVLM-D-72B'이라는 엔비디아의 오픈 소스 LMM이 화제가 됐다. 이 모델 역시 대부분 벤치마크에서 GPT-4o나 클로드 3.5 소네트, '제미나이 1.5 프로', '라마 3-V 405B' 등과 대등하거나 높은 성능을 보인 바 있다. 이 때문에 엔비디아가 본격적으로 프론티어 모델 경쟁에 뛰어드는 것이 아니냐는 추측도 나왔다. 물론 이번에 출시한 모델은 자체 개발이 아니라, 라마 3.1을 베이스로 성능을 개선한 모델이다. 하지만 엔비디아의 인프라에 최적화된 모델을 무료로 제공하면, 이는 CUDA를 통해 생태계를 구축한 것과 비슷한 효과를 낼 수 있다는 분석이다. 특히, 엔비디아는 성능과 함께 비용 효율적인 면도 강조하고 있다. 임대준 기자 ydj@aitimes.com"
}