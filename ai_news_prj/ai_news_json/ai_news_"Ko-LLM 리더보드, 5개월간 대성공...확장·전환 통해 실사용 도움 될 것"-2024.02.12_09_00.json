{
    "title": "\"Ko-LLM 리더보드, 5개월간 대성공...확장·전환 통해 실사용 도움 될 것\"",
    "created_at": "2024.02.12 09:00",
    "content": "'오픈 Ko-LLM 리더보드' 주최사이자 국내 대형언어모델(LLM) 대표주자로 떠오르는 업스테이지(대표 김성훈)가 '한국어 언어모델 평가 지표’의 다양화 및 고도화 필요성을 제기했다. 박찬준 업스테이지 수석연구원은 \"오픈 Ko-LLM 리더보드 오픈을 통해 한국어 LLM 평가 생태계를 구축, 개발 인재들에게 투명한 경쟁의 장을 마련하는 데 성공했다\"라며 \"이제는 다음 단계로 넘어갈 시기\"라고 8일 밝혔다. 업스테이지는 한국지능정보사회진흥원(NIA)과 협약, 지난해 9월부터 ‘오픈 Ko-LLM 리더보드’를 운영하고 있다. 박찬준 수석연구원은 리더보드 기획과 운영을 도맡은 업스테이지 기술의 주축이다. 그는 우선 리더보드 운영이 기대 이상이었다고 평가했다. 리더보드의 목적은 ‘국내 LLM 생태계 조성’이다. 실제 Ko-LLM 리더보드는 국내 개발자는 물론 관련 기업에까지 큰 영향을 미치고 있다. “리더보드 시작 당시에는 2023년 말까지 등록 모델 200개를 넘기는 것이 목표였다”라며 “현재는 오픈 6개월도 되지 않아 1000개 이상의 모델이 업로드된 상태”라고 밝혔다. 특히 ▲개인연구자 ▲기업 ▲빅테크 ▲학계 등 다양한 기술진이 모여 경쟁을 벌인다는 점이 의미 있다고 전했다. KT, 롯데정보통신, CJ올리브네트웍스, 야놀자, 메가스터디, 포티투마루, 한국과학기술원(KAIST), 고려대학교 등 굵직한 기업·기관의 합류가 눈에 띈다. 박 수석연구원은 “개인적으로는 KT의 '믿음 7B'가 1위에 올라, 오픈 소스로 모든 사람에게 사용 기회를 열었던 사례가 인상 깊다”라고 말했다. 원조 리더보드와 비교해도 괄목할 만한 성과다. 허깅페이스에 현재 4000개가 넘는 모델이 운영되고 있는데, 단기간에 국내 시장에서 한국어 모델로만 4분의 1까지 따라잡았다는 점은 상당한 의미가 있다. 이는 국내 LLM 기술력의 빠른 발전 상황을 반영하고 있다는 설명이다. 업스테이지에도 리더보드는 좋은 기회였다. 허깅페이스와 소통 창구를 마련한 것은 물론 연구 협력 관계까지 확장, 실제적인 CPU 업그레드 지원까지 받고 있다고 전했다. KT의 GPU 인프라 지원도 큰 힘이 됐다. 그만큼 리더보드 구성에 애를 썼다. 우선 \"허깅페이스 ‘오픈 LLM 리더보드’가 글로벌 영어 LLM 벤치마크로서 일정 공신력을 확보한 것처럼, 한국어 평가 지표도 성능 기준과 플랫폼을 비슷한 수준으로 재현하기 위해 노력했다\"라고 설명했다. 반면 영어 리더보드와의 차별점에도 집중했다. 허깅페이스의 경우 3년이 넘은 데이터셋을 아직 사용하고 있으며, 내용도 일반에 공개한 상태다. 하지만 한국어 리더보드는 오로지 차트 구성을 위해 모든 데이터를 새로 구축, 프라이빗하게 운영하고 있다. 데이터셋을 오픈했을 때의 이점보다 데이터 오염 최소화 및 공정한 비교평가 등 장점을 살리기 위해 ‘클로즈 셋’으로 운영하는 것이다. 박찬준 수석연구원은 \"이제부터는 성능 평가 기준(Task)과 평가 대상의 확장, 평가 방식의 전환 등을 통해 업데이트를 준비하고 있다\"라고 전했다. 먼저 평가 기준을 지적했다. 현재 Ko-LLM 리더보드는 5개의 평가지표로 구성돼 있다. ▲추론능력(ARC) ▲상식능력(HellaSwag) ▲언어이해력(MMLU) ▲환각방지능력(TruthfulQA) ▲한국어상식생석능력(KoCommonGEN-V2) 등이다. 그는 \"여기에 윤리성 평가와 팩추얼 그라운딩(Factual Grounding) 등을 추가할 필요가 있다\"라고 말했다. 팩추얼 그라운딩은 데이터를 일종의 ‘지식 그래프’처럼 활용하는 기법을 의미한다. 이외에도 업계와 학계와 의견을 수렴, 다양한 평가 지표를 갖출 것이라고 밝혔다. 평가 대상도 확장하겠다고 말했다. 궁극적인 목표는 영어와 한국어를 넘어, 다른 국가의 언어까지 범위를 확장하는 것이다. 최근 코드 데이터가 트렌드로 떠오르는 만큼 ‘코드 언어모델’을 평가하는 차트도 운영하고 싶다고 밝혔다. 평가 방식의 전환은 ‘고정관념의 타파’라고 강조했다. 기존의 관습적인 평가 방식은 실제 LLM을 적용하는 데 나타나는 정확성을 모두 반영하기에 한계가 있다는 설명이다. 첫 한계점으로는 ‘구식 데이터’를 들었다. SQUAD, KLEU 등의 기존 데이터셋은 시간이 지날수록 활용성이 저하될 수밖에 없다. 데이터는 DNA와 같이 지속 변형, 발전하는 성질을 지녔기 때문이라는 설명이다. \"리더보드가 보유한 데이터셋도 ‘고정 상태’에 머물러 있으면 현시점을 실시간으로 반영한다고 보기는 어렵다\"라며 \"하루에도 셀 수 없는 데이터가 새롭게 탄생하기 때문\"이라고 말했다. 최근에는 외부 데이터를 사용할 수 있는 리더보드도 등장하고 있지만, 이 경우에는 공정성 문제가 뒤따른다. 어쨌거나 데이터셋이 오래도록 고정된 경우에는 LLM의 성능을 정확하게 반영한다고 보기 어렵다는 지적이다. 이는 LLM을 실제 B2B나 B2C에 적용할 때 문제가 된다. 사용자나 기업으로부터 끊임없이 쌓이는 데이터에 얼마나 빠르게 대응하느냐가 LLM의 경쟁력을 좌우한다. 하지만 변화가 없는 리더보드 시스템으로는 실제 유연성과 대처 능력을 평가할 수는 없다는 주장이다. 심지어 일정 데이터를 과도하게 학습한 나머지, ‘오버피팅’을 불러올 수도 있다. 이에 대해 “데이터를 일 단위로 지속 추가 갱신하는, ‘자가 증식’ 리더보드 데이터셋 도입이 목표\"라고 밝혔다. 벤치마크가 한계를 가진 만큼, 다양한 평가 방식이 필요하다는 의견이다. 결국 모델을 사용하고 평가하는 것은 사용자와 기업이기 때문이다. 사람이 직접 AI 챗봇과 대화, 비교를 거치는 ‘챗봇 아레나’를 예로 들었다. 또 똑같은 벤치마크 평가라고 해도, 매달 평가 척도를 교체하거나 특정 도메인에 초점을 맞추는 등 ‘다각도 LLM 평가 시스템’이 필요하다고 말했다. 이런 리더보드 운영 노하우를 바탕으로 향후 논문이나 관련 보고서를 작성, 공개할 예정이다. 이런 기술적인 면과 함께 리더보드의 지속성을 담보하는 가장 중요한 요소로 '영향력'과 '인지도' 등을 꼽았다. 업스테이지도 자체 개발 '솔라' 모델로 글로벌 리더보드 1위를 차지하는 등의 성과를 거뒀다. 그는 “리더보드 순위가 실제 사용성을 의미하지는 않는다”라며 “성능보다 중요한 것은 사람들의 인식”이라고 전했다. 주기적으로 SNS 사용 후기를 들여다보고 있다. X(트위터)나 레딧 등 커뮤니티에 솔라에 대한 언급이 많다고 소개했다. \"긍정적 후기는 물론 부정적인 의견도 있다\"라며 \"하지만 이런 많은 의견을 모두 참고, 모델을 계속 발전시키는 것이 무엇보다 중요하다\"라고 강조했다. “솔라는 상용화가 가능한 '아파치 2.0' 라이선스로 공개, 현재 모델 다운로드 수가 1만건이 넘어갔다”라며 “무엇보다 사람들이 솔라를 직접 사용하고 미세조정하는 사례가 많이 생겨나길 기대한다”라고 마무리했다. 장세민 기자 semim99@aitimes.com"
}