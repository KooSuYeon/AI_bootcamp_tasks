{
    "title": "인피닉, '퓨샷 객체 감지' 연구로  국제학술지에 논문 게재",
    "created_at": "박수빈 기자",
    "content": "인공지능(AI) 전문 인피닉(대표 박준형)은 ‘이미지-언어 유사성을 활용한 퓨샷(Few-shot) 객체 감지’ 연구 논문이 국제 학술지 ‘컴퓨터 비전과 이미지 이해’에 게재됐다고 28일 밝혔다. AI 연구소에서 발표한 이번 논문은 이미지와 언어의 유사성을 활용해 30장 이내 적은 양의 이미지 데이터에서 객체 위치와 클래스를 검출, 객체 감지 정확성을 높이는 모델(RISF) 연구 결과다. RISF 모델은 ▲이미지 내 객체의 위치와 클래스 정보를 검출하는 모델(Detector)과 ▲이미지-텍스트 간 유사도를 사전 학습한 CLIP(Contrastive Language-Image Pre-training) 모델을 결합했다. 특히 자체 제작한 BNRL이라는 새로운 손실 함수를 만들어, 모델 결합 시 발생할 수 있는 오류를 최소화하는 방법을 추가해 정확도를 높였다는 설명이다. RISF 모델은 글로벌 머신러닝 학술 사이트 ‘페이퍼 위드 코드’에서 퓨샷 객체 감지 부분 AP 지표 25.5를 기록, 전 세계 2위에 올랐다. 페이퍼 위드 코드는 전 세계 AI 연구자들이 AI 연구 모델과 논문을 공유하는 글로벌 커뮤니티다. 인피닉의 연구 논문이 게재된 국제 학술지 ‘컴퓨터 비전과 이미지 이해’는 컴퓨터 비전과 이미지 처리, 패턴 인식 등 비정형 데이터 분야의 다양한 주제를 다룬다. 과학기술논문인용색인(SCIE)급 학술지로 국제적으로 고품질의 연구를 게재, 연구자 사이에서 폭넓은 인지도를 가지고 있다. 논문 발표를 주도한 정민재 연구원은 “RISF 모델은 객체 감지 단계에서 기존의 접근 방식보다 훨씬 뛰어난 성능을 보여준다”라며 “특히 적은 양의 비전 데이터 만으로 물체 감지하는데 뛰어난 성능과 정확도를 나타내기 때문에 AI 학습 단계에서 유용하고 효과적인 모델이 될 수 있다”라고 설명했다. 박준형 인피닉 대표는 “RISF 모델은 글로벌 커뮤니티 페이퍼 위드 코드 2위뿐만 아니라 SCI급 학술지에 실리며 세계적으로 인정을 받았다”라며 “향후에도 AI 분야의 지속적인 연구 개발을 이어 나갈 것”이라고 말했다. 박수빈 기자 sbin08@aitimes.com"
}