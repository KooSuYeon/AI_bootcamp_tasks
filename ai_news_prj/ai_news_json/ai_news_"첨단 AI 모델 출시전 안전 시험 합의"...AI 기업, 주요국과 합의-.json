{
    "title": "\"첨단 AI 모델 출시전 안전 시험 합의\"...AI 기업, 주요국과 합의",
    "created_at": "",
    "content": "각국 정부가 주요 인공지능(AI) 기업과 첨단 모델 출시 전 안전성을 시험하는 데 합의했다. 이번 주초 바이든 정부가 발표한 행정명령과 흡사한 내용이다. 로이터와 BBC, 블룸버그 등은 2일(현지시간) 미국과 유럽연합(EU) 등 같은 뜻을 가진 국가들이 '프론티어 모델', 즉 첨단 AI 모델 출시에 앞서 안전성을 검토하는 과정에 주요 AI 기업과 합의했다고 전했다. 이에 따르면 이번 합의에 참가한 국가는 미국과 영국,  EU를 비롯해 한국, 일본, 호주, 캐나다, 프랑스, 독일, 이탈리아,  싱가포르 등이며, 전날 '블레츨리 선언'에 참가했던 중국은 빠졌다. 또 안전성 시험에 합의한 기업은 오픈AI와 마이크로소프트, 구글, 메타 이외에도 일론 머스크 테슬라 CEO가 지난 7월 출범한 연구조직 ‘엑스AI’가 포함됐다. 리시 수낙 영국 총리는 \"선언과 테스트에 대한 조치, 위험에 관한 국제 패널 설립 약속은 인류에게 유리한 균형을 이룰 것\"이라며 \"생각이 비슷한 국가들이 모델을 배포하기 전후에 엄격하게 평가해야 한다는 원칙에 따라 AI 분야에서 일하는 엄선된 회사들과 획기적 합의에 도달했다\"라고 강조했다. 이번 합의에 참가한 회사들은 이미 지난 7월 백악관에서 발표한 'AI 자율 서약'에 따라 '프론티어 모델 포럼'이라는 조직을 만들었다. 또 모델 출시 전 안전 시험 결과를 정부에 통보하는 것은 이번 주초 바이든 정부가 발표한 AI 행정명령에 포함된 그대로다. 단지 벤지오 교수와 같은 외부 인물이 이를 검토한다는 것이 차이다. 안전성 시험은 영국이 신설한 'AI 안전 연구소(AI Safety Institute)'를 통하며, '딥러닝의 창시자'로 알려진 요수아 벤지오 몬트리올대학교 교수가 주도하기로 했다. UN 과학 자문위원회 회원이기도 한 벤지오 교수는 대표적인 AI 경계론자 중 하나다. 수낙 총리는 \"지금까지 새로운 AI 모델의 안전성을 테스트하는 유일한 사람은 이를 개발하는 회사뿐이었다\"라며 \"숙제 내용을 스스로 검토하는 것에 의존해서는 안 된다\"라고 강조했다. 중국이 이번 안전성 합의에 빠진 것에 대해서 지적하는 내용도 많다. 하지만 영국은 애초 중국을 초청하며 첫날 포괄적 선언에만 참석하고, 나머지는 빠지는 일부 참석안을 제안했다. 또 중국이 안전성 합의에 참가해도 바뀔 것은 거의 없다. 이미 중국은 국내에서 사용하는 대형언어모델(LLM)에 대해 엄격한 테스트를 거치는 라이선스제를 실시하고 있으며, 중국 빅테크는 첨단 모델이라고 부를 만큼 앞선 모델을 내놓지 못했기 때문이다. 대신 이번 서밋에서는 일론 머스크 CEO가 스포트 라이트를 받았다. 당초 머스크 CEO는 \"AI 기업 관계자가 아니다\"라는 내부 의견으로 인해 초청 여부도 불투명했으나, 이번 행사를 통해 AI 업계를 대표하는 인물로 떠올랐다. 특히 이 행사의 대미를 장식하는 대담에 참석, 수낙 총리와 AI 규제에 대한 토론 생방송에 참가했다. 그는 토론 중 영국 총리로부터 간접적인 투자 요청을 받기도 했다. 한편 6개월 뒤 한국에서 열리는 회의는 중간 평가 성격으로, 'AI 미니 가상 정상회담'이라고 소개됐다. 2차 정상 회담은 1년 뒤 프랑스에서 열린다. 임대준 기자 ydj@aitimes.com"
}