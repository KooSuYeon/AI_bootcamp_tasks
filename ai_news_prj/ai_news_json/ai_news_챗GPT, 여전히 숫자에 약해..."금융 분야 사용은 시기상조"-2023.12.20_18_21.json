{
    "title": "챗GPT, 여전히 숫자에 약해...\"금융 분야 사용은 시기상조\"",
    "created_at": "2023.12.20 18:21",
    "content": "'챗GPT'와 같은 대형언어모델(LLM)이 수치 계산이 필요한 회계 및 재무 관련 지식 등 금융 분야의 질문에 대답하지 못하는 경우가 많다는 연구 결과가 나왔다. 벤처비트는 19일(현지시간) 스타트업 패트로누스 AI가 미국 증권거래위원회(SEC)의 재무 문서를 기반으로 한 재정적 질문에 대해 LLM이 어떻게 응답하는지 테스트하기 위한 벤치마크인 ‘파이낸스벤치(FinanceBench)’를 출시했다고 보도했다. 이에 따르면 패트로누스는 파이낸스벤츠를 사용, 오픈AI의 ‘GPT-4’ 및 ‘GPT-4-터보’, 앤트로픽의 ‘클로드 2’, 메타의 ‘라마 2' 등 대표적인 LLM 4종을 테스트했다. 파이낸스벤치는 주요 상장 기업의 SEC 서류와 수익 보고서, 수익 통화 기록과 같은 공개적으로 이용 가능한 재무 문서를 기반으로 한 1만개의 질의응답으로 구성된 고품질의 대규모 데이터셋이다. 테스트 결과, 최첨단 LLM 4종도 파이낸스벤치의 150개 샘플 질문에서 대부분 대답에 실패한 것으로 나타났다. GPT-4 터보의 경우 SEC 소스 문서에 대한 액세스 권한이 부여되지 않은 '비공개' 테스트에서 88%에 답하지 못했다. 기본 서류에 대한 액세스가 제공되면 정답률이 크게 올라갔다. 특히 답변이 텍스트 어느 곳에 위치했는지를 알려주고 실시한 '오라클' 모드에서는 정답률이 85%까지 올라갔다. 그러나 서류에서 정확한 관련 위치를 찾기 위해서 인간이 개입하기 때문에 사실상 모델 능력 테스트로서는 의미가 없다는 설명이다. 그나마도 오답률 15%를 기록했다. 오픈 소스 LLM인 라마 2가 가장 심각했다. 최대 오답률은 70%에 달했으며, 정답은 19%에 불과했다. 또 프롬프트에 문서 전체 입력이 가능한 긴 컨텍스트 창을 가진 LLM의 경우, 성능은 더 좋지만 실용성이 떨어진다는 점을 지적했다. 긴 컨텍스트 창을 가진 GPT-4 터보는 79%의 경우 정확하게 답변했지만, 여전히 17%의 잘못된 답변을 생성했다. 클로드 2도 제기된 질문의 75%에 답할 수 있었고, 21%는 잘못된 답을 제공했다. 레베카 치안 패트로누스 AI CTO는 ”답변이 컨택스트 내에 있고 인간이 대답할 수 있는 경우에도 거부율이 정말 높다”라며 ”특히 금융 등 산업에서는 모델이 20번 중 1번 잘못된 답을 얻더라도 치명적”이라고 지적했다. 결국 LLM을 금융 분야에 사용하는 것은 시기상조라는 의미다. LLM은 숫자에 약하다는 사실을 재차 입증한 셈이다. 오픈AI 역시 오픈AI 모델을 사용하여 맞춤형 금융 조언을 제공하는 것을 금지하고 있다고 밝혔다. 메타와 앤트로픽은 논평 요청에 응답하지 않았다. 한편 패트로누스 AI는 LLM 안전 위험을 식별하는 ‘간편안전테스트(SimpleSafetyTests)’ 진단 테스트 제품군도 출시했다. 이 테스트는 자살, 아동 학대, 신체적 상해 등 심각성이 큰 5가지 위험 영역에 걸쳐 취약성을 조사하도록 설계된 100개의 테스트 프롬프트로 구성된다. 라마 2 등 11개의 오픈 소스 LLM을 테스트한 결과, 여러 모델에서 20% 이상의 안전하지 않은 응답을 하는  것으로 나타났다. 레베카 치안 패트로누스 AI CTO는 \"70억에서 400억 개의 매개변수 모델에서 안전하지 않은 응답의 비율이 높다는 것은 놀라운 일\"이라며 \"가장 큰 원인은 기본 훈련 데이터 때문일 가능성이 높다\"고 지적했다. 박찬 기자 cpark@aitimes.com"
}