{
    "title": "세일즈포스, 오픈 소스 LMM 출시...\"동시에 다수 이미지 읽어내는 능력 탁월\"",
    "created_at": "2024.08.20 18:00",
    "content": "세일즈포스가 대형멀티모달모델(LMM) 제품군을 출시했다. 요즘 유행하는 '최고 성능'에 초점을 맞춘 것이 아니라, 멀티모달 데이터의 가장 흔한 형태인 '여러 이미지와 텍스트의 결합을 처리하는 능력'이 탁월하다고 설명했다. 벤처비트는 19일(현지시간) 세일즈포스가 LMM을 개발하기 위한 프레임워크 ‘x젠-MM(xGen-MM)’에 관한논문을 아카이브에 게재했다고 보도했다. 이 프레임워크에는 사전 훈련된 모델, 데이터셋, 그리고 미세조정을 위한 코드 등이 포함됐다. 가장 큰 모델은 40억개의 매개변수를 가지고 있으며, 동급의 오픈 소스 모델들과 비교했을 때 경쟁력 있는 성능을 발휘한다. 이 프레임워크의 핵심은 사전 훈련한 소형언어모델 ‘파이3-미니(phi3-mini)’와 '비전 토큰 샘플러'의 조합이라는 점이다. 이는 모델이 여러 이미지와 텍스트가 결합된 ‘인터리브된 데이터(interleaved data)’를 처리할  수 있게 하며, 이를 통해 모델은 여러 이미지를 동시에 분석하고 질문에 답하는 복잡한 작업을 수행할 수 있다. 자율주행이나 의료 등 현실 세계에서 매우 유용한 기능이라는 설명이다. 훈련 과정에는 동적 고해상도 이미지 인코딩 전략이 포함, 모델이 다양한 해상도의 이미지를 효과적으로 처리할 수 있다. 이 방식은 이미지를 패치 단위로 인코딩, 해상도를 유지하면서 비전 토큰의 시퀀스 길이를 줄인다. 이를 통해 이미지 해석 능력을 향상하고 계산 요구 사항을 크게 줄여, 대규모 응용 프로그램에서 모델의 가용성을 높인다. x젠-MM 모델은 세일즈포스가 구축한 대규모 데이터셋으로 훈련했다. 여기에는 ‘민트-1T(MINT-1T)’라는 이름의 1조토큰 규모의 인터리브 이미지와 텍스트 데이터가 포함돼 있다. 또 광학 문자 인식(OCR) 및 시각적 기반 정립(visual grounding)에 중점을 둔 새로운 데이터셋을 구축했다. 이 분야는 AI 시스템이 시각적 세계와 자연스럽게 상호작용하는 것을 돕는다. 이번 출시에는 다양한 용도에 맞게 최적화된 모델 버전이 포함돼 있다. ▲기본 사전훈련 모델(base pretrained model) ▲지시를 따르도록 조정된 ‘인스트럭션-튜닝 모델(instruction-tuned model)’ ▲유해한 출력을 줄이기 위해 설계된 ‘세이프티-튜닝 모델(safety-tuned” model)’ 등이 포함된다. 여러 멀티모달 벤치마크를 통해 성능을 검증한 결과, 인상적인 결과를 보여줬다. 예를 들어, 인스트럭션-튜닝 모델은 시각적 질문 응답(VQA)과 광학 문자 인식(OCR) 작업에서 뛰어난 성능을 보였다. 특히, x젠-MM은 텍스트VQA(TextVQA)와 COCO 캡셔닝 작업에서 유사한 모델들을 크게 능가, 8-샷 평가에서 각각 66.9와 90.6의 점수를 기록했다. 세이프티-튜닝 모델의 도입은 LMM 신뢰성을 향상, 환각과 같은 유해한 행동을 줄이면서도 복잡한 멀티모달 작업에서 높은 정확성을 유지했다고 전했다. 고해상도 이미지 처리 작업에서도 뛰어난 성능을 발휘했다. 현재 x젠-MM의 코드, 모델, 데이터셋은 세일즈포스의깃허브 저장소에서 사용할 수 있으며, 추가 자원은프로젝트 웹사이트에 곧 추가될 예정이다. 박찬 기자 cpark@aitimes.com"
}