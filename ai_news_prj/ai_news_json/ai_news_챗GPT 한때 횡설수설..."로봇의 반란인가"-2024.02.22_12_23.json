{
    "title": "챗GPT 한때 횡설수설...\"로봇의 반란인가\"",
    "created_at": "2024.02.22 12:23",
    "content": "'챗GPT'가 한때 횡설수설, 오픈AI가 반나절 만에 문제를 수정했다. 이 과정에서 '로봇이 반란을 일으켰다'라는 우스갯소리까지 떠돌았다. 벤처비트는 21일(현지시간) 챗GPT가 전날 오후부터 엉뚱하거나 무의미한 대답을 내놓으며 많은 사용자들이 불만을 털어놓았다고 보도했다. 이에 따르면 챗GPT의 답변 중 일부는 열어와 스페인어가 뒤섞여 이해할 수 없을 정도였으며, 다른 경우에는 단어나 구절을 무의미하게 계속 반복했다. 그러자 X(트위터)에는 이를 입증하는 스크린샷과 불만이 쏟아졌다. 이 때문에 피해를 봤다는 주장도 등장했고, 일부에서는 영화 '터미네이터'와 '매트릭스' 등에서 볼 수 있는 이상한 형태의 출력을 두고 \"로봇이 반란을 일으켰다(robot uprising)\"라고 농담했다. 오픈AI는 곧 이 문제를 파악하고 \"수정 중\" \"상황 파악 중\" 등의 공지를 올린 데 이어 다음 날 오전에는 수정을 마치고 정상 가동 중이라고 밝혔다. \"사용자 경험 최적화로 인해 모델이 언어를 처리하는 방식에 버그가 발생했다\"라며 \"LLM은 부분적으로 확률을 기반으로 단어를 무작위로 샘플링하여 응답을 생성한다. 그들의 '언어'는 토큰에 해당하는 숫자로 구성된다. 어제의 경우 모델이 이러한 숫자를 선택하는 단계에 버그가 있었다\"라고 이유를 밝혔다. 따라서 \"모델은 약간 잘못된 숫자를 선택하여 말이 안 되는 단어 시퀀스를 생성했다. 기술적으로, 추론 커널은 특정 GPU 구성에서 사용될 때 잘못된 결과를 생성했다\"라며 \"원인을 확인한 후 수정 사항을 적용하고 사건이 해결됐음을 확인한다\"라고 게시했다. 이와 비슷한 상황이 지난해 7월 일어났다. 당시에는 챗GPT 작동 방식을 MoE(전문가 믹스)로 수정하는 과정에서 일어난 일로, 오픈AI는 \"모델이 더 똑똑해졌다\"라고 주장했다. 즉 쿼리를 처리하는 과정을 단일 모델이 아닌, 전문 모델로 배분하는 기술적인 패치를 적용하는 중 일어난 일이다. 반면 이번 문제는 순전히 버그에 의한 것이다. 벤처비트는 \"챗GPT의 신뢰성과 제품 사용에 대한 안전을 의심하게 만들었다\"라고 평했다. 임대준 기자 ydj@aitimes.com"
}