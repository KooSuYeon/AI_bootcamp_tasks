{
    "title": "대세로 자리잡은 대형언어모델(LLM) 오픈소스 공개",
    "created_at": "2023.06.27 18:19",
    "content": "오픈소스로 공개되는 인공지능(AI) 언어모델이 크게 늘고 있다. 올해 들어서만 23개 모델이 공개되면서 지금까지 깃허브에 오픈소스로 공개된 언어모델은 총 37개로 늘었다. 오픈AI나 구글과 같은 빅테크들이 대형언어모델(LLM)을 개발하고도 핵심 기술을 공개하지 않는데 따른 반작용으로 풀이된다. 워싱턴포스트와 악시오스 등 외신에 따르면 지난달 31일 UAE 기술혁신연구소가 매개변수 13억개에서 400억개 사이인 '팰컨'을 오픈소스로 공개한데 이어 최근 모자이크ML이 매개변수 300억개인 언어모델 'MPT-30B'를 공개하는 등 오픈AI와 구글을 제외한 후발주자들이 개발하는 LLM은 대부분 깃허브에 오픈소스로 공개되는 추세다. 이들 모델은 매개변수가 1750억개인 오픈AI의 ‘GPT-3'나 5400억개에 달하는 구글의 ‘팜’과는 비교할 수 없을 정도로 작은 규모의 LLM이지만 품질면에서 크게 뒤지지 않는 것으로 알려졌다. '팰컨'의 경우 오픈소스 커뮤니티인 허깅페이스의 LLM 성능 평가 순위에서 1위를 차지했다. 특히 규모가 작은 만큼 개발비용이나 활용도 면에서는 'GPT-3'에 비해 훨씬 우수하다는 평가도 받고 있다. 챗봇이나 코드 완성, 텍스트 요약과 같은 특정 애플리케이션개발에는 오히려 유리하다는 것이다.  또 중국의 베이징 AI 아카데미가 지난 9일 공개한 '아퀼라' 처럼 일정 조건을 충족하면 상업용으로 사용할 수 있도록 하는 모델들도 나오고 있다. 이처럼 언어모델을 오픈소스로 공개하는 것이 일반화되는 분위기는 오픈소스 커뮤니티를 중심으로 언어모델 개발 수요가 폭증하고 있는데 따른 현상이다. 특히 개발이 늦은 후발주자 입장에서는 오픈소스로 공개하는 것이 향후 세를 넓히는 데 유리할 것이라는 판단도 이같은 분위기 조성에 한 몫하고 있는 것으로 보인다. 메타가 지난 2월 오픈소스로 공개한 ‘라마(LLaMa)’로 개발 비용이 낮아진 것도 언어모델 개발 붐 조성에 기여했다. ‘라마’는  매개변수가 70억개에서 650억개 사이로 기존 LLM보다 작으면서도 성능은 못지 않다. 이에 따라 ‘라마’를 기반으로 한 언어모델들이 잇달아 등장했다. 오픈소스는 어떤 소프트웨어의 소스코드와 데이터셋, 가중치를 공개해 누구나 접근할 수 있고 복사, 수정 그리고 재배포를 할 수 있도록 하는 관행이다. 소프트웨어 구축 비용과 진입 장벽을 낮춰 수많은 개발자들이 쓸 수 있도록 함으로써 자연스럽게 협업을 통한 혁신을 이끌 수 있는 장점이 있다. 물론 오픈소스로 배포하는 것이 장점만 있는 것은 아니다. 메타가 공개한 '라마'가 '앨리'라는 성인용 챗봇의 기반이 된 것처럼 오남용 우려도 커지고 있다. 이와관련해 마르지예 가세미 MIT 컴퓨터과학과 교수는 \"오픈소스를 지지하지만 개방성은 위험을 수반할 수 있다\"면서 \"자동차 면허를 주듯이 오픈소스 언어모델의 개발이나 수정을 할 수 있는 권한을 부여하는 방안이 필요하다\"고 제안하기도 했다. 정병일 기자 jbi@aitimes.com"
}