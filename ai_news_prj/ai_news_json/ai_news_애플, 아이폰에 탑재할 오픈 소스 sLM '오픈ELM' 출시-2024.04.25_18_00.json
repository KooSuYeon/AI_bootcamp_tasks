{
    "title": "애플, 아이폰에 탑재할 오픈 소스 sLM '오픈ELM' 출시",
    "created_at": "2024.04.25 18:00",
    "content": "애플이 초경량급 오픈 소스 소형언어모델(sLM)을 출시했다. 아이폰이나 맥북 등에서 인터넷 연결 없이도 완전히 실행되도록 '온디바이스 AI'에 최적화돼 있는 것이 특징이다. 벤처비트는 24일(현지시간) 애플이 클라우드 서버에 연결하지 않고도 장치에서 로컬로 실행 가능한 온디바이스 인공지능(AI)용 오픈 소스 sLM ‘오픈ELM(OpenELM)’에 관한 논문을온라인 아카이브에 게재했다고 전했다. 이에 따르면 오픈ELM은 텍스트 생성 작업을 효율적으로 수행하도록 설계된 소형 모델로, 허깅페이스에서 4개의 사전 훈련 모델과 4개의 명령 조정 모델을 공개했다. 매개변수 수는 각각 2억7000만개(0.27B), 4억5000만개(0.45B), 11억개(1.1B), 30억개(3B)로 현재 공개된 sLM 중 가장 작은 규모다. 사전 훈련은 모델이 일관되고 잠재적으로 도움이 되는 텍스트를 생성하도록 하는 방법이며, 명령 조정은 사용자의 특정 요청에 대해 보다 관련성이 높은 출력으로 응답하도록 하는 방법이다. 애플은 모델 가중치와 추론 코드만 제공하고 비공개 데이터 세트에 대한 사전 훈련만 제공하던 일반적인 사례와 달리, 오픈ELM은 학습 로그, 다중 체크포인트, 사전 훈련 구성을 포함해 공개 데이터 세트에서 언어 모델을 학습하고 평가 및 명령 조정하기 위한 전체 프레임워크를  공개했다. 오픈ELM 라이선스는 ‘애플 샘플 코드 라이선스’하에 배포됐다. 해당 라이선스에 따르면, 상업적 용도로 오픈ELM을 사용하거나 수정할 수 있으나 향후 재배포 과정에서는 라이선스에서 제시한 문구와 면책 조항을 함께 명시해야 한다. 또한 모델 결과가 유해하거나 편향된 결과를 생성할 수 있다며 결과에 대한 안정성을 애플이 보장하지 않는다고 설명했다. 지난해 10월 멀티모달언어모델 ‘페럿(Ferret)’에 이은 애플의 두번째 오픈 소스 언어모델이다. 애플은 깃허브, 위키피디아, 레딧, 아카이브 등의 1조8000억개의 토큰으로 구성된 공개 데이터셋을 활용해 오픈ELM을 사전훈련했다고 밝혔다. 오픈ELM 모델들은 상용 노트북 또는 일부 스마트폰에서 실행하기에 적합하다. 애플에 따르면 인텔 i9-13900KF CPU와 64GB DDR5-4000 DRAM, 그리고 엔비디아 RTX 4090 GPU와 24GB VRAM을 장착한 우분투 22.04에서 작동하는 워크스테이션에서 실행되었으며, M2 Max 시스템 온 칩(SoC)과 64GB RAM이 장착된 맥OS 14.4.1에서 작동하는 애플 맥북 프로에서도 실행됐다. 성능 면에서도 오픈ELM이 상당히 좋은 것으로 나타났다. 특히 0.45B 모델이 전반적으로 우수한 것으로 나타났다. 1.1B 모델은 올모 1.2B보다 2.36% 더 성능이 뛰어나며 필요한 사전 훈련 토큰은 2배 더 적다. 지식과 추론 능력을 테스트하는 ARC-C 벤치마크에서 사전 훈련된 오픈ELM 3B 는 42.24%의 정확도를 기록했다. MMLU와 헬라스웩(HellaSwag) 벤치마크에서는 각각 26.76%, 73.28%를 기록했다. 한편 마이크로소프트(MS)가 최근 출시한  38억 매개변수와 4K 컨텍스트 길이의 파이-3 미니가 ARC-C 벤치마크에서 84.9%, MMLU에서 68.8%, 헬라스웩에서 76.7%를 기록하며 1위를 차지했다. 오픈ELM 모델군 테스트를 시작한 한 사용자는 \"견고한 모델이지만 매우 정렬된\" 것으로 보인다고 지적했다. 인간이 원하는 작업을 AI가 수행하게 만들고, 원하지 않는 작업을 수행하지 않도록 하는 정렬(alignment)에는 뛰어나지만, 창의적이지는 않다는 말이다. 벤처비트는 \"애플이 오픈ELM을 오픈 소스로 출시한 만큼, 장기적으로 성능은 점차 개선될 것으로 예상된다\"라고 평했다. 박찬 기자 cpark@aitimes.com"
}