{
    "title": "스노우플레이크, 기업용 '업계 최고 오픈 소스' LLM 출시",
    "created_at": "2024.04.25 18:00",
    "content": "스노우플레이크가 기업용 오픈소스 대형언어모델(LLM) '아크틱(Arctic)'을 데이터 클라우드 플랫폼에 추가했다. 이를 두고 '업계 최고 수준의 개방성'을 제공하는 LLM이라고 강조했다. 벤처비트는 24일(현지시간) 스노우플레이크가 엔터프라이즈급 LLM 아크틱을 출시했다고 보도했다. 이에 따르면 스노우플레이크 고유의 '전문가 혼합(MoE)' 방식으로 설계된 아크틱은 동급 최고 성능과 생산성을 지원한다. 기업의 복잡한 요구사항 처리에도 최적화되어 SQL 코드 생성, 명령 이행 등 다양한 기준에서 최고 조건을 충족한다. 특히 무료로 상업적 이용까지 가능한 '아파치 2.0' 라이선스 기반의 오픈 소스로 뛰어난 개방성을 갖췄다. 슈리다 라마스워미 스노우플레이크 CEO는 “스노우플레이크 AI 연구팀은 AI 분야 최전방에서 혁신을 이끌며 자사에 중요한 전환점을 마련했다”라며 “스노우플레이크는 개선된 성능과 효율을 AI 커뮤니티에 공개하며 오픈 소스 AI의 가능성을 넓혀가고 있다. 아크틱은 안정적이고 효율적인 AI 능력을 크게 향상할 것”이라고 말했다. 아크틱의 MoE 설계는 기업의 요구사항에 따라 세밀하게 설계된 데이터 조립을 통해 학습 시스템과 모델 성능 모두를 향상한다. 4800억개의 매개변수를 최대 128개의 전문가 그룹으로 나눠, 쿼리에 맞춰 170억개만 활성화하는 방식이다. 이를 통해 뛰어난 토큰 효율과 품질을 구현, 최상의 결과를 제공한다는 설명이다. 실제로 아크틱은 추론이나 학습 중 데이터브릭스의 'DBRX'의 약 50%, 메타의 '라마 3 70B'의 약 75%의 매개변수를 활성화한다. 스노우플레이크가 공유한 벤치마크에 따르면 아크틱은 이 접근 방식을 통해 평균 65%의 점수를 얻었다. 이는 라마 3 70B의 평균 기업 성능과 동일하며, '믹스트랄 8X22B'의 70% 바로 뒤에 위치한다. SQL 생성을 위한 스파이더 벤치마크에서 아크틱은 79%를 기록, DBRX 및 믹스트랄 8X7B를 능가하고 라마 3 70B 및 믹스트랄 8X22B와 비슷한 수준을 기록했다. 휴먼이밸+ 및 MBPP+의 코딩 작업에서는 64.3%로, DBRX 및 믹스트랄 8X7B를 능가하고 라마 3 70B 및 믹스트랄 8X22B에는 뒤쳐졌다. 명령에 따른 기능을 측정하는 IF이밸 벤치마크에서 아크틱은 52.4%로, 믹스트랄 8X22B를 제외한 대부분의 모델을 능가했다. 아크틱은 자체 LLM 앱 개발 서비스인 코텍스 내부와 허깅페이스, 라미니, 마이크로소프트 애저, 엔비디아 API 카탈로그, 퍼플렉시티, 투게더 AI 등 다양한 모델 목록에서 사용할 수 있다. 허깅페이스에서는 아크틱 모델 가중치와 코드를 아파치 2.0 라이선스에 따라 직접 다운로드할 수 있어, 개인용이나 상업용 또는 연구용 애플리케이션에 제한 없이 사용할 수 있다. 박찬 기자 cpark@aitimes.com"
}