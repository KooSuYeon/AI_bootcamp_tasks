{
    "title": "원라인에이아이, 유럽학회에서 '언어모델 성능평가' 연구 발표",
    "created_at": "박수빈 기자",
    "content": "금융 생성 인공지능(AI) 전문 원라인에이아이(대표 정한얼)는 이탈리아 토리노에서 열리는 '2024 국제 컴퓨터 언어학, 언어 자원 및 평가 공동 국제 학회(LREC-COLING 2024)'에 참가, 한글 모델 평가에 특화된 데이터셋 및 연구 결과를 발표한다고 15일 밝혔다. 원라인에이아이는 금융업계에서 사용하는 언어모델 연구 결과를 꾸준히 발표해왔다. 이번 학회에도 한국 특유의 지식과 문화적 맥락을 평가하는 데이터셋과 성과를 공유할 예정이다. 이전 한글 벤치마크가 자연어 이해나 추론 능력을 평가하는 데 중점을 둔 반면, 이번 학회에서 발표하는 한국어 벤치마크 데이터셋은 지식의 깊이 자체를 강조한다는데 차이점이 있다고 전했다. 한국어 어휘·문화·지리·역사에 대한 지식이 대화 상황에서 토큰 또는 시퀀스 분류와 같은 전통적인  자연어 이해 작업만큼 중요하다고 판단했다. 또 이 벤치마크는 외래어(LW), 표준 명칭(SN), 희귀어(RW), 일반 지식(GK), 역사(HI), 독해력(RC)과 같은 여섯 개의 하위 작업을 포함한다. 이를 통해 평가한 언어모델의 한글 성능은 주의 깊게 볼 만 하다고 밝혔다. 한글 오픈 소스 'Polyglot-Ko' 모델이 메타의 '라마 2'와 구글 'UMT5'보다 여섯개 항목에서 모두 높은 성능을 보였다는 것. 이 결과는 벤치마크가 한국어로 맞춤화되지 않은 모델보다 뛰어나며, 프롬프트를 통한 '인 컨텍스트 러닝(In-Context Learning)'만으로는 성능차를 좁히기 어렵다는 뜻이라고 설명했다. 또 모델의 크기와 성능간 상관관계 실험을 통해, 언어모델 성능은 모델의 크기를 넘어 더 넓은 범위의 요소에 의해 영향을 받는다는 것을 밝혔다. 이는 LLM을 학습할 때 모델 크기에 따라 학습 비용이 크게 증가하는 상황에서 의미있는 연구로 이어질 수 있다는 평가이다. 정한얼 원라인에이아이 대표는 \"지난해 Fin-NLP 발표 이후로 빠르게 변화하는 생성 AI 분야에서 지속적으로 연구 결과를 발표하는 것은 우리의 핵심 경쟁 우위 요소 중 하나\"라며 \"3월 중 이런 기술력이 응축된 금융 특화 생성 플래그십 모델을 공개할 예정\"이라고 말했다. 한편 원라인에이아이는 앞서 대규모 한글 평가 데이터셋 'KMMLU'를 발표한 바 있다. KMMLU는 현재 가장 뛰어난 한글 언어모델 평가 데이터셋으로 평가받으며 누적 다운로드 수 30만회를 돌파하였다. 박수빈 기자 sbin08@aitimes.com"
}