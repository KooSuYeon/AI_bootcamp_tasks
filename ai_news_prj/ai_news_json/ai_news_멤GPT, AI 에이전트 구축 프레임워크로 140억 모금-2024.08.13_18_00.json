{
    "title": "멤GPT, AI 에이전트 구축 프레임워크로 140억 모금",
    "created_at": "2024.08.13 18:00",
    "content": "인공지능(AI) 스타트업 멤GPT가 7000만달러(약 960억원)의 기업 가치로 1000만달러(약 140억원)를 모금했다. 이 회사는 'AI 에이전트'를 개발하기 위한 프레임워크를 개발 중이다. 비즈니스 인사이더는 12일(현지시간) AI 에이전트 스타트업 멤GPT가 펠리시스 벤처스가 주도한 시리즈 A 라운드에서 7000만달러의 기업 가치로 1000만달러 규모의 투자를 유치했다고 보도했다. 멤GPT는 장기 메모리와 검색 증강 생성(RAG)를 위한 외부 데이터 소스 연결, 사용자 정의 도구 등을 사용해 대형언어모델(LLM) 기반 에이전트를 쉽게 구축하고 배포할 수 있는 프레임워크 ‘멤GPT(MemGPT)’을 개발하고 있다. UC 버클리 박사 학위를 받은 새라 우더스와 찰스 파커가 설립했다. AI 에이전트 구축 시 한번에 처리할 수 있는 컨텍스트 창 크기에 의해 LLM의 기능이 제한되는 문제점을 해결하기 위해 메모리 관리에 초점을 맞춘 에이전트 프레임워크, 즉 AI 에이전트를 구축하기 위한 도구 세트를 개발했다. 이 프레임워크는 AI 에이전트가 일반적으로 처리할 수 있는 것보다 더 많은 정보를 처리할 수 있게 한다. 특히 전통적인 운영체제(OS)에서 영감을 받은 접근 방식으로, LLM이 처리 한계를 초과하는 큰 문서라도 분석하고 기억할 수 있도록 한다. 컴퓨터 OS가 RAM과 디스크 스토리지에서 애플리케이션과 데이터를 관리해 물리적 메모리 한계를 넘는 것을 본땄다는 내용이다. 멤GPT도 LLM 내부에서 다양한 메모리 계층을 작동한다. 따라서 AI 에이전트에서도 주요 컨텍스트는 RAM과 유사하며, LLM 프로세서가 추론 중에 작업하는 직접적인 컨텍스트가된다. 외부 컨텍스트는 하드 드라이브와 비슷하지만 LLM이 직접 접근할 수 없는 곳에 정보를 저장해 필요할 때 접근할 수 있다. 인터럽트는 OS 인터럽트와 마찬가지다. 멤GPT는 프로세서를 일시 중지하고 다시 시작해 제어 흐름을 관리할 수 있다. 이 아키텍처는 동적 컨텍스트 관리를 가능하게 만들어, OS가 페이지 오류를 처리하는 방식과 유사하게 LLM이 과거 데이터를 검색할 수 있도록 한다. 에이전트가 이전 컨텍스트를 기억할 수 있는 솔루션도 도입했다. 메모리를 효과적으로 관리함으로써 확장된 시퀀스에 걸쳐 정보를 유지하고 액세스할 수 있다. 이는 많은 상호 작용이나 긴 텍스트가 있는 대화나 문서에서 일관된 응답을 이해하고 생성하는 데 중요하다는 설명이다. 이처럼 계층화된 메모리 시스템과 데이터 전송 기능, 인터럽트 등을 통한 제어로 메모리를 효율적으로 관리한다는 결론이다. 이 설정은 고정 컨텍스트 LLM을 향상, 문서 분석 및 다중 세션 채팅과 ​​같은 작업을 보다 효과적으로 처리할 수 있게 한다. 또 최신 LLM의 고유한 컨텍스트 제한을 극복해 나은 성능과 사용자 상호 작용을 제공한다. 멤GPT는 \"이런 솔루션을 통해 언어 모델링에서 메모리 관리와 생성 용량 간의 격차를 크게 해소, 다양한 도메인에서 정교한 AI 에이전트 구축을 가능하게 만들었다\"라고 밝혔다. 한편, 깃허브에 공유된 멤GPT는 현재 1만1000개 이상의 별을 받았다. 이는 개발자들 사이에서 상당한 인기를 얻었다는 증거다. 한편 멤GPT와 펠리시스 벤처스는 투자에 대해 공식적인 논평을 내놓지 않았다. 박찬 기자 cpark@aitimes.com"
}