{
    "title": "음성 받아 적어주는 오픈AI '위스퍼'에서 환각 문제 발견",
    "created_at": "2024.10.28 18:05",
    "content": "전 세계적으로 널리 사용되고 있는 오픈AI의 음성-텍스트 필사 도구 ‘위스퍼(Whisper)’에서 심각한 환각 문제가 발견됐다는 보도가 나왔다. AP는 26일(현지시간) 오픈AI의 음성-텍스트 변환 인공지능(AI) 모델 위스퍼가 텍스트 일부 또는 전체 문장을 지어내는 환각 경향을 보였다고 보도했다. 이에 따르면 미시간대학교 연구진은 10건의 오디오 필사본 중 8건에서 환각, 즉 없는 내용을 지어내는 현상을 발견했다고 발표했다. 또 한 머신러닝 엔지니어는 100시간 이상의 위스퍼 필사본을 연구한 결과, 절반 이상의 필사본에서 환각을 발견했다. 위스퍼로 만든 2만6000개의 필사본 대부분에서 환각이 발견됐다는 보고도 등장했다. 생성 AI의 환각에 대한 지적은 많았지만, 오디오 내용을 충실히 따라야 하는 비교적 단순한 필사 작업에서 이런 문제가 발생한다는 점은 다소 놀랍다는 반응이다. 연구자들은 위스퍼가 왜 환각을 일으키는지 확신하지 못하지만, 주로 일시적인 정지나 배경 소음 또는 음악이 재생되는 중에 발생하는 경향이 있다고 지적했다. 특히 의료 분야에서 위스퍼 기반 도구 활용이 확대되는 가운데, 심각한 결과를 초래할 수 있는 환각 오류에 대한 우려의 목소리가 커지고 있다. 예를 들어, 미국의 나블라가 개발한 위스퍼 기반 필사 도구는 현재 3만명 이상의 임상의와 40개 의료 시스템에서 사용되고 있다. 나블라는 “이 도구가 약 700만건의 의료 방문을 기록하는 데 사용됐다”라며 “위스퍼가 환각 증상을 보인다는 사실을 알고 있으며 이 문제를 해결하고 있다”라고 밝혔다. 이에 대해 오픈AI는 \"환각을 줄이는 등 모델의 정확성을 개선하기 위해 지속적으로 노력하고 있다\"라며 \"사용 정책에 따라 특정 고위험 의사결정 상황에서는 위스퍼 사용을 금지하고 있다\"라고 말했다. 위스퍼는 오픈AI가 2022년 9월 오픈 소스로 처음 공개했으며, 같은 해 12월 V2에 이어 지난해 11월 데브데이에서 V3를 출시한 바 있다. 박찬 기자 cpark@aitimes.com"
}