{
    "title": "업스테이지, 사전학습 sLM '솔라' 공개…\"글로벌 LLM 대전 본격 참전\"",
    "created_at": "장세민 기자",
    "content": "업스테이지가 자체 개발 소형언어모델(sLM) ‘솔라(Solar)’를 공개했다. 특히 벤치마크 성적을 바탕으로 글로벌 빅테크들과의 경쟁에서 자신감을 내비쳤다. 인공지능(AI) 전문 업스테이지(대표 김성훈)는 솔라의 사양과 벤치마크 결과 등을 공개, 글로벌 대형언어모델(LLM) 대전에 본격 참가한다고 14일 밝혔다. 지난 8월 허깅페이스의 ‘오픈 LLM 리더보드’에서 '라마 2'와 'GPT-3.5\"의 점수를 뛰어넘어 1위를 차지한 모델을 기반으로 했다. sLM 기준이라고 할 수 있는 300억 매개변수(30B) 이하 크기로, 더 큰 모델들의 성능을 앞섰다. 솔라는 이를 기업이 활용하기 좋은 '프라이빗 LLM'을 위해 더 작은 크기로 구성한 사전학습 모델이다. 107억 매개변수 모델로서는 처음으로 리더보드 평가에서 74.2점을 기록, 전체 1위를 차지했다. 특히 최근 부각된 알리바바의 최신 모델 '큐원(Qwen)'보다 6분의 1 이상 작은 크기다. \"7B와 13B 모델 사이의 장점을 모두 잡기 위해 오픈 소스 7B 모델을 활용, 레이어를 추가해 깊이를 더했다\"라며 \"결국 10.7B로 완성, 크기와 성능 균형을 맞췄다\"라고 설명했다. 더불어 사전 학습 및 미세조정 단계에서 리더보드 벤치마킹 데이터셋을 사용하는 대신, 자체 구축한 데이터를 적용해 성능을 끌어 올렸다고 전했다. 그 결과 미스트랄AI의 최신 모델 '믹스트랄(Mixtral 8x7B)'의 성능마저 뛰어넘었다고 강조했다. 업스테이지는 사전학습 모델까지 공개, 상업적 활용을 가능케 했다. 사전학습 모델 역시 허깅페이스 리더보드 평가 기준 66.04점으로, 큐원이나 라마 2, 미스트랄 모델을 제치고 1위에 올랐다. 김성훈 업스테이지 대표는 “솔라가 모두를 위한 모델이 되기를 희망한다”라며 “KT의 전략투자 등 지원이 큰 도움이 됐고 앞으로도 솔라 모델을 활용, B2B 시장에서의 협력도 추진할 것”이라고 말했다. 이처럼 최근 글로벌 LLM 업계는 새 모델 출시와 더불어 벤치마크 결과를 공개하는 것이 유행이 됐다. 업스테이지 역시 벤치마크 성적을 바탕으로 미세조정 기술을 과시, 글로벌 시장을 본격적으로 두드리겠다는 의도다. 장세민 기자 semim99@aitimes.com"
}