{
    "title": "알리바바, '라마3' 능가하는 오픈 소스 모델 ‘큐원2’ 공개",
    "created_at": "2024.06.11 18:05",
    "content": "알리바바가 새로운 오픈 소스 대형언어모델(LLM) ‘큐원2(Quwen2)’를 공개했다. 일부 성능은 메타의 '라마 3'를 능가한다고 주장했다. 사우스차이나모닝포스트(SCMP)는 7일(현지시간) 알리바바가 오픈 소스 LLM ‘퉁이첸원(Tongyi Qianwen)’의 두번째 버전 큐원2를 공개했다고 보도했다. 큐원2는 영어와 중국어 외 27개 언어의 사전 훈련과 더 긴 길이 컨텍스트 창을 특징으로 한다. 4억9000만~727억개의 매개변수를 갖춘 ▲큐원2-0.5B ▲큐원2-1.5B ▲큐원2-7B ▲큐원2-57B-A14B ▲큐원2-72B 등 5가지 모델을 제공한다. 특히 큐원2-0.5B는 현존 최소 매개변수 모델로 꼽힌다. 알리바바는 큐원2가 다국어 이해뿐만 아니라 사후 학습을 통해 코딩이나 수학, 추론, 명령 수행 처리 능력 등을 개선했다고 밝혔다. 특히 사전학습 데이터셋과 최적화된 학습 방법을 활용, 큐원2-72B는 라마3-70B보다 우수한 성능을 보였다고 설명했다. 작은 크기의 큐원2 모델들도 비슷하게 높은 수준을 보이며, 특히 코딩과 중국어 관련 지표에서 두각을 나타냈다고 밝혔다. 알리바바는 전작 큐원으로 오픈 소스 커뮤니티에서 글러벌한 인기를 끌었다. 따라서 후속작에도 큰 기대가 모인다는 분석이다. 한편 알리바바는 퉁이첸원 2.5를 공개한 지 한달 만에 큐원2를 출시했다. 당시 회사는 오픈AI의 가장 진보된 모델인 'GPT-4'보다 중국 관련 기능에서 퉁이첸원 2.5가 더 나은 성능을 발휘한다고 밝힌 바 있다. 이 모델은 이미 9만곳이 넘는 기업들이 채택했으며, 700만회 이상 다운로드된 것으로 알려졌다. 박찬 기자 cpark@aitimes.com"
}