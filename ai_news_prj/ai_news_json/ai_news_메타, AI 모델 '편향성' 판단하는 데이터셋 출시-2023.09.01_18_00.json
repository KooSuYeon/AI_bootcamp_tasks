{
    "title": "메타, AI 모델 '편향성' 판단하는 데이터셋 출시",
    "created_at": "2023.09.01 18:00",
    "content": "메타는 31일(현지시간) 공식 블로그를 통해 컴퓨터 비전 모델의 편향(bias) 정도를 파악할 수 있는 벤치마크 데이터셋 '페이스티(FACET)'를 출시했다고 밝혔다. 페이스티는 여러 가지 유형의 컴퓨터 비전 인공지능(AI) 모델이 편향된 결과를 생성하는 지를 판단해주는 평가용 대형 데이터셋이다. 이를 통해 기업은 자신들이 보유한 AI 모델의 편향성을 체크해볼 수 있다. 편향은 학습 데이터에 영향을 받는 AI 모델의 특성에 따라 정확하지 않은 결과를 도출하는 문제다. 예를 들어 백인 사진만 학습한 AI 모델은 흑인이나 황인종의 얼굴을 잘 인식하지 못한다. 이는 인종이나 성별, 연령에 따른 불평등을 유발할 수 있다. 따라서 벤치마크 데이터셋은 이런 문제가 발생하지 않토록 꼼꼼하게 제작했다. 페이스티는 5만명의 사람을 포함한 3만2000개의 이미지로 구성했으며, 전문 라벨러가 성별이나 연령 등 인구통계학적 특성과 피부색, 헤어스타일 등 신체적 특성, 직업군 등에 대해 일일히 주석을 달았다. 기존 'SA-1B' 데이터셋을 분할, 6만9000개 이미지에 대한 주석도 포함했다. SA-1B는 데이터 엔진으로 수집한 1100만개의 다양한 고해상도 개인 정보 보호 이미지와 11억개의 고품질 분할 마스크로 구성된 메타의 데이터셋이다. 이를 통해 사용자들은 페이스티에서 사진을 처리, 컴퓨터 비전 모델의 편향성을 확인할 수 있다. 또 표시된 정확도에 따라 AI의 편향 정도까지 가늠할 수 있다. 메타는 페이스티를 사용해 ▲유사한 이미지를 그룹화하는 '이미지 분류' 모델 ▲사진에서 관심있는 항목을 자동으로 감지하는 '객체 감지' 모델 ▲주위에 상자를 그리는 등 사진에서 관심 있는 항목을 시각적으로 강조하는 '인스턴스 분할' 모델 ▲사용자가 자연어 용어로 설명하는 개체를 사진에서 스캔할 수 있는 '시각적 접지' 모델 등 네가지 유형의 모델 편향을 탐지할 수 있다고 설명했다. 이전에도 비슷한 도구가 있었지만, 메타는 페이스티가 가장 정교하다고 강조했다. 피부색이나 성별, 연령은 물론 헤어 스타일이나 문신, 안경, 머리장식 등에도 주석을 달아, 곱슬머리에 대한 편견과 안경 착용자에 대한 편견 같은 점도 판단할 수 있다는 설명이다. 하지만 이를 AI 모델 학습용으로 사용하는 것은 적절하지 않다고 지적했다. “페이스티는 표준 공정성 평가 벤치마크로 사용할 목적으로만 출시했다”고 명시했다. 더불어 메타는 컴퓨터 비전 모델을 향상하기 위해 지난 4월 공개한 이미지 인식 모델 '다이노v2(DINOv2)'를 '아피치 2.0’ 라이선스로 전환했다. 즉 연구는 물론 상업 프로젝트 모두에 사용할 수 있도록 오픈 소스로 공개한 것이다. 다이노v2 모델은 이미지에서 이미지와 비디오 프레임 내의 개별 물체를 정확하게 식별, 다른 컴퓨터 비전 모델의 학습에 활용할 수 있다. 또 2021년에 개발한 이전 세대 모델보다 정확도가 훨씬 높은 것이 장점이다. 메타는 이외에도 ▲카메라에서 사진 속 물체까지의 거리를 추정하는 모델과 ▲이미지를 섹션으로 나누고 각 섹션을 설명할 수 있는 의미론적 분할 모델 등 두가지 새로운 컴퓨터 비전 AI를 추가했다. 박찬 기자 cpark@aitimes.com"
}