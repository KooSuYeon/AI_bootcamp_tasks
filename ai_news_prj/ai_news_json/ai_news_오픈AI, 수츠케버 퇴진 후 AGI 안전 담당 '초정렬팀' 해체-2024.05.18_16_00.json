{
    "title": "오픈AI, 수츠케버 퇴진 후 AGI 안전 담당 '초정렬팀' 해체",
    "created_at": "2024.05.18 16:00",
    "content": "오픈AI가 일반인공지능(AGI) 출연에 대비한 안전 기술 개발 부서인 '초정렬팀(Superalignment)'을 해체했다. 이곳은 일리야 수츠케버 전 수석 과학자가 이끌던 팀으로, 샘 알트먼 CEO의 축출 사태의 불씨가 된 곳으로 알려져 있다. 블룸버그와 테크크런치 등은 18일 오픈AI가 초정렬팀을 독립 부서로 유지하는 대신, 회사의 연구 활동 전반에 분산 배치하기로 결정했다고 보도했다. 이에 따르면 초정렬팀은 지난해 7월 수츠케버의 주도로 조직됐다. AI 안전에 중점을 둔 수츠케버는 빠른 AI 개발을 원했던 알트먼과 잦은 충돌을 일으켰고, 결국 11월에는 수츠케버가 알트먼을 몰아내기에 이르렀다. 수츠케버는 14일 퇴사를 알리며 \"회사가 안전하고 유익한 AI를 구축할 것이라고 확신한다\"라고 밝혔지만, 나머지 직원들은 그렇게 생각하지 않았다. 수츠케버와 초정렬팀을 이끌었던 얀 레이케가 다음날 퇴사 의사를 밝혔다. 레이케는 X(트위터)를 통해 오픈AI가 초정렬팀의 연구가 우선순위에서 뒤로 밀렸다고 주장했다. 그는 \"지난 몇달 동안 우리 팀은 어려움을 겪었다. 때로 컴퓨팅 지원을 받지 못했고, 중요한 연구를 수행하는 것이 점점 더 어려워졌다\"라고 밝혔다. 또 \"인간보다 똑똑한 기계를 만드는 것은 본질적으로 위험한 노력\"이라며 \"그러나 지난 몇 년 동안 안전 문화와 프로세스는 빛나는 제품보다 뒷전으로 밀려났다\"라고 주장했다. 이와 관련, 알트먼은 지난해 11월 축출 복귀 후 자신의 퇴진 이유를 의식한 듯, AI 안전 정책을 대폭 강화하고 이사회 허락 없이 새 모델을 출시하지 않겠다고 밝혔다. 하지만 안전 연구를 위해서는 컴퓨팅 리소스를 거의 분배하지 않았다는 것이 레이케의 주장이다. 하지만 알트먼 CEO는 몇시간 뒤 레이케의 트윗에 \"그의 말이 맞다. 우리는 할 일이 더 많다\"라고 답변했다. 또 \"우리는 그것을 하기 위해 최선을 다하고 있다\"라며 \"며칠 뒤 더 자세한 내용을 밝히겠다\"라고 덧붙였다. 이에 앞서 초정렬팀의 다른 멤버들도 이미 회사를 그만둔 것으로 확인됐다. 특히 다니엘 코코타일로라는 직원은 \"AGI 개발을 중단해야 한다\"라는 의견을 남겼다. 이제부터 정렬 작업에 관한 부분은 오픈AI 공동창립자이자 GPT-4 개발을 핵심 역할을 한 존 슐먼이 맡게 된다. 이와 별도로 수츠케버의 수석 과학자 역할을 맡을 책임자로는 연구 이사인 야쿠브 파초키를 임명했다. 임대준 기자 ydj@aitimes.com"
}