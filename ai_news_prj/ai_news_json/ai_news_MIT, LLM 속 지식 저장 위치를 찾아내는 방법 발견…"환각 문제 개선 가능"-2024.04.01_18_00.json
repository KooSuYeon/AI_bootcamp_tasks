{
    "title": "MIT, LLM 속 지식 저장 위치를 찾아내는 방법 발견…\"환각 문제 개선 가능\"",
    "created_at": "2024.04.01 18:00",
    "content": "간단한 일차함수를 사용, 대형언어모델(LLM) 내에서 특정 지식이 어디에 저장돼 있는지를 확인할 수 있다는 연구 결과가 나왔다. 이를 통해 LLM의 환각 현상을 줄일 수 있다는 설명이다. MIT 뉴스는 25일(현지시간) MIT 연구진이 간단한 선형 함수를 사용해 LLM에 저장된 사실을 복구하고 디코딩하는 내용의 논문을온라인 아카이브에 게재했다고 전했다. 이에 따르면 연구진은 다양한 지식에 대한 선형 함수를 식별, 모델 내에 특정 지식이 어디에 저장돼 있는지 확인할 수 있다고 밝혔다. 이 기술을 사용하면 모델 내부의 거짓 정보를 찾아 수정할 수 있기 때문에 부정확하거나 무의미한 답변을 제공하는 경향을 줄일 수 있다는 설명이다. 연구진은 “LLM은 많은 데이터를 학습해 이해하기 어려운 매우 복잡한 비선형 함수임에도 불구하고, 때로는 내부 작동하는 메커니즘은 매우 간단하다”라고 말했다. 일반적으로 LLM은 트랜스포머 아키텍처를 기반으로 하는 신경망으로, 수십억개의 상호 연결된 노드, 즉 뉴런이 포함되어 있다. 이 노드는 여러 계층으로 그룹화, 데이터를 인코딩하고 처리한다. 트랜스포머에 저장된 지식의 대부분은 주체와 객체를 연결하는 관계로 표현될 수 있다. 예를 들어 ‘마일스 데이비스가 트럼펫을 연주한다’라는 문장은 주어인 '마일스 데이비스'와 대상인 '트럼펫'을 연결하는 관계다. 트랜스포머가 더 많은 지식을 얻으면 여러 계층에 걸쳐 특정 주제에 대한 추가 지식을 저장한다. 사용자가 해당 주제에 대해 질문하면 모델은 응답하기 위해 가장 관련성이 높은 사실을 디코딩해야 한다. 예를 들어 ‘마일스 데이비스는 ○○○을 연주한다’라는 문장을 트랜스포머에 프롬프트로 제출하면, 모델은 악기인 ‘트럼펫’으로 응답해야 한다. 마일스 데이비스의 출생지인 ‘일리노이’로 응답해서는 안 된다. 연구진은 “이처럼 신경망 계산 어딘가에는 마일스 데이비스가 트럼펫을 연주한다는 사실을 찾아 해당 정보를 추출하고 다음 단어를 생성하는 데 도움을 주는 메커니즘이 있어야 한다”라고 설명했다. LLM은 매우 복잡하지만, 간단한 선형 함수를 사용해 관계 정보를 디코딩한다는 사실을 발견했다. 또 디코딩 함수는 검색되는 지식 유형에 따라 다르다. 예를 들어, 트랜스포머는 사람이 연주하는 악기를 출력할 때마다 한가지의 디코딩 함수를 사용하고, 사람의 출생지를 출력할 때마다 다른 디코딩 함수를 사용하는 식이다. 연구진은 이런 디코딩을 위한 단순 함수 추정 방법을 개발한 다음, ‘국가의 수도’ ‘밴드의 리드 싱어’와 같은 47개의 서로 다른 관계에 대한 함수를 정의했다. 이들이 올바른 개체 정보를 복구할 수 있는지 확인하기 위해 대상을 변경하면서 각 함수를 테스트했다. 예를 들어, ‘국가의 수도’에 대한 함수는 대상이 노르웨이인 경우 오슬로를 검색하고, 영국인 경우 런던을 검색해야 한다. 그 결과 함수는 60% 이상이 올바른 정보를 검색했는데, 이는 트랜스포머의 일부 정보가 이러한 방식으로 인코딩되고 검색된다는 것을 보여준다는 설명이다. 연구진은 “그러나 모든 것이 선형적으로 인코딩되는 것은 아니다. 일부 지식의 경우 모델이 해당 지식과 일치하는 텍스트를 생성했지만, 이에 대한 선형 함수를 찾을 수 없었다”라며 \"이는 모델이 해당 정보를 저장하기 위해 더 복잡한 작업을 수행하고 있음을 의미한다”고 설명했다. 또 ‘빌 브래들리는’이라는 프롬프트로 시작해 ‘스포츠를 한다’와 ‘대학에 다녔다’의 디코딩 함수를 사용, 모델이 브래들리 상원의원이 프린스턴대학교 재학 시 농구 선수임을 알고 있는지를 확인했다. 이는 모델이 텍스트를 생성할 때 특정 정보에 집중해도, 모든 정보를 인코딩한다는 것을 의미한다. 연구진은 이런 접근 방식으로 ‘속성 렌즈(attribute lens)’라는 탐지(Probing) 기술을 만들었다. 이는 트랜스포머의 다양한 레이어 내에서 특정 관계에 대한 특정 정보가 어디에 저장되어 있는지를 시각화하는 방법이다. 속성 렌즈는 자동으로 생성될 수 있으며, 모델에 대해 더 많은 것을 이해하는 데 도움이 되는 간소화된 방법을 제공할 수 있다고 전했다. 이 도구는 저장된 지식을 수정하고 AI 챗봇이 잘못된 정보를 제공하는 것을 방지하는 데 도움을 줄 수 있다. 앞으로 연구진은 지식이 선형적으로 저장되지 않는 경우, LLM에서 어떤 일이 발생하는지를 이해하기 위한 연구를 이어갈 예정이다. 박찬 기자 cpark@aitimes.com"
}