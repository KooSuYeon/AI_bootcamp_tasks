{
    "title": "알리바바, 수학 전용 모델 '큐원2-매스' 오픈 소스 출시",
    "created_at": "2024.08.09 18:05",
    "content": "알리바바가 수학 전용 소형언어모델(sLM) ‘큐원2-매스(Qwen2-Math)’를 공개했다. 오픈AI의 'GPT-4o', 앤트로픽의 '클로드 3.5 소네트', 구글의 '제미나이 1.5 프로' 등 전 세계의 모든 다른 모델보다 성능이 뛰어나다고 주장했다. 벤처비트는 8일(현지시간) 알리바바가 720억, 70억, 15억 매개변수의 영어 기반 수학 전용 모델 ‘큐원2-매스’ 시리즈를 오픈 소스로 출시했다고 보도했다. 이에 따르면 가장 큰 모델인 ‘큐원2-매스-72B-인스트럭트’ 버전은 수학경시대회 수준의 매스(MATH) 벤치마크에서 84% 점수를 기록하며, GPT-4o의 76.6%, 클로드 3.5 소네트의 71.1%, 구글의 매스-제미나이 1.5 프로(Math-Gemini Specialized 1.5 Pro)의 80.6% 등 유명 모델들의 성능을 능가했다. 또 초등학교 수학 벤치마크인 'GSM8K'에서도 96.7%의 점수로 경쟁자를 능가했으며, 대학 수준의 '칼리지 매스' 벤치마크에서도 47.8%의 높은 점수를 기록했다. 큐원2-매스-7B-인스트럭트 버전은 매스, GSM8K 및 칼리지 매스 벤치마크에서 각각 75.1%, 89.9%, 459%로 동급 최고의 점수를 기록했다. 70억 매개변수 규모에서는 마이크로소프트(MS)의 '오르카-매스-7B(Orca-Math-7B)' 모델이 86.81%로 가장 근접한 한 점수를 기록했다. 다만, 알리바바는 이번 벤치마크에서 MS의 오르카-매스 모델과 직접 비교하지 않았다. 가장 작은 버전인 큐원2-매스-1.5B-인스트럭트 버전도 매스에서 69.4%, GSM8K에서 84.2%, 칼리지 매스에서 44.2%의 점수를 기록하며, 4배 이상의 크기를 가진 모델에 근접한 성능을 보였다. 최근 수학 문제를 스스로 해결하는 AI가 부각되고 있다. 특히 수학 능력은 언어모델의 평가를 위한 주요한 잣대 중 하나다. 언어 항목과는 달리, 수학은 정확한 답이 하나만 존재하기 때문에 추론 능력을 가늠할 수 있다. 이런 이유로 인공일반지능(AGI) 개발에서도 수학적 능력이 중요하다고 지적된다. 한편 큐원2-매스는 월간 활성 사용자가 1억명을 넘는 모든 상업적 사용에 한해 별도의 라이선스를 받아야 한다. 박찬 기자 cpark@aitimes.com"
}