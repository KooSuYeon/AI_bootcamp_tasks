{
    "title": "SK \"국내 'H100' 2000장에 불과...인프라 구축에 집중할 것\"",
    "created_at": "2024.11.04 18:05",
    "content": "국내에 보유 중인 엔비디아 'H100' GPU가 아직 2000여장에 불과한 것으로 알려졌다. SK는 이런 점을 보완하기 위해 '인프라'에 집중하겠다고 밝혔다. SK텔레콤(대표 유영상)은 4~5일 양일간 열리는 ‘SK AI 서밋 2024’에서 ‘인공지능(AI) 인프라 슈퍼 하이웨이’ 구축 계획을 전격 공개, AI 인프라 기반의 변화를 이끌어 나가겠다고 밝혔다. 현장에는 3만5000여명의 인파가 몰렸다. 이 자리에서 빅테크 CEO와 SK가 강조한 주요 안건은 ‘인프라’였다. 유영상 SKT 대표는 메타 등 글로벌 빅테크가 평균 15만개의 GPU를 확보하고 있는 데 반해, 국내는 전체를 합쳐 2000개에 불과한 H100 GPU를 확보 중이라는 통계가 있다고 말했다. 이와 관련, 과학기술정보통신부 산하 소프트웨어정책연구소의 AI 기업 대상 설문조사에서는 국내 주요 1441개 AI 기업이 보유한 H100이 지난해 말 기준으로 총 1961개라는 집계가 나온 바 있다. 유 대표의 말대로라면 이후에도 H100 보유량은 거의 늘지 않았다는 것이다. 하지만 빅테크의 GPU 보유량은 최근 급속도로 증가하는 추세다. xAI는 올 하반기에 단일 클러스터에 10만장의 GPU를 투입했고, 메타는 그보다 더 큰 인프라를 구축했다고 밝힌 바 있다. 이는 파운데이션 모델 구축 능력에서 국내와 해외의 수준차를 실감케하는 부분이다. GPU가 적으면 모델 개발에 걸리는 시간이 길어질 수 밖에 없다. 이런 GPU 공급 부족을 빠르게 해소하기 위해 SKT는 수도권에 위치한 가산 데이터센터를 AI DC로 전환, 클라우드 형태로 GPU를 제공하는 서비스형 GPU(GPUaaS)를 출시할 계획이다. GPU를 직접 구입하는 것이 어렵기 때문에, 다른 클라우드 회사의 인프라를 빌려서 쓴다는 말이다. 이를 위해 12월에는 미국 클라우드 스타트업 람다와 협력을 통해 엔비디아 'H100' 기반 GPUaaS 출시를 시작으로 내년 3월에는 국내 최초로 GPU 'H200'을 도입할 예정이라고 전했다. 구체적인 수치는 공개하지 않았으나, 이후 고객사 수요에 맞춰 물량을 단계적으로 확대해 나갈 계획이다. 이처럼 SK는 ▲AI 데이터센터 ▲GPU 클라우드 서비스(GPUaaS) ▲엣지 AI 등 세 축을 중심으로 전국의 AI 인프라를 구축, 이를 기반으로 국내외 파트너들과 글로벌 시장에도 진출할 계획이고 밝혔다. SK그룹 역량과 파트너사 솔루션을 결집한 AI 데이터센터(DC) 테스트베드를 오는 12월 판교에 오픈할 계획이다. 엔비디아 최신칩과 하이닉스 HBM 등 첨단 AI 반도체와 차세대 액체 냉각 솔루션 3종(칩 접촉 냉각, 탱크형 액침 냉각, 샤시형 액침 냉각)을 비롯한 GPU 가상화 솔루션, AI 에너지 최적화 기술 등을 구현한 국내 유일의 테스트베드로 자리잡을 것이라고 설명했다. 기가와트(GW)급 AI DC를 통해 중장기적으로 ▲50조원 이상 신규 투자 유치 ▲55만명 이상의 고용 창출 ▲175조원 이상의 경제 효과 ▲지역 AI 첨단산업 육성등을 기대한다고 전했다. ‘한국형 소버린 AI’도 구현 계획도 밝혔다. SKT는 2025년부터 총 1000억원을 투자해 리벨리온의 NPU(신경망처리장치), SK하이닉스의 HBM, SK텔레콤과 파트너사들이 보유한 다양한 AI DC 솔루션을 결합할 예정이다. 마지막으로 전국에 연결된 통신 인프라를 활용해 AI DC와 ‘온디바이스AI’ 사이 간극을 해결할 수 있는 엣지 AI를 도입할 예정이다. 현재 SKT는 글로벌 파트너사들과 통신 인프라를 활용한 AI DC 구축 및 맞춤형 서버 개발을 진행하고 있다. 또 국내외 여러 기업과 협력해 헬스케어, AI로봇, AI CCTV 등 6개 영역에서 엣지AI 서비스 개발 기술실증(PoC)을 추진 중이다. 최태원 SK 회장도 이날 행사에 등장, 인프라와 에너지의 중요성을 강조했다. 특히 하나의 대형언어모델(LLM)을 구축하는데 최소 10기가와트(GW) 수준의 데이터센터가 필요하다고 설명했다. 1GW 수준의 데이터센터를 구축하는 데 약 400억달러(54조 9560억원) 이상이 필요하다는 것을 감안하면 10배 정도 수준의 비용이 들어갈 것이라고 덧붙였다. 결국 전력의 양, 송전의 방법, 탄소 감축 등 문제를 해결해야 한다고 전했다. 이에 SK는 그리드 형태가 아닌 독립적인 형태의 에너지를 가져올 수 있도록 고려 중이라고 강조했다. 현재 소형 원자로 형태를 개발 중이며 미래 AI데이터센터의 좋은 해결책이 될 것으로 전망했다. 이어 AI데이터센터 히트 컨트롤(온도 조절, 쿨링) 기술을 갖추기 위해 자체AI 데이터 센터의 기반 기술력을 개발 중이라고 밝혔다. 이 외에도 사티아 나델라 마이크로소프트 CEO, 젠슨 황 엔비디아 CEO, C.C. 웨이 TSMC CEO 등이 축하영상을 보내왔다. 특히 최 회장은 \"지난번 젠슨 황 CEO와 만났을 때, HBM4 공급을 6개월 당겨달라는 요청을 받았다\"라며 \"그렇게 해주겠다고 했다\"라고 밝혔다. 이어 \"SK는 인프라부터 에너지, 서비스 등 AI의 전 측면을 아우를 수 있는 몇 안 되는 기업\"이라고 강조했다. 장세민 기자 semim99@aitimes.com"
}