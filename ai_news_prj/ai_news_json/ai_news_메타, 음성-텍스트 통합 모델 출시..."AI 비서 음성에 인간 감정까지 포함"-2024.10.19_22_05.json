{
    "title": "메타, 음성-텍스트 통합 모델 출시...\"AI 비서 음성에 인간 감정까지 포함\"",
    "created_at": "2024.10.19 22:05",
    "content": "메타가 '인공지능(AI) 비서' 목소리에 인간과 같은 감정과 톤을 담을 수 있는 새로운 오픈 소스 모델을 출시했다. 얼마 전 출시된 GPT-4o의 '고급 음성 모드(AVM)'에 대응하려는 의도다. 메타는 18일(현지시간) 홈페이지를 통해 원활한 음성 및 텍스트 통합을 위한 멀티모달모델(LMM) '메타 스피릿 LM(Meta Spirit LM)'을 출시한다고 발표했다. 이 모델은 ▲스피릿 LM 베이스(Spirit LM Base)와 ▲스피릿 LM 익스프레시브(Spirit LM Expressive) 등 두가지 버전으로 구성됐다. 베이스 모델은 단순한 음성 전환 모델이지만, 익스프레시브는 톤이나 감정, 피치와 같은 인간 목소리의 뉘앙스를 그대로 반영한다. 메타 연구진은 기존의 TTS(텍스트-음성 변환)는 표현력이 부족하다고 지적했다. 이는 대부분 모델이 '자동 음성 인식(ASR)' 방식을 사용, 음성을 텍스트로 변환하고 LLM을 사용해 내용을 처리한 뒤 출력을 다시 음성으로 전환하기 때문이다. 하지만 메타의 모델은 텍스트-음성 변환이 아니라 '인터리빙(interleaving)' 방식을 사용해 텍스트와 음성 데이터셋을 모두 학습했다고 밝혔다. 특히 베이스 모델은 음성 토큰으로 인코딩해 단어를 표현하지만, 익스프레시브 모델은 음성 토큰에 피치와 스타일 토큰을 통합하는 등 한단계 더 발전했다고 전했다. 이를 통해 흥분이나 분노 같은 목소리 톤의 세부 사항을 포착하고 감정을 반영하는 음성을 생성할 수 있다는 것이다. 또 스토리텔링이나 감정 중심의 가상 비서, 향상된 대화형 대화 시스템을 포함한 복잡한 애플리케이션에 사용할 수 있다고 강조했다. 음성-텍스트 벤치마크인 'STSP'에서 익스프레시브 모델은 감정적 의도를 효과적으로 유지, ASR나 TTS 캐스케이드 방식 LLM보다 더 자연스럽고 감정적인 출력을 제공했다고 밝혔다. 메타는 지난달 커넥트 행사를 통해 라마 시리즈 최초의 멀티모달모델(LMM) '라마 3.2'를 공개했다. 또 메타 AI에 유명 배우들의 목소리를 포함했다. 마크 저커버그 CEO는 \"음성이 텍스트보다 AI와 상호작용하는 훨씬 더 자연스러운 방법이 될 것으로 생각한다\"라고 말했다. 이어 이번 모델로 다양한 목소리를 챗봇에 탑재하면, 오픈AI GPT-4o와 흡사한 성능을 갖추게 된다. 한편, 메타는 이날 지난 8월 논문으로 공개한 ‘자가학습 평가자(Self-Taught Evaluator)’ 모델도 출시했다. 이는 올바른 결과에 도달하는 추론 과정을 생성해 어떤 응답이 더 나은지 판단하는 '평가형 LLM(LLM-as-a-Judge)' 개념을 도입, 보상 학습 과정에서 인간의 라벨링 과정을 없애고 LLM으로만 학습 데이터를 생성한 모델이다. 이 때문에 'LM을 활용해 LLM의 품질과 정확성을 평가하는 모델'로 알려졌다. 또 이미지와 비디오를 위한 'SAM(Segment Anything Model) 2.1' 등 몇가지 기술을 추가 공개했다. 임대준 기자 ydj@aitimes.com"
}