{
    "title": "메타, 오픈소스 다국어 음성 인식 모델 공개",
    "created_at": "2023.05.23 19:37",
    "content": "1000개 이상의 언어로 음성을 인식하고 생성할 수 있는 인공지능(AI) 모델이 나왔다. 메타는 22일(현지시간) 블로그를 통해 4000개 이상의 음성 언어를 식별하고 1100개 이상 언어의 음성-텍스트 변환 및 텍스트-음성 변환을 제공하는 음성 인식 모델인 ‘MMS(Massively Multilingual Speech)’를 오픈소스로 공개했다고 밝혔다. 음성 인식은 AI에서 여전히 어려운 분야 중 하나다. MMS는 4000개의 언어로 된 신약 성경 오디오 데이터 세트와 언어당 평균 32시간의 데이터를 제공하는 1100개 이상의 언어로 된 신약 성경 오디오-텍스트 데이터 세트에 대해 MMS 모델을 훈련했다. MMS 모델은 wav2vec 2.0이라는 자가 지도 학습(Self-supervised learning)으로 맥락화된 표현과 개별 음성 단위를 함께 학습하는 방식이다. 먼저 레이블이 지정되지 않은 오디오 데이터 세트에서 일반 데이터 표현을 사전 훈련하고 레이블이 지정된 오디오-텍스트 데이터 세트에서 모델을 미세 조정하도록 훈련한다. 이 방식을 통해 훨씬 적은 데이터로 음성 인식 모델을 훈련할 수 있다. 메타는 결과 모델이 다른 음성 인식 모델과 비교해 모두 우수한 성능을 보였다고 주장했다. 메타에 따르면 언어 수가 증가함에 따라 성능은 감소하지만 매우 미미하다. 61개 언어에서 1107개 언어로 확대하면 문자 오류율이 약 0.4%만 증가하지만 언어 적용 범위는 17배 이상 증가한다. 현재 최고의 음성 인식 모델인 오픈AI의 ‘위스퍼(Whisper)’와 비교해 MMS 모델의 단어 오류율이 위스퍼의 절반 수준이지만 11배 더 많은 언어를 처리한다는 설명이다. 메타는 AI 연구 커뮤니티의 모든 사람들이 이 작업을 기반으로 모델을 개선하고 훈련하는 데 사용되는 MMS 데이터 세트와 도구를 오픈소스로 공유하고 있다. 메타는 “MMS의 목표는 더 많은 언어를 지원하도록 적용 범위를 확장하고 기존 음성 기술의 주요 과제인 방언 처리를 개선하는 것이다”고 말했다. 박찬 기자 cpark@aitimes.com"
}