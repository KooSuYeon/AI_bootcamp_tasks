{
    "title": "‘안전한 AI' 위해 국내외 리더 모였다...글로벌 AI 세이프티 컨퍼런스 개최",
    "created_at": "0",
    "content": " 인공지능(AI)의 안전성과 신뢰성 확보를 논의하기 위해 국내외 빅테크와 스타트업의 리더가 한자리에 모였다. 12일 서울 코엑스에서는 '생성 AI 레드팀 챌린지(Gen AI Korea 2024)' 2일차 행사로 '글로벌 AI 세이프티 컨퍼런스'가 진행됐다. 과학기술정보통신부가 주최하고 네이버와 셀렉트스타가 대표 공동 파트너사로 참여한 이번 행사는 전날 '레드팀 해커톤'을 진행, 600여명의 인파가 몰렸다. 컨퍼런스에도 여파가 이어져, 많은 참관객들이 자리했다. 키노트에는 에이단 고메즈 코히어 CEO와 에마드 모스타크 전 스태빌리티 AI CEO 등 글로벌 유명 인사는 물론 ▲하정우 네이버 퓨처 AI 센터장 ▲김세엽 셀렉트스타 CEO ▲댄 헨드릭스 센터 포 AI 세이프티 총괄▲크리스 메세롤 프론티어 모델 포럼(AI윤리안전 포럼) 대표 ▲김경훈 카카오 AI 세이프티 리더 ▲오혜연 한국과학기술원(KAIST) 교수 ▲에릭 데이비스 SK텔레콤 글로벌 텔코 담당 등이 나섰다. 최근 스태빌리티 AI CEO에서 자진 사퇴한 에마드 모스타크는 화상 통화로 토크에 참여했다. 진행은 황민영 셀렉트스타 부대표가 담당했다. 에마드 모스타크는 개인 SNS에 ‘자발적’ 사퇴를 언급하며 AI 업계의 권력 분산과 탈중앙화, 거버넌스를 강조한 바 있다. 이번 컨퍼런스에서도 마찬가지였다. 그는 “두달반 전쯤에 그만두게 됐다”라며 “AI가 인간 수준으로 진화하고 있는데도 여전히 거버넌스는 부재하다고 생각한다”라고 주장했다. 특히 몇몇 국가와 빅테크만이 ‘AI 데이터셋 접근권’을 가지고 있는 점을 지적했다. AI 규제도 AI 활용뿐만 아니라 ‘데이터셋의 인풋’부터 기준을 정립해야 한다고 설명했다. 그는 대부분 오픈 소스와 대형 모델의 경우 ‘영어’ 데이터를 기반으로 한다며, 진정한 AI 평등과 안전을 위해서는 ‘국가 언어별 특성을 접목한 LLM’이 개발돼야 한다고 전했다. 이를 위해 한국을 비롯한 타 국가에서도 데이터셋 발언권 및 결정권을 가져야 한다고 말했다. 현재는 이 목표를 실행할 수 있는 새 기업을 기획 중이라며, 나아가 헬스케어 분야의 버티컬 AI로도 활용하겠다는 목표를 전했다. “이젠 새 목표를 이룰 시간이 많아졌다”라고도 말했다. AI의 전망에 대해서는 “이젠 데이터의 규모보다, 최적화가 더 중요해질 것”이라며 “하나의 거대한 AGI보다 여러개의 모델이 협업하는 형태로 진행해야 더 안전할 것”이라고 예측했다. 마지막으로 현재 폐쇄형 AI, 즉 ‘논 거버넌스 AI’가 강세지만, 앞으로는 시민의 교육 및 트레이닝, 테스트를 거치는 ‘거버넌스 AI’와 ‘설명 가능한 AI’가 우위에 서야 한다고 강조했다. 에이단 고메스 코히어 CEO 역시 화상 통화로 토크에 나섰다. 그는 \"코히어는 곧 한국어 포함 10개국어를 지원하는 다중언어 LLM을 출시할 것\"이라고 전했다. 특히 다양한 기업을 상대로 검색 증강 생성(RAG) 기반 LLM을 구축해 온 만큼, 비교적 ‘안전한 AI’를 구축할 수 있다고 밝혔다. 약관이나 정책, 토픽 등 전체적인 부분을 기업과 상호 소통하며 결정했다는 설명이다. AI 규제에는 “긍정적인 입장”이라고 밝혔다. 하지만 ‘평등한 결과’를 불러올 수 있는 규제가 필요하다고 강조했다. 과도한 규제가 펼쳐질 경우 대응이 어려운 것은 스타트업으로, 결국 기존 메인 플레이어만이 살아남게 될 것이라는 의견이다. 코히어는 모델을 평가하는 수백명의 평가 집단을 구축하고 있으며, 다국어로 확장하며 규모를 더욱 키울 계획이라고 밝혔다. 독성 데이터의 경우 ‘아예 학습에서 배제’하던 기존 방법에서 ‘우선 학습한 후 나중에 해당 데이터를 언급하지 않도록 세이프티 필터를 추가하는 방식’으로 전환했다고 소개했다. 또 '하이퍼클로바'의 주역 하정우 네이버 퓨처 AI 센터장은 '초거대 생성AI 시대의 책임감 있는 AI를 위한 네이버의 노력'을 제목으로 강연을 진행했다. 특히 지난해 공개한 챗봇 '하이퍼클로바X' 구축 및 테스트 과정에서도 '안전한 답변'을 최우선으로 했다고 비하인드를 소개했다. 하 센터장은 \"일각에서는 하이퍼클로바X의 답변이 다소 심심하고 재미 없다는 지적이 있다\"라며 \"이는 사회 민감 이슈나 편향성을 최소화한 결과로, 예민한 문제를 건드리는 답변의 경우 기업에도 피해로 돌아올 수 있기 때문에 어쩔 수 없는 부분\"이라고 설명했다. 하지만 답변의 정확도나 성능에는 아무 관련이 없다고 강조했다. 예를 들면 \"우리가 공통으로 믿어야 하는 종교는 무엇인가\" \"국가에서 무상 급식을 지원해야 하는가\" \"삼성 주식에 투자하는 게 좋을까\" 등 불확실한 예측이나 추정, 편파적 의견을 유도하는 질문에는 중립을 지킬 수 있도록 '사회적 민감성 배제 학습'을 거쳤다고 밝혔다. 특히 '사회적으로 민감한 질문'을 정의하는 데에만 1년 반의 시간을 소요할 만큼 까다로운 과정이었다고 전했다. 더불어 레드팀 및 안전팀을 운영, 인원을 적극 채용 중이라고 강조했다. 김세엽 셀렉트스타 CEO는 '서비스별 맞춤 AI 신뢰성 평가' 기준이 필요하다고 주장했다. 업계에서도 LLM의 신뢰성 평가가 주요 이슈 중 하나라고 전했다. 올 하반기에는 6개월간 리더보드 챌린지를 운영할 예정이라고 전했다. 이후 연말에는 AI 허브에 전체 결과물을 모두 공개할 계획이다. 한편 컨퍼런스 종료 후에는 11일 진행한 ‘레드팀 챌린지’의 시상식을 진행했다. 장세민 기자 semim99@aitimes.com"
}