{
    "title": "누스, GPU 효율 최대 1만배 향상하는 도구 공개...\"유휴 GPU 인터넷으로 연결\"",
    "created_at": "2024.08.28 18:00",
    "content": "인공지능(AI) 스타트업 누스 리서치가 AI 모델의 학습 과정에서 GPU 효율을 최대 1만배 향상하는 도구를 공개했다. 이를 통해 이제 강력한 AI 모델을 클라우드 연결없이 소비자 수준의 인터넷 연결을 통해 공개 웹에서 훈련할 수 있게 됐다는 설명이다. 벤처비트는 27일(현지시간) 누스 리서치가 AI 모델을 훈련하는 각 단계에서 GPU 간에 전송해야 하는 정보의 양을 줄여주는 새로운 최적화 도구 ‘디스트로(DisTrO)’를 공개했다고 보도했다. 누스는 인기 오픈 소스 모델 ‘헤르메스(Hermes)’ 시리즈로 유명한 기업이다. 특히 지난 15일 출시한 '헤르메스 3'는 \"누구냐”라는 질문에 기억상실을 일으킨다고 알려져 화제가 됐다. 이번에 공개한 디스트로는 인기 있는 기존 훈련 알고리즘인 '올-리듀스(All-Reduce)'와 비교해 효율성이 857배 증가하고, 훈련 과정의 각 단계에서 전송되는 정보량이 74.4GB에서 86.8MB로 대폭 감소한 것으로 나타났다 전통적인 AI 훈련 방법은 모든 GPU에서 매우 높은 대역폭의 연결을 필요로 하는 반면, 디스트로는 이런 통신 오버헤드를 4~5배 감소시킨다. 이 감소는 훈련의 수렴 속도를 저해하지 않고도 대규모 모델을 100Mbps 다운로드 및 10Mbps 업로드 속도의 느린 인터넷 연결에서도 훈련할 수 있게 했다. 하지만 누스는 \"디스트로 방법이 잘 작동하는 최소 모델 크기는 메타의 '라마 2' 정도\"라고 밝히며, \"모델이 커지면 대역폭 감소 비율이 어떻게 변하는지, 즉 비율이 증가하는지 감소하는지 또는 일정하게 유지되는지는 아직 알지 못한다\"라고 밝혔다. 초기 테스트 결과, 대형언어모델(LLM)의 사전 훈련 단계에서 대역폭 요구 사항이 최대 1000배에서 3000배까지 감소할 수 있으며, 후속 훈련 및 미세조정에서는 1만배까지 달성할 수 있다. 또 디스트로는 LLM 뿐 아니라 스테이블 디퓨전이나 미드저니 등 대형 확산 모델에도 적용가능하다. 모델 훈련을 위해 모든 GPU를 한곳에 모으는 대신, 전 세계에 분산된 GPU를 소비자 인터넷을 통해 통신할 수 있다. 유휴 GPU를 연결해 훈련에 사용할 수 있다는 설명이다. 구체적으로 모델을 VRAM에 로드되는 분산 데이터 병렬 처리(DDP) 전략에 따라 작동하는 32개의 'H100' GPU를 사용해 평가됐다. 이런 설정을 통해 통신 요구 사항을 크게 줄이면서도 올-리듀스와 동일한 수렴 속도를 달성할 수 있었다는 설명이다. 이 결과는 디스트로가 모델 품질을 희생하지 않고도 기존 학습 방법을 대체할 수 있는 잠재력을 가지고 있으며, 대규모 분산 학습을 위한 확장 가능하고 효율적인 솔루션을 제공할 수 있음을 보여 준다. 디스트로는 고속 상호 연결에 대한 필요성을 줄임으로써 소비자 수준의 인터넷 연결을 사용하는 참가자들 간에도 분산 네트워크를 통한 모델 훈련을 가능하게 할 수 있다. https://twitter.com/NousResearch/status/1828121648383566270?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1828121648383566270%7Ctwgr%5E54a46d43c6f51e7ab9ac1e2058c7c247810015a5%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fventurebeat.com%2Fai%2Fthis-could-change-everything-nous-research-unveils-new-tool-to-train-powerful-ai-models-with-10000x-efficiency%2F 누스는 \"디스트로의 효율성은 기존 인프라의 사용을 최적화하고 대규모 데이터센터의 필요성을 줄임으로써 AI 훈련의 환경적 영향을 완화하는 데 도움이 될 수 있다\"라고 밝혔다. 또 \"LLM 훈련 방식을 리소스를 많이 소모하는 중앙 집중식의 데이터센터에서 벗어나, 다양한 지역에 분산된 컴퓨팅 자원을 활용하는 분산형 협력 접근 방식으로 전환할 수 있다\"고 강조했다. 박찬 기자 cpark@aitimes.com"
}