{
    "title": "메타, CoT 없이도 LLM 추론 향상하는 프롬프트 기술 ‘시스템 2 증류’ 공개",
    "created_at": "2024.07.15 18:05",
    "content": "메타가 대형언어모델(LLM)이 중간 단계의 프롬프트 생성 없이도 추론과 계획이 필요한 복잡한 작업을 처리할 수 있도록 하는 기술을 공개했다. 벤처비트는 12일(현지시간) 메타가 LLM 추론 능력을 향상하는 프롬프트 기술 ‘시스템 2 증류(System 2 distillation)’에 관한 논문을 아카이브에 게재했다고 전했다. 인지 과학에서는 패턴을 인식하고, 빠른 판단을 내리거나, 익숙한 기호를 이해할 때 사용하는 빠르고 직관적이며 자동적인 사고 방식을 '시스템 1'이라고 부른다. 반면 '시스템 2'는 수학 방정식을 풀거나, 여행을 계획하는 것과 같은 복잡한 문제 해결에 사용하는 느리고, 의도적이며, 분석적인 사고 방식을 의미한다. 일반적으로 LLM은 시스템 1에 가깝다. LLM은 텍스트를 매우 빠르게 생성할 수 있지만, 추론과 계획이 필요한 시스템 2 작업에는 어려움을 겪는다. 하지만 연구진은 LLM이 초기 질문에 대한 최종 답변을 제공하기 전에 중간 추론 단계를 생성하는 방식으로, 시스템 2 사고 방식을 구현할 수 있다고 설명했다. 예를 들어, LLM이 추론 과정을 단계별로 설명하도록 지시하는 ‘사고 사슬(CoT, Chain of Thought)’ 기법을 적용할 수 있다. 이 방법은 정확한 결과를 생성하는 데 도움이 된다. 하지만 일반적으로 응답에 대한 추론 비용과 지연 시간이 증가한다는 단점이 있다. 메타 연구진은 이 문제를 해결하기 위해 사고 사슬 같은 중간 단계 없이도 LLM이 복잡한 문제를 해결하도록 훈련 데이터셋을 구축하는 ‘시스템 2 증류’ 기술을 도입했다. 일반적으로 증류는 ‘교사(teacher)’라는 더 큰 모델을 사용, 작은 모델인 ‘학생(student)’을 훈련할 데이터셋을 구축한다. 예를 들어, 'GPT-4'나 '클로드 3'와 같은 프론티어 모델을 사용, '라마-2 7B' 같은 작은 모델에 대한 훈련 데이터를 생성하는 식이다. 다만 메타가 공개한 시스템 2 증류 기술은 별도의 교사 모델을 사용하지 않는다. 대신 RaR(수정 및 응답), S2A(시스템 2 주의), BSM(분기 해결 병합), CoT(사고 사슬) 등의 시스템 2 프롬프트 기술을 사용한다. 이를 통해 동일한 프롬프트에 대한 LLM의 답변을 수집하고 비교해, 가장 자주 나타나는 답변을 정답으로 간주해 초기 프롬프트와 함께 '증류 데이터셋'에 추가한다. 그다음 구축된 증류 데이터셋으로 LLM을 미세조정하면, LLM은 추론 단계를 건너뛰고 바로 답변으로 넘어가지만 정확도 높은 답을 생성할 수 있다. 연구진은 라마-2-70B를 사용해 RaR, S2A, BSM, CoT 등 시스템 2 프롬프팅 기술과 시스템 2 증류 방법을 평가했다. 그 결과, 시스템 2 증류는 복잡한 추론 과제에서 LLM의 성과를 크게 개선할 수 있으며, 시스템 2 프롬프팅의 정확도와 일치하거나 능가했다. 또 증류 모델은 중간 추론 단계를 거칠 필요가 없기 때문에 훨씬 더 빠르게 응답을 생성할 수 있었다. 다만 시스템 2 증류 기법이 모든 유형의 추론 문제를 해결할 수는 없다고 밝혔다. 예를 들어, 복잡한 수학 추론 과제는 CoT 프롬프팅과 같은 의도적인 추론이 필요할 수도 있다는 지적이다. 연구진은 “이런 방식을 이용해 LLM은 아직 잘할 수 없는 작업에 대한 추론에 더 많은 시간을 할애할 수 있을 것”이라고 주장했다. 박찬 기자 cpark@aitimes.com"
}