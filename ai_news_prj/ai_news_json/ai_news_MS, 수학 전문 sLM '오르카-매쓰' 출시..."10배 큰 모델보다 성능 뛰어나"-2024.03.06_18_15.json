{
    "title": "MS, 수학 전문 sLM '오르카-매쓰' 출시...\"10배 큰 모델보다 성능 뛰어나\"",
    "created_at": "2024.03.06 18:15",
    "content": "마이크로소프트(MS)가 수학 전문 경량언어모델(sLM) ‘오르카-매쓰(Orca-Math)’를 공개했다. 70억개의 매개변수를 가진 경량 모델로, 더 큰 대형언어모델(LLM)보다 뛰어난 수학 해결 능력을 보인다는 점에서 주목받고 있다. 벤처비트는 5일(현지시간) MS가 매개변수가 10배 더 큰 LLM의 성능을 능가하는 수학 전문 sLM ‘오르카-매쓰’를 오픈 소스로 출시했다고 전했다. 이에 따르면 오르카-매쓰는 ‘미스트랄 7B’ 모델을 기반으로, 고도로 맞춤화된 20만개의 수학 단어 문제로 구성된 합성 데이터셋에서 미세조정했다. 또 반복 학습 프로세스를 통해 스스로 문제 해결을 연습하도록 훈련했다. 기존의 오픈 소스 데이터셋에서 3만6217개의 샘플 수학 단어 문제를 수집했다. 각 문제에 대한 모델의 답변을 오픈AI의 GPT-4에 제공하고 피드백을  요청, 모델이 반복해 답변을 개선하도록 훈련했다. 오르카-매쓰 모델은 초중등 수준 8500개의 다양한 수학 단어 문제 및 질문으로 구성된 GSM8K 벤치마크에서 구글 '제미나이 울트라' 및 오픈AI 'GPT-4'를 제외한 대부분의 70억~700억개 매개변수의 LLM보다 뛰어난 성능을 보였다. GSM8K 벤치마크에서는 정확도 86.81%를 기록했다. 이 수치는 메타의 '라마-2-70B', 구글 '제미나이 프로', 오픈AI 'GPT-3.'5 등과 '메타매쓰-70B' '위저드매쓰-70B'와 같은 수학 전용 모델을 능가한 것이다. 오르카-매쓰의 기반 모델 미스트랄 7B는 37.83%를 기록했다. MS는 “비슷한 크기의 모델을 훨씬 능가하고 최소 10배 이상 큰 모델과 유사하거나 더 나은 성능을 달성, 작은 모델도 나은 해결 능력을 제공할 수 있다는 것을 보여줬다”라며 “미세조정을 위해 20만개의 수학 문제로 구성된 고품질의 소규모 합성 데이터를 사용한 것이 개선의 핵심”이라고 설명했다. 또 오르쓰-매쓰와 합성된 20만 수학 단어 문제 데이터셋을 연구 및 상업적 용도로 사용할 수 있도록 허깅페이스에 공개했다. 한편 최근 수학 문제를 스스로 해결하는 AI가 부각되고 있다. 지난 2월에는 상하이 AI실험실과 칭화대학교, 푸단대학교, 서던캘리포니아대학 연구진이 200억 매개변수의 수학 전용 모델 '인턴LM-매쓰(InternLM-Math)'을 개발, 벤치마크에서 GPT-4의 90% 수준까지 따라붙었다고 밝혔다. 지난 1월에는 구글 딥마인드 연구진이 국제 수학 올림피아드에 출제된 기하학 문제 30개 중 25개나 풀어낸 '알파지오메트리(AlphaGeometry)'를 오픈 소스로 공개한 바 있다. 국내에서도 지난 1월 스타트업 업스테이지가 매개변수 130억개(13B)의 '매쓰GPT'를 개발, 벤치마크에서 MS의 ‘토라(ToRA) 13B’ 모델을 능가했다고 밝혔다. 이처럼 수학 모델은 최근 몇개월 사이에 빠르게 소형화 및 고성능화되고 있다. 박찬 기자 cpark@aitimes.com"
}