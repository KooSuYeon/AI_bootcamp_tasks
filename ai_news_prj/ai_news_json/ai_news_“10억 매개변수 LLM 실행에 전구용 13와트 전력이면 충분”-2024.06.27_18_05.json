{
    "title": "“10억 매개변수 LLM 실행에 전구용 13와트 전력이면 충분”",
    "created_at": "2024.06.27 18:05",
    "content": "13와트(W)의 전력만으로 10억 매개변수 규모의 대형언어모델(LLM)을 실행하는 방법이 등장했다. 엔비디아 'H100'과 같은 데이터센터 GPU에 필요한 700W 전력보다 약 50배 더 ​​효율적이다. 톰스하드웨어는 26일(현지시간) UC 산타 크루즈 연구진이 LLM 실행에서 가장 비용이 많이 드는 요소를 제거하는 방식에 관한논문을 아카이브에 게재했다고 보도했다. 이에 따르면 연구진은 LLM에서 가장 비용이 많이 드는 요소인 ‘행렬 곱셈(matrix multiplication)’을 제거하고 맞춤형 하드웨어에서 알고리즘을 실행하면, 10억개 매개변수 규모의 LLM을 단지 13W의 전력으로 구동할 수 있다는 것을 발견했다. 이는 전구 하나를 켜는 데 필요한 에너지 정도이며, 일반적인 하드웨어보다 50배 이상 효율적이다. 지금까지 LLM을 구동하는 신경망은 모두 행렬 곱셈이라는 기법을 사용했다. LLM에서는 단어가 숫자로 표현되며, 이 숫자들은 행렬로 구성된다. 행렬은 서로 곱해져서 언어를 생성하며, 특정 단어의 중요성을 평가하거나 문장이나 단락 내의 단어들 간의 관계를 강조하는 작업을 수행한다. LLM은 수조개의 이런 숫자를 포함하고 있다. 행렬이 클수록 신경망이 학습할 내용이 많아지며 계산도 늘어난다. 알고리즘이 행렬을 곱하려면, 이 행렬들을 어디엔가 저장했다가 계산할 때 불러와야 한다. 이는 행렬을 물리적으로 분리된 수백개의 GPU에 저장함으로써 해결한다. 서로 다른 GPU에 있는 행렬의 숫자를 곱하려면 데이터 이동이 필요하며, 이 과정이 신경망의 시간과 에너지 비용의 대부분을 차지한다. 연구자들은 동일한 성능과 정확성을 유지하면서 신경망에서 행렬 곱셈을 제거하기 위해 두가지 방법을 결합했다. 먼저 행렬 내의 모든 숫자를 -1, 0, 1의 세 가지 값 중 하나로 변환했다. 이를 통해 숫자를 곱하는 대신, 더하는 방식으로 계산이 가능해졌다. 그다음 시간 기반 계산(time-based computation)을 도입해 네트워크에 효과적인 메모리를 제공, 더 적은 연산을 수행하면서 빠르게 동작할 수 있게 했다. 한 행렬의 모든 숫자를 다른 행렬의 모든 숫자와 곱하는 일반적인 방식 대신, 동일한 수학적 결과를 얻기 위한 전략을 개발했다. 이 접근 방식에서는 행렬을 겹쳐 놓고 가장 중요한 연산만을 수행한다. 연구진은 \"행렬 곱셈에 비해 상당히 가벼운 방법\"이라며 \"우리는 비용이 덜 드는 연산으로 비싼 연산을 대체했다\"라고 설명했다. 메타의 최신 모델 '라마 3'와 자신들의 모델을 비교했을 때, 심지어 수십억 개의 모델 매개변수 규모에서도 동일한 성능을 달성할 수 있었다고 전했다. 연구진은 자신들의 신경망을 GPU에서 작동하도록 설계해 오픈 소스로 공개했다. 표준 GPU에서 다른 모델보다 약 10배 적은 메모리를 소비하고 약 25% 더 빠르게 작동하는 것을 확인했다. LLM을 실행하는 데 필요한 메모리 양을 줄이는 것은 스마트폰과 같은 작은 메모리 장치에서도 알고리즘을 전체 용량으로 실행할 수 있다는 의미다. 그러나 엔비디아의 GPU 하드웨어는 행렬 곱셈에 최적화되어 있기 때문에, 연구진은 소비 에너지를 더 줄이기 위해 신경망에 최적화된 맞춤형 하드웨어를 설계했다. 연구진은 FPGA라는 프로그래밍 가능한 회로 위에 맞춤형 하드웨어 프로토타입을 개발했다. 이 하드웨어를 사용하면 모델은 단지 13W의 전력으로 사람이 읽는 속도보다 더 빠르게 단어를 생성할 수 있다. 반면 GPU를 사용할 경우 약 700W의 전력이 필요하다. 연구진은 \"현재의 결과는 매우 만족스러운 수준이지만, 더 나은 결과를 만드는 것도 어렵지는 않다\"라며 \"13W로 이런 작업을 수행할 수 있다면 전체 데이터 센터에 해당하는 컴퓨팅 성능으로 무엇을 할 수 있는지 상상해 보라”라고 강조했다. 박찬 기자 cpark@aitimes.com"
}