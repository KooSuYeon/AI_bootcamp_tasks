{
    "title": "메타, 오픈소스 멀티모달 모델 ‘이미지바인드’ 공개",
    "created_at": "2023.05.10 16:17",
    "content": "메타가 텍스트(문자), 이미지, 오디오 등 6가지 유형의 정보를 묶어 학습할 수 있는 새로운 오픈소스 AI 모델을 공개했다. 대규모 언어 모델 ‘라마(LLaMA)’, 이미지 분할 모델 ‘SAM(Segment Anything Model)’에 이어 오픈소스로 AI 모델을 잇따라 발표하며 눈길을 끌고 있다. 메타는 9일(현지시각) 텍스트, 이미지·비디오, 오디오뿐 아니라 심도(3D), 열화상(적외선), 동작과 위치를 계산하는 관성 측정 장치(IMU) 센서 데이터까지 총 6가지 정보를 묶어 학습할 수 있는 AI 모델 ‘이미지바인드(ImageBind)’를 공개했다고 밝혔다. 6가지 서로 다른 양식의 정보를 동시에 학습, 이해할 수 있는 멀티모달 AI 모델이 공개된 건 이번이 최초다. 연구에 무료로 활용 가능한 오픈소스 기반 모델이라는 점에서 의미가 크다는 게 업계의 평가다. 여러 유형의 데이터를 처리하는 이미지바인드와 같은 신경망을 멀티모달 모델이라고 한다. 일반적으로 멀티모달  모델은 수집하는 각 유형의 데이터를 별도의 임베딩에 저장한다. 예를 들어 이미지와 텍스트를 처리하는 신경망은 하나의 임베딩에 이미지를 저장하고 다른 임베딩에 텍스트를 저장할 수 있다. 반면 메타의 이미지바인드 모델은 여러 유형의 데이터를 별도로 저장하는 대신 결합하여 단일 임베딩에 보관한다. 이를 통해 복잡한 컴퓨팅 작업을 지원할 수 있다. 특히 이 모델은 여러 유형의 데이터를 한 번에 분석할 수 있다. 예를 들어 사용자는 이미지바인드가 스케치와 텍스트 설명을 기반으로 자동차 이미지를 생성하도록 할 수 있다. 이미지바인드는 인간이 여러 감각에서 정보를 수집하고 모든 정보를 동시에 전체적으로 처리할 수 있는 방법과 유사한 접근 방식을 취한다. 예컨대 사진 속 물체가 어떻게 소리를 내고 3D처럼 보이는지, 얼마나 따뜻하고 추운지, 어떻게 움직이는지에 대한 전체적인 이해를 기계에 제공할 수 있다. 이미지바인드는 이미지 또는 비디오를 입력으로 사용해 관련된 오디오를 검색하거나 오디오를 입력해 관련 이미지를 검색하거나 텍스트로 관련 이미지 및 오디오 클립을 검색할 수 있다. 오디오, 이미지 및 프롬프트를 조합해 관련된 이미지 검색도 가능하다. 또 이미지바인드를 생성 AI 모델과 결합하면 오디오에서 이미지를 생성할 수도 있다. 메타는 \"이번 연구는 기계가 다양한 형태의 정보를 동시에 전체적으로 직접 학습할 수 있는 인간의 능력에 한걸음 더 다가설 수 있는 접근법\"이라며 \"향후 촉각, 화법, 후각, 뇌 fMRI(기능적 자기공명영상) 신호와 같은 가능한 많은 감각을 연결하면 인간 중심 AI 모델이 가능해질 것\"이라고 강조했다. 박찬 기자 cpark@aitimes.com"
}