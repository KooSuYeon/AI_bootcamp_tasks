{
    "title": "메타, LLM 성능 높이는 '멀티 토큰 예측' 아키텍처 공개",
    "created_at": "2024.05.07 18:00",
    "content": "메타가 대형언어모델(LLM)의 예측 토큰 수를 늘려, 정확성과 속도를 개선할 수 있다는 연구 결과를 발표했다. 이를 통해 모델 속도를 최대 3배 빠르게 할 수 있다고 주장했다. 벤처비트는 6일(현지시간) 메타와 에콜 데 퐁 파리테크, 파리 사클레 대학 등 연구진이 여러 토큰을 동시에 예측하는 '멀티 토큰' 예측 기법에 관한 논문을온라인 아카이브에 게재했다고 전했다. 멀티 토큰 예측은 전통적인 자동회귀 언어 모델이 한번에 토큰 하나씩 예측하는 것과 달리, 여러 토큰을 동시에 예측함으로써 모델 성능을 향상할 수 있는 방법이다. 연구진은 “모든 유형의 모델 및 언어 작업에 보편적인 솔루션은 아니지만, 일부 영역에서는 생성 작업에서 3배의 속도와 더 나은 정확도를 제공한다”라고 말했다. LLM을 훈련하는 고전적인 방법은 ‘다음 토큰 예측(next-token prediction)'으로 알려져 있다. 이는 모델에 일련의 토큰이 주어지고 다음 토큰을 예측해야 하는 자기 지도 학습 기술이다. 예측된 토큰을 입력에 추가하고 한번에 토큰 하나씩 프로세스를 반복하는 식이다. 멀티 토크 예측은 기존의 트랜스포머 아키텍처를 기반으로 하지만, 단일 출력 대신 여러 독립적인 출력 헤드를 통해 여러 토큰을 동시에 예측하는 것이 특징이다. 추론 과정에서는 기본적인 다음 토큰 예측을 유지하면서, 추가적인 출력 헤드를 사용해 디코딩 속도를 빠르게 할 수 있다. 이를 통해 실행 시간을 최대 세배까지 단축한다. 연구 결과에 따르면 큰 모델일수록 멀티 토큰 예측의 효과가 증가하는 것으로 나타났다. 예를 들어, 4토큰 예측을 위해 학습한 경우 67억 및 130억 매개변수 모델은 MBPP 코딩 벤치마크에서 단일 토큰 예측에 비해 정확성이 향상된 반면, 3억 매개변수 모델은 더 나쁜 결과가 나왔다. 특히 바이트 수준에서 토큰화를 진행하는 실험에서는 멀티 토큰 예측이 단일 바이트 예측 모델을 크게 앞서는 결과를 나타냈다. 이는 사전에 정의된 어휘 없이 작은 정보 조각을 사용해야 하는 애플리케이션에 특히 중요하다는 평가다. 연구진은 “이와 같은 멀티 토큰 예측 기술은 추가 비용 없이도 기존 모델보다 더 강력하고 빠른 트랜스포머 모델을 훈련시킬 수 있는 효과적인 방법”이라며 “앞으로 이 기술의 다양한 응용 가능성을 탐구할 계획”이라고 덧붙였다. 박찬 기자 cpark@aitimes.com"
}