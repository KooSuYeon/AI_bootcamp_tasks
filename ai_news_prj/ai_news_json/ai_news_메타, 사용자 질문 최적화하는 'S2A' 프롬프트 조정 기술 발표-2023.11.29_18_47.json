{
    "title": "메타, 사용자 질문 최적화하는 'S2A' 프롬프트 조정 기술 발표",
    "created_at": "2023.11.29 18:47",
    "content": "대형언어모델(LLM)의 추론 능력을 향상하는 새로운 프롬프트 조정 기술이 나왔다. '지침 조정(instruction fine-tuned) LLM'을 통해 사용자 입력 프롬프트에서 불필요한 텍스트를 제거하는 방식이다. 벤처비트는 28일(현지시간) 메타 연구진이 오해의 소지가 있거나 관련 없는 정보를 제거하는 방식으로 사용자의 프롬프트를 수정, 관련 있는 데이터에만 집중함으로써 LLM이 답변 및 추론 작업을 정확하게 수행할 수 있도록 해주는 ‘시스템 2 어텐션(S2A)’ 기술을 공개했다고 보도했다. 이에 따르면 초기 실험에서 S2A를 사용한 LLM의 성능이 크게 향상된 것으로 나타났으며, 안정적인 추론 기능이 요구되는 애플리케이션에 유용할 것이란 분석이 나왔다. 추론에서 LLM의 성능은 효과적으로 프롬프트를 작성하는 프롬프트 엔지니어링 기술로 향상될 수 있지만, 프롬프트에 관련이 없거나 독선적인 정보가 포함되면 LLM이 불안정해질 수 있다. 예를 들어 사용자 질문에 개인적 추측이나 의견이 포함된 경우, 모델은 정답을 제공하기보다는 사용자의 입력을 단순히 확인하거나 반영하려는 경향을 보인다. 이런 문제는 LLM에 사용되는 딥러닝 아키텍처인 '트랜스포머'의 어텐션(atention) 메커니즘 때문에 발생한다. 텍스트 내 상관관계를 밝혀내는 어텐션 메커니즘은 다음 토큰을 예측하는 능력을 향상한다. 반면 이에 따라 모델은 컨텍스트에 존재하는 잘못된 단서에 취약해진다. 반복할 때마다 텍스트에서 잘못된 단어가 반복될 가능성이 커지고, 모델이 특정 주제에 집착하게 만드는 패턴을 형성한다. LLM은 작업과 직접적인 관련이 없더라도 프롬프트에 포함된 모든 상황별 정보를 사용해 응답을 생성하기 때문이다. S2A 접근 방식은 먼저 프롬프트에서 불필요한 컨텍스트 요소를 제거한 다음 텍스트를 다시 생성하고 이를 최종 응답을 생성하는 데 사용한다. 추론을 왜곡하지 않도록 구성된 지침-답변 쌍의 데이터로 미세조정한 '지침 조정 LLM'을 사용, 컨텍스트를 다시 작성한다. 결국 변경된 컨텍스트가 LLM으로 전달, 최종 답변을 생성하는 방식이다. 지침 조정 LLM 대신 '제로샷 프롬프트'를 LLM에 보내 원래 프롬프트에 대해 원하는 프롬프트를 재생성하도록 S2A를 구현할 수 있다. 즉 LLM에 컨텍스트를 재생성하도록 지시, 원래 프롬프트에서 관련성이 높은 컨텍스트를 추출하는 식이다. 연구진은 관련 없는 정보, 오해의 소지가 있는 사실, 독선적인 문장 등을 포함하는 질문 답변, 장문 추론, 수학 단어 문제 등 다양한 문제에 대해 S2A를 테스트했다. 결과 S2A는 자기주장이 강한 질문에도 쉽게 흔들리지 않는 응답을 생성하고, 긴 형식의 콘텐츠 생성에서 객관성을 잘 유지하는 것으로 나타났다. 또 관련 없는 문장이 포함된 수학 문제를 해결하는 데 있어 탁월한 성능을 보여준 것으로 알려졌다. 연구진은 \"인상적인 결과에도 불구하고 S2A가 항상 성공하는 것은 아니며, 모델이 가끔 허위 상관관계에 의해 영향을 받는 경우가 있다\"라고 인정했다. 더불어 생성 작업에 단계를 추가하고 원래 프롬프트에서 상황별 정보를 추출해야 하기 때문에 LLM 비용을 증가하는 단점이 있다고도 밝혔다. 박찬 기자 cpark@aitimes.com"
}