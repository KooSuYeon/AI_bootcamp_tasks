{
    "title": "수츠케버 \"10년간 AI 주도한 스케일링 법칙 넘을 것...안전한 초지능 개발이 목표\"",
    "created_at": "2024.09.06 18:05",
    "content": "일리야 수츠케버 SSI 창립자도 인공일반지능(AGI) 개발이 우선 목표라고 밝혔다. 여기에 정렬(alignment)을 적용, '안전한 초지능(safe superintelligence)'을 만들겠다는 계획이다. 로이터는 5일(현지시간) 수츠케버 창립자와의 인터뷰를 통해 SSI(Safe Superintelligence)라는 회사를 설립한 이유와 계획 등을 전했다. 전날에는 SSI의 투자 유치 사실을 가장 먼저 보도하기도 했다. 수츠케버는 오픈AI의 수석 과학자로, 샘 알트먼 CEO 축출 사태를 주도하며 유명해졌다. 하지만 이에 앞서 존경받는 AI 기술자 중 한명으로 잘 알려져 있다. 특히, '스케일링(scaling) 가설'의 지지자로 꼽히는데, 이는 AI 학습에 사용하는 데이터와 컴퓨팅이 증가할수록, AI 모델 성능이 증가한다는 내용이다. 이는 현재 AI 모델 개발의 원칙으로 통한다. 오픈AI 재직 시 '테스트-시간 계산(test-time computation)'이라는 이론을 발전, 현재 '스트로베리'로 알려진 '큐스타'의 배경을 만들었다. 또 제프리 힌튼 토론토대학교 교수 밑에서 교육을 받았으며, 그처럼 AI 안전을 강조하며 오픈AI의 초정렬 팀을 설립했다. 그는 먼저 현재 AI 발전을 끌어온 기존 스케일링과는 다른 개념으로 초인공지능을 개발하겠다고 밝혔다. \"기존 작업과는 조금 다른 산을 발견했다. 이 산꼭대기에 오르면 패러다임이 바뀌고, AI에 대해 우리가 알던 모든 것도 변할 것\"이라며 \"바로 이 시점에서 가장 중요한 초지능 안전 작업이 이뤄질 것\"이라고 말했다. 이어 \"우리의 첫번째 제품은 안전한 초지능이 될 것\"이라고 강조했다. 이어 \"그 시점에 도달하면 세상이 너무 많이 변할 것이기 때문에 무엇을 해야 할지 예측하는 것은 어렵다\"라며 \"AI가 무슨 일을 하고 있는지 이해하기도 어려워지며, 세상은 우리가 생각하는 대로 결정되지 않을 가능성이 크다\"라고 설명했다. 새로운 방식이 무엇인지는 자세하게 밝히지 않았다. 다만 \"모두가 스케일링 가설이라고만 말하지만, 무엇을 스케일링하고 있는지에는 소홀하다\"라고 지적했다. \"지난 10년 동안 딥 러닝의 큰 돌파구는 스케일링 가설에 대한 특정 공식이었다\"라며 \"하지만 그것은 변할 것이고, 그에 따라 시스템의 역량이 그게 증가할 것\"이라고만 설명했다. 오픈AI에서 많은 비판을 받았던 오픈 소스에 대한 의견도 밝혔다. \"현재는 모든 AI 회사가 주요 작업을 오픈 소스로 공개하지 않는다. 우리도 마찬가지\"라며 \"하지만 특정 요인에 따라 관련 초지능 안전 작업을 오픈 소스로 공개할 기회가 많을 것으로 생각한다. 전부는 아니더라도 일부는 확실히 있을 것\"이라는 말이다. 회사를 일반적인 AI 회사가 아닌, 'AI 안전 회사'로 포지셔닝한 데 대해서도 이유를 밝혔다. \"실제로 이 분야에 대해 매우 높은 평가를 내리고 있다\"라며 \"모든 회사는 AI가 계속 발전함에 따라 어느 시기에는 그들이 직면한 도전의 본질을 깨닫게 될 것으로 본다\"라고 말했다. \"그래서 우리는 다른 누구도 할 수 없다고 생각하는 대신, 우리가 그 문제에 기여할 수 있다고 생각한다\"라고 강조했다. 임대준 기자 ydj@aitimes.com"
}