{
    "title": "메타, 첫 멀티모달모델 '라마 3.2' 출시...\"오픈 소스로 폐쇄형 잡을 것\"",
    "created_at": "2024.09.26 07:10",
    "content": "메타가 '라마' 시리즈 중 이미지와 텍스트를 모두 이해하는 첫번째 대형멀티모달모델(LMM)을 출시했다. 오픈 소스 대표 LMM으로, 오픈AI나 앤트로픽 등의 폐쇄형 모델과 경쟁할 것이라고 선언했다. 메타는 25일(현지시간) 미국 캘리포니아주 멘로파크 본사에서 연례 개발자 컨퍼런스 '커넥트 2024'를 열고 '라마 3.2'를 공개했다. LMM은 매개변수 11B와 90B의 소형 및 중형 모델 두가지로 출시됐다. 여기에 모바일 및 엣지 장치에 적합한 온디바이스 AI용 1B 및 3B 텍스트 전용 모델이 추가됐다. 마크 저커버그 메타 CEO는 기조연설에서 \"이것은 우리의 첫번째 오픈소스 멀티모달 모델\"이라며 \"시각적 이해가 필요한 많은 애플리케이션을 가능하게 할 것\"이라고 말했다. 이전 버전과 마찬가지로 라마 3.2는 12만8000 토큰 컨텍스트 길이를 가지고 있어 수백페이지짜리 텍스트를 입력할 수 있다. 메타는 이날 처음으로 공식 '라마 스택 배포판'을 공유, 개발자가 온프레미스와 디바이스, 클라우드, 단일 노드 등 다양한 환경에서 모델을 사용할 수 있도록 했다. 저커버그 CEO는 \"오픈 소스는 이미 가장 비용 효율적인 사용자 정의형, 신뢰할 수 있고 성능이 뛰어난 옵션이 됐다\"라며 \"우리는 업계에서 전환점에 도달했으며, 업계 표준이 되기 시작했다. AI의 리눅스라고 부른다\"라고 강조했다. 또 메타는 두달 전에 '라마 3.1'을 출시했으며, 이 모델이 지금까지 10배의 성장을 달성했다고 밝혔다. 저커버그 CEO는 \"라마는 계속해서 빠르게 개선되고 있다. 점점 더 많은 기능을 가능하게 하고 있다\"라고 설명했다. 라마 3.2는 이미지 인식 및 시각적 이해 작업에서 앤트로픽의 '클로드 3 하이쿠'와 오픈AI의 'GPT4o-미니'와 경쟁할 수 있다고 밝혔다. 지시 따르기, 요약, 도구 사용 및 프롬프트 다시 쓰기와 같은 영역에서는 구글의 '젬마'나 마이크로소프트의 '파이 3.5-미니'보다 성능이 뛰어나다는 벤치마크를 공개했다. 라마 3.2 모델은홈페이지과 허깅페이스 및 메타의 파트너 플랫폼에서 다운로드할 수 있다. 한편, 메타는 100만명 이상의 광고주가 자사의 생성 AI 도구를 사용하고 있으며, 지난달 1500만개의 광고가 이 도구를 사용해 만들어졌다고 밝혔다. 메타 생성 AI를 사용한 광고는 그렇지 않은 광고보다 클릭률이 11%, 전환율이 7.6% 더 높았다고 주장했다. 또 소비자를 위해 메타 AI에 '목소리'를 더했다. 라마 3.2에는 유명 배우 주디 덴치와 아콰피나, 존 시나 등의 목소리가 포함됐다고 공식 발표했다. 저커버그 CEO는 \"음성이 텍스트보다 AI와 상호작용하는 훨씬 더 자연스러운 방법이 될 것이라고 생각한다\"라고 말했다. 마지막으로 \"메타 AI가 전 세계에서 가장 많이 사용되는 어시스턴트가 될 것\"이라며 \"아마도 이미 그 단계에 있을 것\"이라고 덧붙였다. 임대준 기자 ydj@aitimes.com"
}