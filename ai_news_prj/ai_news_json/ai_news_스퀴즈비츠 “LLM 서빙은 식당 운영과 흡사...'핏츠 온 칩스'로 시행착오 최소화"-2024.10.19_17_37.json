{
    "title": "스퀴즈비츠 “LLM 서빙은 식당 운영과 흡사...'핏츠 온 칩스'로 시행착오 최소화\"",
    "created_at": "2024.10.19 17:37",
    "content": "인공지능(AI) 전문 스퀴즈비츠(대표 김형준)가 최적의 대형언어모델(LLM) 서빙 시나리오를 찾아주는 솔루션 ‘핏츠 온 칩스(Fits on Chips)’를 선보인다고 19일 밝혔다. 2022년 설립된 스퀴즈비츠는 서울대학교, 포스텍, 한국과학기술원(KAIST) 연구진과 인공지능(AI) 분야의 오랜 전문가들을 중심으로 구성한 기업이다. AI 경량화와 가속화 기술 전문으로, 주요 AI 및 머신러닝 학회에 70편 이상의 논문을 제출한 바 있다. AI 반도체 설계 경험을 기반으로 하드웨어 특성에 맞는 최적화를 다수 기업과 진행, 전문성을 갖췄다. GPU, CPU, NPU 등 하드웨어와 고급 알고리즘의 결합으로 효율성을 최적화, AI 서비스 비용 절감 효과를 제공하는 것이 특기다. 신제품 핏츠 온 칩스도 이런 기술력을 바탕으로 개발됐다. 김승렬 스퀴즈비츠 프로덕트 매니저 겸 디자이너는 우선 'LLM 서빙'에 대해 설명했다. “LLM 서빙은 세가지 요소를 조화하는 것이 핵심\"이라며, ▲LLM 사용자의 요청 ▲GPU(인프라) ▲서빙 프레임워크(vLLM, 텐서RT LLM 등)을 꼽았다. 이는 모델을 직접 구축하고 운영하는 경우에 해당한다. 물론 API를 통해 LLM을 끌어다 사용하는 경우가 많지만, 보안이나 비용 등의 이유로 모델을 구축하는 사례가 늘어나며 LLM 서빙의 중요성도 부각되고 있다. 하지만 어떤 하드웨어 인프라를 기반으로 무슨 LLM을 어떤 방식으로 서빙할지 결정하는 과정은 생각보다 더 번거롭다. 이를 해결하기 위해 등장한 것이 핏츠 온 칩스다. 김 매니저는 “LLM 서빙은 식당 운영에 비유하면 이해가 쉽다”라고 소개했다. 우선 LLM 사용자의 요청은 ‘식당을 찾은 손님의 주문’에 비유했다. 직장인이 많은 지역의 식당은 점심에 가장 많은 사람이 몰려들지만, 여행지의 식당은 특정 식사 시간이 아니더라도 고르게 수요가 발생한다. 조리 시간도 중요한 부분이다. 누군가는 오래 걸리더라도 퀄리티가 높은 메뉴를 원하지만, 빠르고 간단한 메뉴를 찾는 사람도 있다. GPU는 요리사에 해당한다. 요리사 중에서는 한번에 많은 요청을 일정한 속도로 처리하는 사람도 있지만, 너무 많은 요청이 동시에 들어올 경우 당황하거나 속도가 느려지는 사람도 있다. 요리사가 커버할 수 있는 테이블 수는 달라질 것이고, 이런 차이에 따라 역할도 달라질 수밖에 없다. 프레임워크는 식당 운영 정책에 비유할 수 있다. 2시간 단위로 예약을 운영하며 동시에 여러 팀에 동일한 코스를 제공하는 식당이 있는가 하면, 10분 단위로 예약을 운영하며 다양한 주문에 맞춰 요리를 내놓는 집도 있다. vLLM이나 텐서RT LLM 등 프레임워크의 상세 설정과 같은 운영 방식이 이에 해당한다. 이제 식당을 운영하는 사장, 즉 LLM을 직접 서빙해야 하는 기업이 무엇을 해야 하는지는 확실해진다. 수요자의 종류와 요청을 파악한 뒤 적합한 운영 정책을 개발, 이에 맞는 인프라를 택해야 한다. 무조건 가장 뛰어난 요리사를 많이 고용하는 것이 답이 아니라는 말이다. 테이블을 너무 적게 운영하거나 사람이 몰리지 않는 장소에 식당을 열면 직원 월급도 주기 어려워진다. 손만 빠른 요리사에게 파인 다이닝을 맡기는 것도 효율적이지 않다. 한정된 비용과 GPU 자원, 능력으로 사용자 요청에 맞는 LLM 서빙 방식을 결정해야 한다. 식당 운영에도 시행착오를 통한 노하우가 필요한 것처럼, 이 과정도 수많은 테스트를 필요로 한다. 핏츠 온 칩스는 ▲모델 선택 ▲미세조정 ▲장치와 프레임워크 설정 ▲평가 ▲배포 등 전체 과정을 지원, LLM 서빙의 어려움을 획기적으로 줄여주는 역할을 한다고 설명했다. 김승렬 매니저는 \"물론 API를 사용하는 기업은 '프랜차이즈 식당'을 운영하며 시행착오를 줄이는 케이스\"라며 \"하지만 앞서 말했듯 LLM 서빙이 필수적인 분야가 늘어나고 있다\"라고 전했다. 이 솔루션은 사실 내부에서 연구를 돕기 위해 개발해 사용하던 것이다. 하지만, 시장 수요가 충분하다는 판단에 따라 출시한 경우다. 특히 경량화 기술을 심도 있고 빠르게 분석하기 위해 개발한 만큼, 실제 필요와 편리성에 철저하게 초점을 맞췄다고 밝혔다. 출시를 위해서는 인터페이스(UI)와 사용자경험(UX)에 힘을 줬다. 허깅페이스에서 모델과 데이터셋을 쉽게 불러올 수 있으며 이후 기준에 따른 모델 평가, 배포까지 한 페이지에서 처리할 수 있다. 성능 수치를 일일이 비교하기 번거로울 것에 대비, 그래프화로 즉각적인 시각화 및 인사이트 획득이 가능하다. 이로 인해 사용자는 다양한 프로젝트에 맞춰 쉽게 실험을 설계하고, 모델 벤치마크를 실시간으로 요청하고 확인할 수 있다고 전했다. 특히 벤치마크 기준으로 'TTFT(time to first token)'와 'TPOT(time per output token)'라는 항목을 새로 도입했다. TTFT는 모델이 첫 출력을 생성하는데까지 걸리는 시간이며, TPOT는 모든 출력의 평균적인 생성 시간을 말한다. 기존 벤치마크에서는 찾기 어려운 항목이다. 하지만 모델을 직접 활용하는 입장에서는 TPOT, 즉 여러 작업을 빠르게 수행하는 능력이 중요할 수 있다. 반면, 길고 심도 있는 답변을 내놓아야 하는 경우에는 TTFT 기준으로 성능이 우수한 모델을 도입하는 게 유리하다. 또 TPOT와 TTFT는 상충 관계(trade-off)가 존재한다. 빠른 응답을 위해 TPOT를 목표로 최적화를 진행하며 TTFT를 낮추면, 서빙 과정에서 개별 작업에 집중하는 결과를 초래한다. 이는 운영 관점에서 전체 처리량을 의미하는 '스루풋(Throughput)'이 감소할 수 있다. 이처럼 활용에 따라 목표 기준과 적합한 세팅은 달라질 수밖에 없다. 이런 최적의 세팅과 결과를 찾아가는 것이 이제까지는 꽤 어려웠다. 핏츠 온 칩스를 이를 해결하는 솔루션이다. \"모델 실험 설계와 데이터 수집을 획기적으로 간소화할 수 있다\"라고 강조했다. 이런 이유로 주변에서는 좋은 반응을 얻고 있다. 특히 지난 9일에는 실리콘밸리에서 인텔과 개발자 밋업까지 진행했다. 이 자리에서는 인텔 '가우디' 칩으로 LLM 서비스를 효율적으로 구성하는 방법을 공개, 주목을 받았다. 김 매니저는 '피시 앤 칩스'를 연상케 하는 이름도 \"해외 시장을 염두에 두고 만든 것\"이라고 덧붙였다. 핏츠 온 칩스는해당 웹사이트에서 대기자 리스트를 통해 사용 신청을 받고 있다. 장세민 기자 semim99@aitimes.com"
}