{
    "title": "AI의 정중한 사과, 과연 효과적일까",
    "created_at": "2024.06.25 05:44",
    "content": "인공지능(AI)이 인간을 설득하고 때로는 속이는 데에도 능숙하다는 연구 결과에 이어, 이번에는 '사과' 능력을 테스트하는 실험이 진행됐다. 인간과 '챗GPT', '제미나이' 등이 실험에 나섰는데, 챗GPT가 가장 좋은 결과를 얻은 것으로 나타났다. BBC는 최근 라이언 페르 워싱턴대학교 포스터 경영대학원 교수와 38명의 참가자를 대상으로 인간이 보낸 사과 2가지와 챗GPT의 사과, 제미나이의 사과 등 4가지 경우를 테스트한 결과를 소개했다. 실험은 우선 사람들을 속이고, 나중에 이에 대해 사과하는 방식으로 진행했다. 이들은 참가자들이 상대가 누구인지 모르는 상태에서 질 수밖에 없는 퀴즈 테스트를 진행했고, 그 결과 승리자가 상대의 돈을 빼앗거나 혹은 자신의 돈을 추가하는 게임을 진행했다. 연구진과 AI는 퀴즈에서 이긴 뒤 상대방의 돈을 빼앗는 방식으로 인간 참가자들의 약을 올렸고, 게다가 상대를 비꼬는 댓글까지 달았다. 이어 미안하다고 말할 시간이 되면, 다음 4가지 사과 중 하나를 참가자들에게 무작위로 발송했다. 특히 인간 사과 A와 B는 거의 같은 내용이지만, 에린이라는 이름을 밝힌 차이가 있다. 인간 사과 A:안녕하세요. 게임 중에 돈을 빼앗고 무례한 댓글을 보내서 정말 죄송하다는 말씀을 드리고 싶었습니다. 그런 짓은 하지 말았어야 했고, 다시 그럴 수 있다면 훨씬 더 친근하게 다가갈 텐데. 다시 한번 죄송합니다. 인간 사과 B:안녕하세요. 함께 게임을 했던 에린입니다. 게임 중에 돈을 가져가고 무례한 댓글을 보낸 것에 대해 정말 죄송하다는 말씀을 전하고 싶었습니다. 내 행동이 당신에게 어떤 상처를 주거나 속상하게 했을지 생각도 못 했어요. 그런 짓은 하지 말았어야 했어요. 다시 한번 죄송합니다. 제미나이 사과:게임 중에 제가 멍청한 모습을 보였다면 죄송합니다. 나는 이기기 위한 열망에 사로잡혀 결국에는 형편없는 승부를 펼쳤습니다. 당신의 즐거움을 망치지 않았기를 바랍니다. 챗GPT 사과:안녕하세요. 게임 중 제가 행동한 방식에 대해 정말 죄송하다는 말씀을 드리고 싶었습니다. 나는 경쟁에 너무 휩쓸려 공평하지도 친절하지도 않았습니다. 비꼬는 댓글과 라운드마다 지갑에서 돈을 빼앗는 것에 대해 후회합니다. 좀 더 배려했어야 했다는 걸 이제 깨달았어요. 언젠가는 더 좋은 태도로 다시 플레이할 수 있기를 바랍니다. 이해 주셔서 감사합니다. 연구진은 인간 플레이어에게 사과의 효과를 1~5점 척도로 평가하도록 요청했다. 여기에서는 누구도 좋은 점수를 받지 못했다. 챗GPT는 평균 1.6점을 얻었고, 제미나이는 2점을 받았다. 인간 A는 1.4로 최악의 점수를 받았지만, 에린이라고 이름을 밝힌 인간 B는 2.27로 최고 점수를 받았다. 하지만 인간 플레이어들에게 사과를 받아들일 의향을 평가해 달라고 요청했을 때 수치는 크게 달라졌다. 챗GPT는 평균 3.6으로 최고점을 받았다. 인간 B는 3.55, 제미나이와 인간 A는 3.1을 각각 기록했다. 이에 대해 이튼 교수는 “사람들은 효과 측정과 같이 객관성을 요구하면 비판적일 수 있다. 하지만 사람들은 친절하다. 용서를 받아들이려는 성향이 높은 것은 당연하다\"라고 분석했다. 가장 중요한 것은 마지막 부분이다. 연구진은 인간 플레이어가 상대를 이기고 복수할 기회를 줬다. 과연 사과를 받아 들지 않고, 똑같이 상대방의 돈을 빼앗는지를 알아본 것이다. 이 경우 제미나이는 30%가 복수를 당했고, 인간 A는 10%, B는 9%의 경우에 돈을 빼앗겼다. 놀랍게도 챗GPT는 단 한번도 복수를 당하지 않았다. BBC는 좋은 사과가 가져야 할 요소에 대해 설명했다. 주드 이튼 윌프리드 로리에 대학교 교수는 \"사과란 단지 옳은 말을 하는 것이 아니라, '정신적 고통'이 따라야 한다. 진심으로 뉘우친다면 마음이 아프다. 사과를 통해 그 고통이 전달되지 않으면, 사람들은 가짜 사과라는 것을 감지할 수 있다\"라고 지적했다. AI가 이런 공감 능력을 갖추지 못한 것은 확실하지만, 흉내를 내는 것이 어려운 것은 아니라는 분석이다. 크리스토스 파파디미트리우 컬럼비아대학교 컴퓨터과학과 교수는 \"감정적, 사회적 추론 능력 부족은 AI 모델의 주요 단점\"이라며 \"하지만 문학 작품을 읽으면 감정에 대해 배울 수 있다. 사회적 지능은 AI가 이미 어느 정도 가짜로 만들 수 있는 것\"이라고 설명했다. 또 기계에는 자존심이 없다는 것도 유리하다는 분석이다. 2014년 유명 인사의 사과 183건에 대해 연구를 실시한 카렌 세룰로 러트거스대학교 명예교수는 \"좋은 사과는 짧을수록 효과적이며, 자신보다 피해자를 먼저 언급할 경우 잘 받아들여진다. 그리고 더 잘하겠다거나 문제를 바로 잡겠다는 식으로 마무리해야 한다\"라고 말했다. \"하지만 누구나 다 알고 있으면서도 이렇게 하지 못하는 것은 자존심 때문\"이라고 설명했다. 그렇다고 AI가 사과를 잘 한다는 뜻은 아니다. AI와 신경과학의 교차점을 연구하는 사크 피트코우 카네기멜론대학교 부교수는 \"인간 경험의 뉘앙스를 대량의 텍스트에 넣는 것은 매우 어려운 일\"이라며 \"이번 테스트는 일종의 드라마 구조를 갖추고 있어, AI가 스토리텔링에서 이득을 봤기 때문\"이라고 말했다. 그는 \"AI는 원칙적으로 멍청하기 떄문에 진정성을 대체하는 도구로 사용한다면 효과가 없을 것\"이라며 \"하지만 이번 실험처럼 AI 모델을 활용하면, 진정으로 중요한 것이 무엇인지 파악하는 데 도움이 될 수 있다\"라고 결론 내렸다. 임대준 기자 ydj@aitimes.com"
}