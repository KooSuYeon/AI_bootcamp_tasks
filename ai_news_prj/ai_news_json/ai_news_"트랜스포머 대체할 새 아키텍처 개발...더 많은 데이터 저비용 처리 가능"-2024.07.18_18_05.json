{
    "title": "\"트랜스포머 대체할 새 아키텍처 개발...더 많은 데이터 저비용 처리 가능\"",
    "created_at": "2024.07.18 18:05",
    "content": "입력 데이터가 커질수록 추론이 느려지고 메모리 공간이 많이 필요하며 전력 소모가 많은 '트랜스포머' 아키텍처의 약점을 보완하기 위한 새로운 아키텍처가 나왔다. '어탠션 매커니즘'의 단점을 보완했다는 설명인데, 아직 검증이 필요하다는 지적이다. 테크크런치는 17일(현지시간) 스탠포드대학교, UC 샌디에이고, UC 버클리, 메타의 연구진이 트랜스포머보다 많은 데이터를 저비용으로 처리할 수 있는 ‘TTT(Test Time Training)’ 아키텍처에 관한논문을 아카이브에 게재했다고 전했다. '챗GPT'나 '제미나이' 등 LLM에 사용되는 트랜스포머 아키텍처는 컨텍스트 창이 커짐에 따라 필요한 메모리와 계산 시간이 기하급수적으로 증가하는 단점이 있다. 예를 들어, 입력 크기를 토큰 1000개에서 2000개로 확장하면 입력을 처리하는 데 필요한 메모리와 계산 시간이 두배가 아닌 네배로 늘어나게 된다. 이는 텍스트 내 토큰들의 상관관계를 밝혀내기 위해 입력 정보를 병렬로 처리하는 어텐션 메커니즘 때문이다. 트랜스포머의 어텐션 메커니즘을 위한 기본 구성 요소 중 하나는 ‘히든 스테이트(hidden state)’로, 이는 본질적으로 긴 데이터 목록을 뜻한다. 트랜스포머가 무언가를 처리할 때, 방금 처리한 내용을 기억하기 위해 조회 테이블(lookup table)과 같은 메모리인 히든 스테이트에 항목을 추가한다. 예를 들어, LLM이 책을 처리하는 중이라면, 단어 또는 단어의 일부를 표현하는 토큰이 히든 스테이트에 저장된다. 히든 스테이트는 트랜스포머를 강력하게 만드는 요소 중 하나이지만, 동시에 트랜스포머를 제약하기도 한다. 트랜스포머가 방금 읽은 책에 대해 단 한단어라도 말하려면 LLM은 전체 조회 테이블을 스캔해야 하는데, 이는 책 전체를 다시 읽는 것만큼이나 계산적으로 부담이 큰 작업이다. TTT는 히든 스테이트를 머신러닝 모델로 대체, '모델 내 모델'을 구축하는 방식이다. 내부 머신러닝 모델이 리한 데이터를 가중치로 인코딩하기 때문에 추가 데이터를 처리할 때 계속 커지지 않는다. TTT 모델이 처리하는 데이터 양에 상관없이, 내부 모델의 크기는 변하지 않는다. 이것이 TTT 모델의 성능이 매우 뛰어난 이유다. 연구진은 \"TTT는 책을 X번 다시 읽는 계산적 복잡성 없이 책에 대한 X개의 단어를 말할 수 있다\"라고 밝혔다. 특히 비디오 분야에 적용할 경우 획긱적인 진전이 가능하다고 강조했다. “소라(Sora)와 같은 트랜스포머 기반 대형 비디오 모델은 단지 조회 테이블만을 가지고 있기 때문에 10초 정도의 비디오만 처리하는 게 한계\"라며 \"우리의 궁극적인 목표는 인간의 시각적 경험과 유사한 긴 비디오를 처리할 수 있는 시스템을 개발하는 것\"이라고 말했다. 그러나 아직 TTT는 트랜스포머의 대체품으로 사용하기에 적합한지는 검증되지 않았다. 연구진은 현재 연구 목적으로 두개의 작은 모델만 개발했기 때문에, TTT 방법을 현재 시점에서 더 큰 트랜스포머와 비교하기 어렵기 때문이다. 마이크 쿡 킹스 칼리지 런던 정보학부 교수는 “이것은 완전히 흥미로운 혁신이라고 생각한다\"라며 \"좋은 소식이지만, 기존 아키텍처보다 더 나은지 여부는 말할 수는 없다”라고 밝혔다. 한편 최근 트랜스포머 아키텍처의 약점을 보완하기 위한 새로운 기술이 잇달아 공개되고 있다. 이스라엘 스타트업 AI21 랩스는 SSM을 기반으로 하는 ‘맘바(Mamba)’와 트랜스포머 아키텍처의 최고의 특성을 결합한 LLM ‘잠바(Jamba)’를 출시했다. 구글은 LLM 컨텍스트 창 길이를 무한확장할 수 있는 ‘인피니-어텐션(Infini-attention)’ 기술을 공개했다. 메타도 막대한 양의 메모리를 요구하지 않고도 컨텍스트 창을 수백만개의 토큰으로 확장 가능한 LLM ‘메갈로돈(Megalodon)’ 모델을 공개했다. 이 외에도 스타트업 심볼리카는 트랜스포머 아키텍처에 기반한 LLM을 실행하는데 많은 비용이 드는 문제를 해결하기 위해 기호(Symbols)를 조작해 작업을 정의하는 ‘심볼릭 AI(Symbolic AI)’ 기법을 도입했다. 박찬 기자 cpark@aitimes.com"
}