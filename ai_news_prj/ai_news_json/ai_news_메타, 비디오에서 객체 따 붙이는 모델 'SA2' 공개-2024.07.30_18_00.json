{
    "title": "메타, 비디오에서 객체 따 붙이는 모델 'SA2' 공개",
    "created_at": "2024.07.30 18:00",
    "content": "메타가 지난해 큰 인기를 누렸던 이미지에서 객체를 구분하는 '세그먼트 애니싱( Segment Anything)'의 업그레이드 버전을 출시헸다. 이번에는 이미지뿐만 아니라, 비디오에서도 개체를 분리하고 편집할 수 있도록 했다. 메타는 29일(현지시간) 이미지나 비디오에서 특정 개체를 분리, 영상에 실시간 적용할 수 있는 '샘 2(Segment Anything Model 2)'https://ai.meta.com/blog/segment-anything-2/를 공개했다. 분할(Segment)은 비전 AI가 사진이나 영상에 포함된 특정 개체를 다른 부분과 분리하는 것을 말한다. 메타는 지난해 4월 이 기술을 적용한 ‘애니메이티드 드로잉스’를 오픈 소스로 공개, 큰 인기를 얻었다. 손으로 그린 스케치를 따다 붙여 애니메이션으로 만들어 준다는 콘셉트였다. 이번에는 기술을 동영상에서도 객체를 분리하고 실시간으로 적용할 수 있게 했다. 비디오 분할은 이미지 분할보다 훨씬 더 어렵기 때문에, 기존 버전은 이를 구현하는 게 어려웠다고 설명했다. 또 비디오에서 객체는 빠르게 움직이고 모양이 바뀌며 다른 객체나 장면의 일부에 의해 가려질 수 있다. 하지만 샘 2에서는 대부분 문제를 해결했다고 전했다. 이 모델을 훈련하기 위해 만든 SA-V 데이터셋도 공개했다. 여기에는 5만1000개 영상에 대한 60만개 이상의 라벨이 포함됐으며, 영상은 47개국에 걸쳐 수집된 다양한 실제 상황을 담고 있다고 전했다. 메타 측은 이 도구가 비디오 편집을 더 쉽게 만들고 혼합현실에 적용될 수 있을 것으로 기대했다. 컴퓨터 비전 모델을 훈련하기 위한 시각 데이터의 라벨링에 사용될 수 있다고도 전했다. 이 도구로 어떤 응용 사례가 등장할 지 기대된다고 강조했다. 한편 마크 저커버그 메타 CEO도 이날 열린 시그래프의 젠슨 황 엔비디아 CEO와의 대담에 출연, 이 제품을 홍보했다. \"과학자들은 이 도구를 이용해서 산호초와 자연 서식지 같은 것들을 연구한다\"라며 \"비디오에서 특정 부분을 제거하고 원하는 것만보여주며 설명하는 것은 멋진 일\"이라고 말했다. 샘 2는 현재 무료 데모https://sam2.metademolab.com/로 사용해 볼 수 있다. 임대준 기자 ydj@aitimes.com"
}