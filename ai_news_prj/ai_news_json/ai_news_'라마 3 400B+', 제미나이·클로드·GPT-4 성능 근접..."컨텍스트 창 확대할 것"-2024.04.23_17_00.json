{
    "title": "'라마 3 400B+', 제미나이·클로드·GPT-4 성능 근접...\"컨텍스트 창 확대할 것\"",
    "created_at": "2024.04.23 17:00",
    "content": "메타가 올 여름 출시 예정인 ‘라마 3’가 성능 면에서 다른 오픈 소스보다 뛰어난 것은 물론, 기존 첨단 모델의 성능에 근접했다는 평가가 나왔다. 디 인포메이션은 22일(현지시간) 메타가 출시 예정인 라마 3의 4050억 매개변수 버전이 오픈AI, 구글, 앤트로픽 등 폐쇄형 대형언어모델(LLM) 성능에 견줄만한 수준이라고 전했다. 이에 따르면 라마 3의 4050억 매개변수 버전(400B+)은 MMLU 벤치마크에서 구글의 '제미나이 프로'(90점), 앤트로픽의 '클로드 3 오퍼스'(88.2점), 오픈AI의 'GPT-4'(86.8점)에 이어 84.8점을 기록했다. 또 메타가 앞서 공개한 라마 3의 700억 매개변수 버전(70B)도 현존 최고 성능의 오픈 소스 LLM으로, 오픈AI의 GPT-3.5, 앤트로픽의 클로드 3 소네트 및 구글의 제미나이 프로 1.5와 동등한 수준의 성능을 기록했다. 다만 개발자들은 라마 3의 컨텍스트 창이  8000개가 조금 넘는 토큰으로 너무 짧다는 점을 지적했다. 이에 비해 '미스트랄 7B' 모델은 3만2000개 토큰, '제미나이 프로 1.5'는 12만8000개 토큰, '클로드 3 소네트'는 20만개 토큰의 컨텍스트 창을 지원한다. 이에 대해 메타는 앞으로 몇달 안에 더 긴 컨텍스트 창을 도입할 것이라고 밝혔다. 이 외에도 라마 3는 최근 스타트업들이 적은 비용으로 효율적인 훈련과 실행을 위해 LLM에 도입하는  ‘전문가 혼합(MoE)’ 접근 방식을 채택하지 않았다. MoE는 LLM을 생물, 물리, 수학 등 각 분야를 담당하는 작은 전문 모델로 쪼개고, 질문에 따라 전문 모델을 연결하거나 몇 종류를 섞는 방식이다. 이 경우 관련 없는 전문 모델은 빼고 관련 있는 모델만 돌리기 때문에 비용과 시간이 훨씬 적게 들어간다. 메타는 “우리는 라마 3에 대한 우리의 기대를 가장 잘 충족시킬 수 있다고 생각되는 방향을 기준으로 모델을 선택했다”고 말했다. 라마 3가 오픈 소스 모델이기 때문에, 개발자들 스스로 MoE 접근 방식을 구축할 수 있을 것이라는 설명이다. 메타는 공식 블로그를 통해 \"멀티모달, 다국어 대화, 더 길어진 컨텍스트 창 등 더 강력한 기능을 갖춘 여러 버전의 새로운 라마 3 버전들이 출시할 것\"이라고 밝혔다. 박찬 기자 cpark@aitimes.com"
}