{
    "title": "코히어 \"사전 학습에 코드 사용하면 코딩 이외 성능도 높아져”",
    "created_at": "2024.08.30 18:00",
    "content": "대형언어모델(LLM)의 사전 학습에 코드 데이터를 사용하면 비코드 관련 성능도 개선된다는 연구 결과가 나왔다. 개발자 사이에서 입소문으로 전해지던 사실을 입증한 사례다. 벤처비트는 29일(현지시간) 코히어 연구진이 LLM 사전 학습에서 코드 데이터가 LLM 성능에 미치는 영향에 관한논문을 아카이브에 게재했다고 보도했다. 우선 연구진은 \"실무자들 사이에서는 코드 데이터가 LLM 성과에 중요한 역할을 한다는 데에 대한 공감이 있지만, 코드가 비코드 작업에 미치는 정확한 영향을 분석한 연구는 제한적이었다\"라고 밝혔다. 연구진은 코드가 일반 LLM 성능에 미치는 영향을 실험하기 위해 ▲텍스트 만으로 사전 훈련한 모델 ▲텍스트와 코드로 사전 훈련한 모델 ▲코드 만으로 사전 훈련한 모델 등을 각각 텍스트로 추가 훈련했다. 그 다음 자연어 추론, 세계 지식, 코드 생성 성능을 측정하는 다양한 벤치마크를 사용해 평가했다. 실험 결과, 코드가 LLM의 비코드 관련 작업 성능을 일관되게 향상시킨다는 것을 발견했다. 자연어 추론 작업에서 코드로 훈련된 모델은 텍스트만으로 훈련된 모델보다 우수한 성능을 보였다. 특히 100% 코드 데이터만으로 사전 훈련한 모델이 벤치마크에서 가장 우수한 성능을 발휘했다. 세계 지식 관련 작업에서는 텍스트와 코드로 사전 훈련한 모델이 가장 우수한 성능을 보였다. 코드 생성 작업에서는 코드만으로 훈련된 모델과 텍스트-코드 훈련 모델 모두가 텍스트만으로 훈련한 모델보다 우수한 성능을 보였다. 연구진은 “결과적으로 사전 훈련에 포함된 코드 데이터가 모델의 추론 능력을 향상시킬 뿐만 아니라, 모델이 더 높은 품질의 결과물을 생성하는 데 도움을 준다”라고 설명했다. 또 사전 훈련 데이터에 코드를 추가함으로써 얻는 성능 향상이 모델이 커질수록 증가한다는 것도 발견했다. 이런 개선은 세계 지식과 코드 생성 성능에서 가장 두드러졌으며, 자연어 추론에서는 소폭 향상을 이끌었다. 더불어 고품질의 합성 코드를 사전 훈련 데이터에 추가하는 것이 성능을 크게 향상시킨다는 것을 발견했다. 이는 인간이 생성한 코드는 수적으로 한계가 있기 때문에, 인간이 생성한 코드에 의존하지 않아도 된다는 점에서 특별히 유용한 발견이다. 이 외에도 훈련의 쿨다운 단계, 즉 자체 데이터로 모델을 미세조정할 때  코드를 통합하면 LLM의 비코드 관련 작업에서 성능이 추가로 향상된다는 것을 발견했다. 연구진은 “훈련 단계에 관계없이 훈련 데이터에 코드를 포함하는 것을 추천한다”라고 강조했다. 박찬 기자 cpark@aitimes.com"
}