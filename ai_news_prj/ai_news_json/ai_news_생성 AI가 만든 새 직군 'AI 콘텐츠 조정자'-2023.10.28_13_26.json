{
    "title": "생성 AI가 만든 새 직군 'AI 콘텐츠 조정자'",
    "created_at": "2023.10.28 13:26",
    "content": "생성 인공지능(AI)이 'AI 콘텐츠 조정자(moderator)'라는 새로운 직군을 만들어 내고 있다. '프롬프트 엔지니어'에 이어 등장한 이 직업은 생성 AI의 출력만을 전문적으로 검토하는 역할이다. 월스트리트저널과 CNBC는 최근 생성 AI의 등장으로 실직 위협이 늘어나는 가운데 반면 AI가 생성한 텍스트나 이미지의 적합성을 검토하는 일자리도 늘어나고 있다고 소개했다. 이에 따르면 AI 개발사를 지원하는 미국의 프롤리픽은 AI 생성 자료를 검토한 사람에게 보상을 제공하는 프로그램을 진행하고 있다. 참가자는 구글이나 메타 등 프롤리픽 고객사로부터 별도 교육을 받은 뒤 AI 생성물을 검토하고 문제가 되는 부분에 대한 피드백을 제공하는 등 AI 개발을 지원한다. 현재 다수의 기업이 이를 활용하고 있으며, 지난 7월 파테크와 옥스포드 사이언스 엔터프라이즈 등으로부터 3200만달러의 투자 유치에 성공하는 등 전망도 밝게 평가받고 있다. 소프트웨어 제조업체인 인튜이트 역시  AI 시스템에서 유해한 언어 및 기타 오작동을 방지하기 위해 내부 콘텐츠 조정팀을 구성했다. 이 회사는 팀을 8명으로만 구성했는데, 이는 다루는 데이터의 보안 문제 때문으로 대규모 인원을 채용하기는 어렵다는 이유에서다. AI 콘텐츠 조정자라는 단어는 처음 등장한 게 아니다. 이전에는 AI 모델 학습을 준비하는 '데이터 라벨러'를 조정자라고 불렀다. 하지만 이번에 등장한 직종은 생성 AI의 결과물에 집중한다. 대형언어모델(LLM)을 운영하는 일부 기업에서는 생성 AI 결과물의 적합성을 판단하기 위해 별도 AI 모델을 가동하고 있다. 그러나 결국 인간의 직접적인 검토가 필요하다는 지적이다. 따라서 자체적인 모니터링 팀을 가동하는 경우도 있으나, 생성 AI가 쏟아내는 엄청난 양의 문서나 이미지를 모두 검토하기는 어려운 현실이다. 이 때문에 등장한 것이 AI 콘텐츠 조정자다. 기존 대형 SNS 기업에서 유저 작성 글을 모니터링하던 것과 흡사하다. 또 AI 분야에서는 LLM 개발 중 활용하는 '휴먼 피드백' 개념을 확장한 것으로 볼 수 있다. 하지만 생성 AI는 환각은 물론 탈옥을 유도하는 프롬프트에 취약한 것으로 알려져 있고, 이는 결국 LLM의 신뢰성과 기업의 직접적인 수익에 영향을 미치기 때문에 콘텐츠 조정의 필요성은 계속 강조되고 있다. 억대 연봉을 내건 프롬프트 엔지니어와 달리 AI 콘텐츠 조정자는 데이터 라벨러와 비슷한 수준의 대우를 받는 것으로 나타났다. 프롤리픽의 경우 참가자에 시간당 최소 8~12달러(약 1만~1만2000원)를 지불하도록 권장하고 있다. 페림 브래들리 프롤리픽 CEO는 \"AI의 윤리 기반 마련과 신뢰를 위해 콘텐츠 조정자와 같은 직종의 수요가 늘어나고 있다\"라며 \"데이터 라벨러를 포함해 새로 등장한 AI 직종에 대한 공정하고 윤리적인 대우를 충분히 검토해야 한다\"라고 말했다. 이와 관련, 지난 8월에는 '챗GPT'의 데이터 라벨링을 담당하는 케냐의 노동자들이 폭력적이고 극단적인 콘텐츠에 지속 노출, 트라우마에 시달리고 있다는 보도가 나왔다. 개발 도상국에서 저임금으로 이뤄지는 이런 작업에는 처우 문제가 지속적으로 지적되고 있다. 임대준 기자 ydj@aitimes.com"
}