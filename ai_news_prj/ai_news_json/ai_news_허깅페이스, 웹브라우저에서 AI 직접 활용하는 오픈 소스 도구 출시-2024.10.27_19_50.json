{
    "title": "허깅페이스, 웹브라우저에서 AI 직접 활용하는 오픈 소스 도구 출시",
    "created_at": "2024.10.27 19:50",
    "content": "허깅페이스가 서버 없이 브라우저에서 직접 '트랜스포머'를 실행할 수 있는 웹용 자바스크립트(Javascript) 머신러닝(ML) 라이브러리를 출시했다. 이를 통해 개발자들은 브라우저 내에서 효율적으로 정교한 AI 애플리케이션을 직접 만들 수 있게 됐다. 허깅페이그는 최근 브라우저에서 트랜스포머 아키텍처 기반 모델을 효율적으로 로드하고 실행할 수 있는‘트랜스포머.js(Transformers.js)’ v3를 오픈 소스로 출시했다고 발표했다. 트랜스포머.js의 새 버전은 많은 리소스를 사용하는 트랜스포머 기반 모델을 브라우저 내에서 액세스할 수 있도록 새로운 양자화 형식을 도입했다. 양자화는 압축 기술의 일종으로, 웹 브라우저와 같이 리소스가 제한된 플랫폼에서 모델 크기를 줄이고 처리 속도를 향상할 수 있다. 자연어 처리, 컴퓨터 비전, 오디오, 멀티모달 분야에서 '파이-3' '젬마 2' '라바' 등 120개의 모델 아키텍처를 지원하며, 이전 버전에 비해 추론 속도가 최대 100배 향상됐다. 또 25개의 새로운 예제 프로젝트와 템플릿도 포함됐으며, 1200개 이상의 사전 변환된 맞춤형 모델을 사용할 수 있다. 허깅페이스는 이날 아마존(AWS)과 협력, 기업이 광범위한 하드웨어에서 대형언어모델(LLM)을 배치하고 실행시킬 수 있도록 지원하는'HUGS(Hugging Face Generative AI Services)'를 발표했다. 이는 엔비디아가 밀고 있는 'NIM(Nvidia's Inference Microservices)'과 겹치는 서비스로, 경쟁이 주목된다. HUGS는 엔비디아 NIM과 마찬가지로 컨테이너화된 모델 이미지로, 사용자가 AI 모델을 배포하는 데 필요한 것들을 포함하고 있다. LLM을 대규모로 최적화하기 위해 vLLM이나 텐서RT(TensorRT) LLM을 사용하는 대신, 사용자는 컨테이너 가상화 플랫폼인 도커(Docker)나 쿠버네티스(Kubernetes)에서 미리 구성된 컨테이너 이미지를 활용해 표준 오픈API 호출하고 연결할 수 있다. HUGS는 오픈 소스 텍스트 생성 인터페이스(Text Generation Inference, TGI)와 트랜스포머 프레임워크 및 라이브러리 기반으로 개발됐다. 따라서 엔비디아와 AMD GPU를 포함해 다양한 하드웨어 플랫폼에 배치될 수 있다. 아마존 AI 추론 칩 인퍼런시아나 구글 TPU 같은 특화 AI 가속기들로도 지원이 확대될 예정이다. 허깅페이스는 HUGS를 아마존과 구글의 클라우드 컴퓨팅 서비스에서 시간당 1달러에 제공하며, 전문 클라우드 컴퓨팅 회사인 디지털 오션에서도 제공한다. 기업들은 HUGS를 다운로드 자체 데이터센터에서 실행할 수도 있다. 박찬 기자 cpark@aitimes.com"
}