{
    "title": "MS, AI 챗봇의 탈옥 방지·환각 감지 위한 도구 공개",
    "created_at": "2024.03.29 18:00",
    "content": "마이크로소프트(MS)가 생성 인공지능(AI)의 탈옥을 막고 환각을 감지하는 개발자용 도구를 내놓았다. 선거 등을 앞두고 터져 나오는 구설수를 미리 차단하겠다는 의도다. MS는 28일(현지시간) 공식 블로그를 통해 '안전하고 신뢰할 수 있는 생성 AI 애플리케이션을 구축하는 데 도움이 되는 애저 AI의 새로운 도구' 출시를 발표했다. 여기에는 ▲모델에 영향을 미치기 전에 프롬프트 공격을 감지하고 차단하는 프롬프트 실드(Prompt Shields) ▲모델 출력에서 환각을 감지하는 접지 감지(Groundedness detection) ▲모델 동작을 안전하고 책임감 있는 결과로 유도하는 안전 시스템 메시지(Safety system messages) ▲애플리케이션의 탈옥 공격 및 콘텐츠 위험 생성에 대한 안전성 평가(Safety evaluations)▲어떤 입력과 출력, 사용자가 콘텐츠 필터를 우회하는지 파악할 수 있는 위험 및 안전 모니터링(Risk and safety monitoring) 등이 포함된다. 이들은 조만간 출시 예정이며, 일부는 미리보기로 제공한다. 사라 버드 MS 책임 있는 AI 최고 제품 책임자는 더 버지와의 인터뷰에서 “우리는 대부분 사용자가 프롬프트 공격이나 증오성 콘텐츠에 대해 깊은 전문 지식을 갖고 있지 않다는 것을 알고 있다\"라며 \"이런 평가 시스템을 통해 사용자는 무엇이 문제인 지를 확인할 수 있다\"라고 말했다. 특히 최근 제미나이로 인해 큰 문제가 된 역사적으로 부정확한 이미지나 유명인의 딥페이크 등이 생성되는 것을 막을 수 있다는 설명이다. 또 애저를 사용하는 회사의 시스템 관리자는 누가 안전하지 않은 출력을 시도하는지 파악할 수 있게 된다. 이 기능은 현재 애저에서 제공하는 'GPT-4'나 '라마 2'같은 모델에 즉시 적용할 수 있다는 설명이다. 일부 오픈 소스 모델에는 수동 지정도 필요하다. 이에 앞서 지난 2월에는 MS와 구글, 오픈AI 등 20개 빅테크가 생성 AI 콘텐츠의 선거 악용을 방지하기 위해 공동 대책을 마련하기로 합의했다. 또 각 회사는 생성 AI 이미지에 워터마크를 삽입할 예정이다. 하지만 이달 초 미국 비영리단체 디지털혐오 대응센터(CCDH)가 발표한 조사 결과에 따르면 여전히 선거 관련 허위 콘텐츠 생성에 취약하다는 결과가 나왔다. 또 MS에서는 이미지 생성 AI에 문제가 있으며, 경고에도 불구하고 회사가 이를 무시했다는 내부 폭로도 등장한 바 있다. 임대준 기자 ydj@aitimes.com"
}