{
    "title": "메타, 텍스트·이미지 동시 처리하는 LMM ‘트랜스퓨전’ 공개",
    "created_at": "2024.09.02 18:00",
    "content": "메타가 단어나 토큰과 같은 불연속적인 이산(discrete) 데이터와 이미지의 픽셀과 같은 연속적인(continuous) 데이터를 모두 처리할 수 있는 트랜스포머 기반의 멀티모달 언어모델(LMM)을 공개했다. 벤처비트는 30일(현지시간) 메타와 서든캘리포니아대학(USC) 연구진이 이산 및 연속 데이터 양식을 모두 처리할 수 있는 새로운 LMM ‘트랜스퓨전(transfusion)’에 관한논문을 아카이브에 게재했다고 보도했다. 이제까지 상당수 모델은 멀티모달 문제를 해결하기 위한 언어 처리와 이미지 처리를 위해 별도의 아키텍처를 사용했다. 따라서 '라바(LLaVA)'와 같은 모델은 각 데이터 양식에 대해 개별적으로 사전 학습했다. 이런 모델은 이미지와 텍스트가 뒤섞여 있는 문서를 처리할 때 어려움을 겪는다. 하지만 최근에는 이미지를 이산 값으로 양자화(quantization), 이를 텍스트와 유사한 일련의 토큰으로 변환하는 방식이 등장했다. 올해 초에 도입된 메타의 '카멜레온(Chameleon)' 모델이 대표적이다. 이 접근 방식은 이미지 처리를 위해 언어 모델을 사용할 수 있게 해 주지만, 양자화에 따른 이미지 데이터 축소로 연속적인 픽셀 값에 포함된 정보를 손실하는 결과를 초래한다. 트랜스퓨전은 경량 모달리티 전용 구성 요소를 통해 텍스트 토큰과 이미지 패치를 변환 처리하기 전에 적절한 표현으로 변환한다. 특히 이미지 데이터의 표현을 개선하기 위해 트랜스퓨전은 '변분 오토인코더(VAE)'를 사용한다. VAE는 이미지와 같은 복잡한 입력 데이터를 저차원 연속 공간에 중간 표현으로 인코딩한 다음, 이를 원래 형태로 디코딩하도록 학습하는 신경망이다. 오토인코더는 압축이나 이미지 노이즈 제거, 스타일 전이 등 여러 응용 분야에 사용된다. 트랜스퓨전에서는 VAE를 사용하여 이미지의 각 8×8 패치를 연속적인 값 목록으로 인코딩한다. 이를 통해 데이터와 매개변수를 공유, 텍스트에는 언어 모델링을, 이미지에는 확산(Diffusion)을 사용하도록 별도의 손실 함수를 적용했다. 연구진은 트랜스퓨전을 기반으로 한 70억개의 매개뱐수를 가진 모델을 훈련한 뒤, 동일한 크기의 카멜레온 모델과 ▲텍스트-텍스트 ▲텍스트-이미지 ▲이미지-텍스트 작업 등을 벤치마크에서 비교했다. 그 결과, 트랜스퓨전은 모든 데이터 양식에서 카멜레온을 능가했다. 텍스트-이미지 생성에서는 카메레온의 3분의 1 이하의 계산 비용으로 더 나은 결과를 얻었으며, 이미지-텍스트 생성에서도 트랜스퓨전은 단지 21.8%의 계산 자원만으로도 카멜레온과 동등한 성능을 달성했다. 트랜스퓨전은 텍스트 전용 벤치마크에서도 더 나은 성능을 보였다. 이는 카멜레온의, 양자화된 이미지 토큰을 사용하는 훈련이 텍스트 성능에 부정적인 영향을 미칠 수 있음을 시사한다. 또 트랜스퓨전은 이미지 생성에 대한 벤치마크에서도 '달리 2'와 스'테이블 디퓨전 XL'과 같은 다른 모델들을 능가했으며, 텍스트 생성도 가능했다. 연구진은 \"확산 모델과 토큰 예측 자기 회귀 모델은 각각 연속 및 불연속 데이터를 생성하는 데 가장 적합한 방식\"이라며 \"이것은 우리가 자연스럽고 간단한 방식으로 두 세계의 장점을 결합하는 새로운 멀티모달 방법을 개발하도록 영감을 줬다\"라고 밝혔다. 박찬 기자 cpark@aitimes.com"
}