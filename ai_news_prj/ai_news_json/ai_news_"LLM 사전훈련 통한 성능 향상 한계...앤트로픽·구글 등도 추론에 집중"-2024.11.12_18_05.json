{
    "title": "\"LLM 사전훈련 통한 성능 향상 한계...앤트로픽·구글 등도 추론에 집중\"",
    "created_at": "2024.11.12 18:05",
    "content": "오픈AI가 사전 훈련(pre-train)을 통한 'GPT' 성능 향상에 한계를 맞았다는 이야기가 나온 데 이어, 나머지 기업들도 같은 현상을 보이고 있다는 소식이 등장했다. 결국 추론이 대형언어모델(LLM) 개발의 돌파구가 될 것이라는 분석이다. 로이터는 11일(현지시간) 12명의 AI 과학자와 연구자, 투자자 등을 인용, LLM 성능 향상이 더뎌지고 있으며 오픈AI가 개발 중인 'o1'과 같은 추론 기능 위주의 모델 개발이 여러 곳에서 진행 중이라고 보도했다. 우선 지난 10년간 LLM 개발을 끌어온 \"더 큰 것이 좋다\"라는 철학이 한계를 맞았다고 지적했다. 이는 '스케일링 법칙'을 말하는 것으로, LLM에 더 많은 데이터와 컴퓨팅 인프라를 투입하면 성능이 좋아진다는 내용이다. 앞서 지난 9일 디 인포메이션은 오픈AI가 '오라이온'으로 알려진 GPT-5를 개발했으나, GPT-3에서 GPT-4로 넘어가는 과정만큼 성능 향상이 이뤄지지 않았다고 보도했다. 즉 사전 훈련에서 스케일링 법칙이 한계를 맞았다는 내용이다. 로이터에 따르면 이는 다른 회사도 마찬가지인 것으로 확인됐다. 소식통 3명은 주요 AI 회사의 연구원들이 2년 가까이 된 오픈AI의 GPT-4보다 성능이 뛰어난 모델을 출시하기 위한 경쟁에서 \"지연과 실망스러운 결과에 직면했다\"라고 전했다. 여기에서도 데이터 고갈과 수천만달러가 들어갈 수 있는 모델 훈련 비용등이 문제로 지적됐다. 이 때문에 연구자들은 오픈AI가 강조한 추론 기능, 즉 '테스트-타임 컴퓨트'를 집중적으로 연구한다고 밝혔다. 이는 사용자 질문에 답하는 동안 모델에 추가 컴퓨팅 리소스와 시간을 제공하면 응답 품질이 계속 향상된다는 이론으로, 오픈AI 추론 모델의 핵심 이론이다. 5명의 관계자에 따르면 앤트로픽과 xAI, 구글, 메타 등 다른 AI 기업도 이 기술의 자체 버전을 개발하기 위해 노력해 왔다. 이런 움직임은 엔비디아가 독점 중인 AI 칩 시장에도 변화를 줄 수 있다는 분석이다. 소니아 황 세쿼이아 캐피털 파트너는 \"이런 전환은 거대한 사전 훈련 클러스터의 세계에서 추론을 위한 분산형 클라우드 기반 서버인 추론 클라우드로 이동시킬 것\"이라고 말했다. 즉, 기존 사전 훈련에 효율적이던 엔비디아 GPU 수요가 추론 칩으로 분산될 수도 있다는 말이다. 세레브라스나 그로크 등 스타트업이 개발 중인 추론 전문 칩은 GPU보다 저렴하다. 하지만 젠슨 황 엔비디아 CEO는 이런 움직임을 의식한듯 지난달 인도에서 열린 한 컨퍼런스에서 \"우리는 이제 두번째 스케일링 법칙을 발견했고, 이것은 추론 시점의 스케일링 법칙\"이라고 밝혔다. 또 \"이런 모든 요소가 블랙웰에 대한 수요를 엄청나게 높였다\"라며 강조했다. 사전훈련의 비중이 줄어들고 추론에 초점이 맞춰져도 엔비디아는 경쟁력이 있다는 말이다. 한편, 디 인포메이션은 11일 오픈AI가 추론 중심 모델의 브랜드를 o1으로 새로 정한 것이 오라이온이라는 이름과 무관하지 않다고 분석했다. o1의 후속 모델 o2의 추론 기능을 탑재한 최첨단 모델이 결국 오라이온이라는 것이다. 즉, o는 오라이온(orion)을 의미한다는 말이다. 임대준 기자 ydj@aitimes.com"
}