{
    "title": "수학 특화 언어모델의 진화...20B 모델로 '미네르바' '레마' 제쳐",
    "created_at": "2024.02.23 17:00",
    "content": "대형언어모델(LLM)의 수학 추론 능력 중요성이 강조되는 가운데, 관련 기술이 점차 발전하고 있다. 이번에는 매개변수 200억개(20B)에 불과한 모델이 기존 최강으로 꼽히던 구글 '미네르바(MInerva 62B)'의 성능을 뛰어넘었다. 마크테크포스트는 22일(현지시간) 상하이 AI실험실과 칭화대학교, 푸단대학교, 서던캘리포니아대학 연구진이 '인턴LM-매쓰(InternLM-Math)'라는 대형언어모델(LLM)을 공개했다고 보도했다. 이에 따르면 이 모델은 30만개의 한자를 처리하는 것으로 유명해진 상하이 AI실험실의 오픈 소스 대형언어모델(LLM) '인턴LM2'를 기반으로 하고 있다. 연구진은 시퀀스 변환모델(seq2seq) 프레임워크 내에 생각의 사슬(CoT), 보상 모델링, 형식적 추론, 데이터 증강 등 기능을 통합했다고 밝혔다. 이런 포괄적인 접근 방식을 통해 뛰어난 정확성과 깊이로 광범위한 수학적 작업을 처리할 수 있다고 설명했다. 또 수학적 데이터에 초점을 맞춘 사전 훈련으로 추론 능력을 향상했으며, 특히 CoT로 인간의 사고 과정을 반영해 문제에 단계별로 접근할 수 있었다고 전했다. 여기에 코딩 통합 기술을 적용, 복잡한 문제를 해결하고 자연스럽고 직관적으로 증명을 생성할 수 있도록 했다고 소개했다. 벤치마크 결과 이 모델은 매개변수가 더 큰 기존 오픈 소스 최강 엘루서AI의 '레마(Llemma 34B)'와 미네르바(MInerva 62B)를 넘어섰다. 레마 역시 지난해 10월 등장한 모델로, 미네르바보다 적은 매개변수로 비슷한 성능을 냈다. 벤치마크는 ▲GSM8K(8500개의 초등학교 수준) ▲MATH(1만2500개의 고난도 수학 경시대회 수준) ▲MiniF2F(올림피아드 수준)등이 포함됐으며, 특히 아무 미세조정 없이 MiniF2F 테스트 세트에서 30.3점으로, 정상권의 실력을 보였다고 강조했다. 물론 이 모델이 최고의 수학 모델은 아니다. 현존 LLM 중 수학 관련 벤치마크 최고점을 받은 것은 'GPT-4'다. 하지만 GPT-4는 매개변수가 1750억개(175B)로 알려져 있으며, 크기가 10분의 1에 불과한 인턴LM-매쓰는 GPT-4의 90% 수준까지 따라붙었다고 주장했다. 또 논문 출판 직전인 지난달 17일에는 구글 딥마인드 연구진이 국제 수학 올림피아드에 출제된 기하학 문제 30개 중 25개나 풀어낸 '알파지오메트리(AlphaGeometry)'를 오픈 소스로 공개한 바 있다. 이 외에도 지난달에는 국내 스타트업 업스테이지가 매개변수 130억개(13B)의 '매쓰GPT'를 개발, 벤치마크에서 마이크로소프트의 ‘토라(ToRA) 13B’ 모델을 능가했다고 밝혔다. 이처럼 수학 모델은 최근 몇개월 사이에 빠르게 소형화 및 고성능화되고 있다. 상하이 AI실험실 측은 \"인턴LM-미쓰는 새로운 문제를 종합하고 솔루션을 검증하며 데이터 확대를 통해 자체적으로 개선하는 능력을 갖추고 있어 수학에 대한 이해를 심화하기 위한 지속적인 탐구에서 중추적인 도구로 자리매김하고 있다\"라고 밝혔다. 임대준 기자 ydj@aitimes.com"
}