{
    "title": "미스트랄 AI, 오픈 소스 ‘미스트랄 7B v0.2’ 출시...\"라마 2 13B 능가\"",
    "created_at": "2024.04.01 18:00",
    "content": "미스트랄 AI가 새로운 오픈 소스 대형언어모델(LLM) '미스트랄 7B v0.2'를 출시했다. 메타의 ‘라마 2’를 뛰어넘는 성능으로, 더 적은 매개변수에서도 성능과 다양성, 효율성을 보여줬다는 평가다. 마크테크포스트는 31일(현지시간) 미스트랄 AI가 ▲‘미스트랄-7B-베이스-v2.0’ ▲‘미스트랄-7B-인스트럭트-v2.0’ 등을 공개했다고 전했다. v0.2에서 가장 눈에 띄는 개선 사항 중 하나는 v0.1의 8000개 토큰에서 3만2000개 토큰으로 컨텍스트 창이 확장된 것이다. 이를 통해 모델은 더 긴 텍스트 시퀀스를 처리하고 이해해 문서 요약, 스토리 생성, 긴 형식의 질문 답변에 더 일관되고 상황에 맞는 출력을 생성할 수 있다. 또 미세 조정된 '로프 세타(Rope Theta)' 매개변수를 도입, 광범위한 작업에서 더 정확하고 일관된 출력을 보장한다. v0.2에서는 v0.1에 있었던 슬라이딩 윈도우 주의 사용을 제거함으로써 추론 시간이 빨라지고 계산 요구 사항이 줄어들었다. 명령어 조정 버전인 ‘미스트랄-7B-인스트럭트-v0.2’는 특정 작업과 애플리케이션에 맞게 미세조정하고 최적화할 수 있다. 이 외에도 미스트랄 7B v0.2는 추론 속도를 향상하고 메모리 소비를 줄이기 위해 GQA(Grouped-Query Attention)를 도입했으며, 까다롭거나 영역별 어휘가 있는 경우에도 정확하고 일관된 출력을 생성할 수 있도록 '바이트-폴백 BPE 토크나이저(Byte-fallback BPE Tokenizer)'를 활용해 모델이 어휘에 포함되지 않은 토큰을 원활하게 처리할 수 있게 했다. 특히 미스트랄 7B v0.2는 다양한 벤치마크에서 인상적인 성능을 기록한 것으로 나타났다. 73억 매개변수의 미스트랄 7B v0.2는 평가된 모든 작업에서 130억 매개변수의 ‘라마 2 13B’ 모델보다 성능이 뛰어났으며, 340억 매개변수의 ‘라마 1 34B’모델과 비슷한 성능을 보였다. 코딩 영역에서도 미스트랄 7B v0.2는  프로그래밍 작업을 위해 특별히 설계된 모델인 ‘코드라마 7B’의 성능에 접근하며 모델의 다재다능함을 보였다. 명령어 조정 변형인 미스트랄-7B-인스트럭트-v0.2는 MT-벤치(MT-Bench) 벤치마크에서 다른 모든 7B 명령어 모델을 능가하는 성능을 기록했다. 이는 챗봇, 가상 비서 및 작업 지향 대화 시스템과 같은 애플리케이션에 이상적인 선택될 수 있다는 의미다. 미스트랄 7B v0.2 모델은 연구원, 개발자 및 기업이 제한 없이 사용할 수 있도록 허용되는 아파치 2.0 라이선스에 따라 출시했다. 모델을 다운로드해 로컬로 사용하거나, 다양한 클라우드 플랫폼에 배포하거나, 널리 사용되는 AI 프레임워크 및 라이브러리를 통해 액세스할 수도 있다. 박찬 기자 cpark@aitimes.com"
}