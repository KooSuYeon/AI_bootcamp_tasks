{
    "title": "\"메타도 크롤링 봇으로 AI 학습 데이터 무단 수집\"",
    "created_at": "2024.08.22 18:00",
    "content": "메타가 인터넷 콘텐츠를 긁어내 대형언어모델(LLM) 학습에 사용하는 '웹 크롤링 봇'을 조용히 출시했다. 이 봇은 웹사이트 소유자가 봇의 콘텐츠 수집 차단을 어렵게 만드는 기능을 가지고 있는 것으로 알려졌다. 비즈니스 인사이더는 21일(현지시간) 메타가 최근 웹을 크롤링하고 AI 모델과 관련 제품에 대한 데이터를 수집하는 새로운 봇 2종 ▲메타-익스트널에이전트(Meta-ExternalAgent) ▲메타-익스터널패처(Meta-ExternalFetcher)를 출시했다고 보도했다. 웹 검사 사이트 오리지널리티AI에 따르면, 메타의 새로운 웹 크롤링 봇은 7월에 처음 등장했다. 웹 크롤링 봇은 방대한 웹 페이지를 뒤지며 각종 정보를 자동으로 수집한다. 또 AI 개발 회사가 인터넷에서 각종 데이터를 자동으로 찾아 끌어와서 LLM 학습 데이터를 확보하는 데도 사용한다. 메타-익스트널에이전트는 AI 훈련 데이터를 수집하고 콘텐츠를 색인화하는 등 2가지 기능을 수행하는 봇이다. 웹사이트 소유자는 데이터 수집은 차단하기를 원하지만, 색인화는 트래픽 유입을 위해 허용하기 때문에 두 기능이 결합된 봇을 차단하기 쉽지 않다. 상위 웹사이트의 1.5%만이 새로운 메타-익스트널에이전트 봇을 차단하고 있는 것으로 알려졌다. 반면, 수년간 온라인 데이터를 스크래핑해 메타의 대형언어모델(LLM)과 AI 음성인식 기술을 훈련시킨 '페이스북봇(FacebookBot)'이라는 초기 웹크롤러는 상위 웹사이트의 약 10%에서 차단됐다. 또 메타-익스터널패처는 회사의 AI 지원 제품과 관련이 있으며 특정 제품 기능을 지원하는 링크를 수집하는 봇이다. 여기에도 차단을 어렵게 하는 기능이 있어, 상위 웹사이트의 1% 미만에서만 차단되고 있다. 현재 크롤링을 거부하기 위해서는 사이트의 'robots.txt'라는 코드에 특정 봇의 접근을 차단하는 조치를 취하는 것이 일반적이다. 그러나 메타는 편법으로 차단을 우회하여 크롤링을 계속했다는 분석이다. 특히 robots.txt 파일에 제한을 적용해 AI 회사가 데이터를 스크래핑하는 것을 막을 수 있지만, 이는 법적 구속력이 없는 자발적인 준수 사항, 즉 '침입 금지' 표시에 불과하다는 점이다. 오픈AI나 앤트로픽, 구글 등이 이를 어겼다는 것은 이미 보도된바 있다. 퍼플렉시티도 robots.txt를 무시하고 크롤링을 금지한 웹사이트에 접근하고 있다는 사실이 드러났다. 존 길럼 오리지널리티AI CEO는 \"기업은 웹사이트 콘텐츠의 노출을 낮추지 않으면서도 데이터 훈련에 사용되는 것을 차단할 수 있는 기능을 웹사이트에 제공해야 한다\"라고 지적했다. 이에 대해 메타 대변인은 \"다른 기업들과 마찬가지로 우리는 온라인에 공개적으로 제공된 콘텐츠를 바탕으로 생성 AI 모델을 훈련한다\"라고 말했다. 또 \"우리는 일부 게시자와 웹 도메인 소유자가 자신의 웹사이트와 생성 AI에 대해 선택권을 원한다는 점을 인식하고 있다\"라며 “따라서 여러 웹 크롤링 봇을 운영, 모든 사용 사례를 단일 에이전트로 묶지 않음으로써 웹 게시자들에게 더 많은 유연성을 제공하는 것\"이라고 설명했다. 한편, 메타는 봇 차단 방법에 대한 정보를홈 페이지에공개했다. 박찬 기자 cpark@aitimes.com"
}