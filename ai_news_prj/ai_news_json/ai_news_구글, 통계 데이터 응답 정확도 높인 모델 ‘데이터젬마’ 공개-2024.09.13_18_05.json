{
    "title": "구글, 통계 데이터 응답 정확도 높인 모델 ‘데이터젬마’ 공개",
    "created_at": "2024.09.13 18:05",
    "content": "논리나 산술, 비교 연산 등이 수반되는 통계 데이터 쿼리에 대한 응답 정확도 높이는 모델이 나왔다. 이를 통해 수치 및 통계적 사실과 관련된 모델의 환각 문제를 해결할 수 있게 됐다는 설명이다. 벤처비트는 12일(현지시간) 구글이 통계 데이터를 토대로 하는 쿼리에서 환각이나 오답을 줄이기 위한 오픈 소스 모델 ‘데이터젬마(DataGemma)’에 관한논문을 발표했다고 보도했다. 대형언어모델(LLM)은 수치나 통계 데이터 등을 포함하는 질문에 대해 부정확한 정보를 생성하는 경향이 있다. 통계적 사실과 관련된 사용자 쿼리에는 다양한 논리, 산술 또는 비교 연산이 포함될 수 있기 때문이다. 예를 들어 \"세계에서 이산화탄소를 가장 많이 배출하는 5개국은 어디인가\" \"미국과 중국의 이산화탄소 배출량을 출처별로 비교하라\" 등과 같은 쿼리에 대해서다. 또 공개된 통계 데이터는 올바르게 해석하려면 종종 배경에 대한 맥락을 파악할 필요가 있다. 이를 위해 일반적으로 검색 증강 생성(RAG) 시스템을 통합한다. 구글은 공공 통계 저장소인 데이터 커먼스(Data Commons)의 실세계 데이터를 활용, 정확성을 높이기 위해 두가지 접근 방식으로 젬마 모델을 미세조정했다. 첫번째 접근 방식인 RIG(Retrieval Interleaved Generation)은 모델의 원래 생성 결과와 데이터 커먼스에 저장된 관련 통계와 비교하는 방식이다. 이를 위해 미세조정된 LLM은 원래의 자연어 쿼리를 다중 모델 후처리 파이프라인이 구조화된 데이터 쿼리로 변환한다. 이어 데이터 커먼스에서 관련 답변을 검색하거나 LLM 생성 결과를 수정, 관련 인용을 제공한다. 두번째 접근 방식은 이미 훈련 데이터 외의 정보를 통합하기 위해 사용하는 RAG 기법이다. 이 경우, 미세조정된 젬마 모델은 원래의 통계 질문을 사용해 관련 변수를 추출하고 데이터 커먼스를 위한 자연어 쿼리를 생성한다. 이 쿼리는 데이터베이스에서 관련 통계나 표를 가져온다. 답이 나오면 원래의 사용자 쿼리를 합쳐, 긴 컨텍스트를 가진 '제미나이 1.5 프로'에 프롬프트로 제공해 최종 답변을 생성한다. 101개의 수작업 쿼리 세트를 사용한 테스트 결과, RIG로 미세조정된 데이터젬마 변형 모델은 기준 모델의 정답율을 5~17%에서 58%로 향상할 수 있었다. RAG의 경우 결과는 다소 덜 인상적이었지만, 여전히 기준 모델보다 나은 성과를 보였다. RAG로 미세조정된 데이터젬마 변형 모델은 24~29%의 쿼리에 대해 데이터 커먼스에서 통계적 응답을 제공할 수 있었다. 기존 LLM은 숫자에서 올바른 추론을 도출하는 데 6~20%의 빈도로 어려움을 겪었다. 이처럼 RIG와 RAG 모두 통계 쿼리를 처리하는 모델 정확성을 향상하는 데 효과적일 수 있다는 것을 입증했다. 반면, 두 접근 방식 모두 각각의 강점과 약점을 가지고 있다. RIG는 개별 통계를 검색하고 검증하기 때문에 빠르지만, 세부 사항이 부족하다. RAG는 포괄적인 데이터를 제공하지만, 데이터 가용성에 제약이 있으며 큰 컨텍스트를 처리할 필요가 생긴다. 현재 데이터젬마 모델은허깅페이스에서학술 및 연구 용도로 사용가능하다. 박찬 기자 cpark@aitimes.com"
}