{
    "title": "xAI, 이미지 생성 통합한 '그록-2' 출시...\"세계 최고 성능 입증\"",
    "created_at": "2024.08.15 11:40",
    "content": "일론 머스크의 xAI가 프론티어급 대형멀티모달모델(LMM) '그록-2(Grok-2)'를 출시했다. 그록-2 역시 각종 벤치마크에서 기존 모델들을 앞섰다고 주장했다. 특히 이 모델은 며칠 전 세계 최고 이미지 생성 모델을 출시한 블랙 포레스트와 협력, 이미지 생성 기능을 추가했다. 벤처비트는 14일(현지시간) xAI가 그록-2와 '그록-2 미니(mini)'를 X(트위터)를 통해 베타 버전으로 출시했다고 전했다. 이 모델들은 월 7달러의 X 프리미엄 구독자가 사용할 수 있다. 또 이달 말까지 엔터프라이즈 API를 통해 제공될 예정이다. 그록-2는 채팅과 코딩, 추론 및 비전 기반 애플리케이션을 포함한 광범위한 작업에서 최첨단 성능을 제공한다. 반면, 그록-2 미니는 효율성을 위해 최적화된 더 작고 빠른 버전으로, 간단한 텍스트 기반 프롬프트에 적합하다. 벤치마크에서는 오픈AI의 'GPT-4o'와 앤트로픽의 '클로드 3.5 소네트', 구글의 '제미나이 프로 1.5' 등 첨단 모델의 성능을 일부 뛰어넘었다고 밝혔다. 구체적으로 대학원 수준의 과학 지식(GPQA), 일반 지식(MMLU, MMLU-Pro) 및 수학 경쟁 문제(MATH)와 같은 분야에서 다른 프런티어 모델과 경쟁할 수 있는 성능 수준을 달성했다고 밝혔다. 또 시각 기반 작업에서 탁월, 시각적 수학 추론(MathVista) 및 문서 기반 질문 답변(DocVQA)에서 최첨단 성능을 제공한다고 강조했다. 또 인간 선호도를 가리는 LMSYS의 챗봇 아레나에서도 'sus-column-r'라는 이름으로 등록, GPT-4o와 제미나이 최신 버전의 뒤를 이었다. 이선 몰릭 펜실베이니아대학교 워튼 경영대학원 교수는 X를 통해 \"이제는 GPT-4 클래스 모델은 5가지로 늘어났다. GPT-4o, 클로드 3.5, 제미나이 1.5, 라미 3.1 그리고 그록-2\"라고 선언했다. 머스크 CEO도 X를 통해 \"열심히 일하는 xAI 팀\"이라며 칭찬했다. 하지만 성능보다 더 눈길을 끈 것은 이미지 생성 기능이다. 이는 xAI가 개발한 것이 아니라, 독일 스타트업 블랙 포레스트 랩스의 이미지 생성 인공지능(AI) 모델 ‘플럭스.1(FLUX.1)’를 통합한 것이다. 앞서 지난 2일 블랙 포레스트 랩스는 플럭스.1을 출시하며 '스테이블 디퓨전'이나 '미드저니', '달리 3'보다 성능이 뛰어난 세계 최고 성능의 이미지 생성 모델이라고 주장했다. 이 회사는 스태빌리티 AI 출신 연구원들이 설립한 회사로, 트랜스포머와 확산(Diffusion) 기술을 결합한 하이브리드 아키텍처를 사용해 모델을 개발했다. 플럭시.1은 이미 몇주 동안 AI 및  AI아트 커뮤니티에서 놀라운 퀄리티로 화제가 됐다. 특히 xAI는 다른 이미지 생성 AI와는 달리, 도널드 트럼프나 칼머랄 해리스와 같은 유명인 이미지 생성을 허용하고 있다. 이는 머스크 CEO가 밝힌 \"자유로운 언론 정신\"을 고수한다는 방침이다. https://twitter.com/BenjaminDEKR/status/1823582769521283293?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1823582769521283293%7Ctwgr%5E8ba30048948546a8d19355ee1f93dba6833ff53d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fventurebeat.com%2Fai%2Fgrok-2-arrives-with-image-generations-is-the-world-ready%2F 한편, 지난해 7월 설립된 xAI는 같은 해 12월 '그록'을 처음 선보였다. 이어 3월에는 그록을 오픈 소스로 공개했고, 이어 몇주 뒤에는 향상된 추론 능력과 늘어난 컨텍스트 창을 갖춘 '그록-1.5'를 출시했다. 또 4월에는 최초의 멀티모달모델(LMM)인 '그록-1.5V'까지 추가했다. 이후 머스크 CEO는 \"엔비디아 'H100' 2만개로 그록-2를 훈련 중\"이라고 밝혔으며, 지난달 22일에는 GPU 10만개로 '그록-3' 훈련을 시작했다고 선언했다. 임대준 기자 ydj@aitimes.com"
}