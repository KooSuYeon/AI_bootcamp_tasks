{
    "title": "애플, 휴대폰 화면 이해하고 작용하는 AI 출시...모바일 'AI 에이전트' 공개하나",
    "created_at": "2024.04.13 16:51",
    "content": "애플이 휴대폰의 화면의 정보를 이해해 '시리(Siri)'와 같은 인공지능(AI) 에이전트과의 상호 작용을 지원하는 새로운 모델을 공개했다. 이를 바탕으로, 6월 개발자 행사에서 '모바일용 AI 에이전트'를 공개할 수도 있을 것으로 보인다. 마크테크포스트는 11일(현지시간) 애플이 모바일 사용자 인터페이스(UI)에 대한 이해와 상호 작용을 향상하기 위해 특별히 개발된 모델인 ‘패럿-UI(Ferret-UI)’에 관한 논문을온라인 아카이브에 게재했다고 전했다. 패럿-UI는 사용자가 AI 에이전트와 대화할 때 화면 내의 이미지, 데이터 등 상호작용할 모든 엔터티들을 참조하거나 사용할 수 있다. 예를 들어 사용자는 휴대폰의 검색앱 화면에서 ‘근처 약국을 찾아줘’라고 AI 에이전트에 요청할 수 있다. 패럿-UI를 적용한 AI 에이전트는 모바일 UI를 이해해 검색창에 검색어를 입력하고 실행까지 할 수 있다. 패럿-UI는 UI 화면을 하위 이미지로 나눈 다음 위젯 분류, 아이콘 인식, OCR, 위젯 찾기 및 아이콘 찾기와 같은 작업을 통해 UI 화면에 포함된 모든 엔터티를 인식한다. 또 다양한 종횡비를 처리하기 위해 ‘모든 해상도(any resolution)’ 전략을 활용, 모바일 UI 화면에 맞게 아키텍처를 조정한다. 하위 이미지는 모델의 이해와 모바일 UI와의 상호 작용 기능을 강화하기 위해 다양한 세부 수준의 시각적 기능을 사용하여 별도로 인코딩된다. 패럿-UI 훈련에는 안드로이드와 아이폰 화면별 UI 작업 데이터셋을 사용했다. 패럿-UI는 UI 벤치마크 테스트에서 오픈 소스 멀티모달언어모델(LMM) ‘패럿’과 'GPT-4V'를 능가하는 성능을 보였다. 아이콘 인식 작업에서 패럿-UI는 GPT-4V 모델에 비해 25% 향상된 정확도 95%를 달성했다. 위젯 분류 성공률은 90%로 GPT-4V를 30% 능가했다. 위젯, 아이콘 찾기 등의 접지 작업에서는 패럿-UI가 각각 92%, 93%의 정확도를 유지해 기존 모델 대비 20%, 22% 향상된 성능을 보였다. 마크테크포스트는 \"직관적이고 접근하기 쉬운 모바일 앱 상호 작용의 잠재력을 보여주며 UI 이해의 미래 발전을 위한 기반을 마련했다\"라며 \"모바일 UI와 상호 작용하는 방식에 진정한 변화를 가져올 수 있는 모델\"이라고 평가했다. 더불어 애플은 지난 1일 음성 비서와의 자연스러운 상호 작용을 위해 화면상에 나타낸 각종 참조 사항은 물론 대화 및 배경 맥락에 참조를 이해할 수 있는 새로운 언어모델 ‘렐름(ReALM)’을 공개했다. 이는 시리와 같은 음성 비서와 대화할 때 백그라운드 작업, 화면 데이터, 대화 관련 엔터티 등 상호작용할 상황별 정보를 참조할 수 있도록 한 것으로, 역시 AI 에이전트에 필요한 기능이다. 잇달아 공개된 두가지 모델을 감안하면, 아이폰에는 사용자가 말로 지시하면 AI가 알아서 앱 작업을 대시 처리하는 모바일 AI 에이전트가 곧 도입될 수 있을 것으로 보인다. 실제로 애플은  6월10일 열리는 연례 개발자 회의 'WWDC 2024'에서 iOS 사상 가장 큰 규모의 변화를 도입할 할 계획으로, 현재 총력을 기울이는 것으로 알려졌다. 다만 AI 에이전트에서 가장 중요한 대형언어모델(LLM)은 아직 출시한 바 없다. 이 때문에 자체 모델 출시에 앞서, 이미 검증된 구글이나 오픈AI 모델을 도입하기 위해 파트너십을 추진한다는 소식도 전해졌다. 한편 모바일 AI 에이전트는 이미 지난 2월 MWC 2024에서 도이치텔레콤이 개념을 선보인 기술이다. 도이치텔레콤은 별도 모바일 앱을 다운로드하지 않고도 항공편, 호텔 등을 예약할 수 있는 새로운 개념의  '앱프리(app-free)' AI 스마트폰을 선보였다. 여러 앱을 하나하나 설치하고 실행하는 대신, AI 에이전트에게 명령을 내리는 방식으로 어지간한 기능을 구현하는 방식이다. 박찬 기자 cpark@aitimes.com"
}