{
    "title": "오픈AI, 'GPT-4o' 출력 16배 늘린 '롱 아웃풋' 모델 출시",
    "created_at": "2024.07.31 18:05",
    "content": "대형언어모델(LLM)의 정확도를 높이기 위해 입력 토큰을 12만8000개로 늘리는 것이 유행인 가운데, 오픈AI가 거꾸로 출력 토큰을 대폭 확대한 새 모델을 테스트용으로 내놓았다. 오픈AI는 29일(현지시간) 홈페이지를 통해 쿼리 당 최대 6만4000개의 출력 토큰을 제공하는 'GPT-4o 롱 아웃풋(Long Output)' 모델을 출시했다고 발표했다. 이는 기존 GPT-4o의 출력 규모인 4000토큰의 16배에 해당하는 크기다. 이를 통해 챗GPT는 약 200페이지에 달하는 중편 소설 분량의 답변을 한번에 내놓을 수 있게 됐다. 입력 토큰의 나면 질문 안에서 답을 찾는 기능으로 인해 모델의 성능이 좋아진다. 그러나 출력 토큰이 늘어나는 것은 모델 비용을 높일 뿐 정확도와는 관계가 없다. 물론 코드 편집이나 글쓰기 수정 등에서 세부적이고 대규모 출력이 필요한 경우 도움이 될 수 있는데, 수요가 얼마나 될지는 미지수다. 실제로 'gpt-4o-64k-putput-alpha' 모델은 ▲입력 100만 토큰 당 6달러 ▲출력 100만 토큰 당 18달러로, 출력 비용이 훨씬 비싸다. 이에 대해 오픈AI는 벤처비트와의 인터뷰에서 \"사용자 피드백에 따른 것\"'이라며 \"우리는 항상 사용자의 요구에 효과적으로 대응하기 위해 새로운 방법을 테스트하고 있다\"라고 밝혔다. 오픈AI는 이 기능을 \"GPT-4o의 실험 버전\"이라고 밝혔다. 일부 사용자에게만 제공되며, 몇주 동안 알파 테스트를 진행한 뒤 확장된 출력이 사용자 요구를 얼마나 효과적으로 충족하는지 데이터를 수집할 예정이다. 한편, 가장 최근 출시된 GPT-4o 미니는 최대 11만2000토큰 입력과 최대 1만6000토큰 출력이 가능하다. 최근 등장하는 타사 모델도 12만8000토큰으로 입력을 확장하는 추세지만, 출력 토큰수에 포커스를 맞춘 경우는 드물다. 따라서 이번 알파 테스트는 더 폭넓은 사용자를 수용하기 위한 시도라는 분석이다. 임대준 기자 ydj@aitimes.com"
}