{
    "title": "엔비디아, 차세대 AI 슈퍼컴퓨터 시스템 ‘DGX GH200’ 공개",
    "created_at": "2023.05.30 16:21",
    "content": "인공지능(AI) 반도체 시장을 장악한 엔비디아가 새로운 슈퍼컴퓨터를 공개했다. 지난 주 엔비디아의 주가가 사상 최고치를 경신했다는 소식에 이어 AI 선두 기업의 행보를 강화하는 모습이다. 엔비디아가 29일(현지시간) 대만 타이베이에서 개막된 ‘컴퓨텍스 2023(COMPUTEX 2023)’ 컨퍼런스에서 새로운 슈퍼컴퓨터 ‘DGX GH200’을 선보였다. DGX GH200 슈퍼 컴퓨터는 엔비디아 GH200 그레이스 호퍼 슈퍼칩과 엔비디아 NVLink 스위치 시스템을 탑재하고, 생성 AI 언어 애플리케이션과 추천 시스템, 데이터 분석 워크로드에 사용될 차세대 AI 모델 개발을 지원한다. DGX GH200은 초당 230TB 대역폭을 갖춘 NVLink를 사용해 256개의 GH200 그레이스 호퍼 슈퍼칩과 144TB의 공유 메모리를 단일 GPU처럼 결합한다. 이전 세대 엔비디아 DGX A100보다 거의 500배 향상된 1엑사플롭의 성능과 100배 커진 144TB 규모 공유 메모리를 제공한다. 또 H100 대비 5.2배 이상의 처리 성능을 지녔다. GH200 그레이스 호퍼 슈퍼칩은 엔비디아 NVLink-C2C 칩을 사용하여 동일한 패키지에서 Arm 기반 엔비디아 그레이스 CPU와 엔비디아 호퍼 H100 텐서 코어 GPU를 결합해 기존 CPU-GPU PCIe 연결이 필요 없다. 이는 최신 PCIe 기술에 비해 GPU와 CPU 사이의 대역폭을 7배 증가시키고 상호 연결 전력 소비를 5배 이상 줄이며 DGX GH200 슈퍼컴퓨터를 위한 600GB 호퍼 아키텍처 GPU 빌딩 블록을 제공한다. 엔비디아는 이날 엔비디아 GH200 그레이스 호퍼 슈퍼칩 양산에 돌입했다고 발표했다. DGX GH200은 그레이스 호퍼 슈퍼칩과 엔비디아 NVLink 스위치 시스템을 결합한 최초의 슈퍼컴퓨터다. 이를 바탕으로 DGX GH200 시스템 내 256개의 GPU가 하나 처럼 작동한다. 이전 세대 시스템에서는 NVLink를 사용해 성능의 저하 없이 결합 가능한 GPU의 개수가 8개에 불과했다. DGX GH200 아키텍처는 이전 세대보다 48배 더 많은 NVLink 대역폭을 제공하여 단일 GPU 프로그래밍의 단순성과 함께 대규모 AI 슈퍼컴퓨터의 성능을 제공한다. 젠슨 황 엔비디아 CEO는 “생성AI, 대규모 언어 모델 및 추천 시스템은 현대 경제의 디지털 엔진이다. DGX GH200 AI 슈퍼컴퓨터는 엔비디아의 가장 앞선 가속 컴퓨팅 및 네트워킹 기술을 통합하여 AI의 경계를 확장한다.\"고 강조했다. DGX GH200 슈퍼컴퓨터는 또한 엔비디아 소프트웨어를 포함해 턴키(turnkey) 방식의 풀스택 솔루션을 제공해 대규모의 AI와 데이터 분석 워크로드를 지원한다. 엔비디아 ‘베이스 커맨드(Base Command)’ 소프트웨어는 AI 워크플로우 관리와 엔터프라이즈급 클러스터 관리, 컴퓨팅, 스토리지 및 네트워크 인프라 가속 라이브러리, AI 워크로드 실행에 최적화된 시스템 소프트웨어를 제공한다. DGX GH200에는 엔비디아 ‘AI 엔터프라이즈(AI Enterprise)’도 추가된다. 엔비디아 AI 플랫폼의 소프트웨어 계층인 엔비디아 AI 엔터프라이즈는 100개가 넘는 프레임워크와 사전 훈련 모델, 개발용 툴을 통해 생성형 AI와 컴퓨터 비전, 음성 AI 등을 아우르는 프로덕션 AI의 개발과 배포를 간소화한다. 업계는 엔비디아의 새로운 슈퍼컴퓨터가 고객을 떠나지 못하게 하는 유인책이 될 것으로 분석한다. MS, 구글 등의 IT 기업들은 오픈AI의 챗GPT와 같은 서비스 개발을 위해 경쟁하고 있다. 엔비디아의 DGX GH200이 고성능 컴퓨터가 필요한 고객의 수요를 충족하는 데 적격인 셈이다. 현재 세계 AI용 반도체 시장에서 엔비디아의 점유율은 90%에 이른다. 엔비디아는 DGX GH200을 구글 클라우드, 메타, 마이크로소프트 애저 등 주요 클라우드 서비스 업체에 올 연말부터 제공할 예정이라고 밝혔다. 박찬 기자 cpark@aitimes.com"
}