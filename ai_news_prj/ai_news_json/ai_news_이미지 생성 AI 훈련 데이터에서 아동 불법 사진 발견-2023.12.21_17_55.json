{
    "title": "이미지 생성 AI 훈련 데이터에서 아동 불법 사진 발견",
    "created_at": "2023.12.21 17:55",
    "content": "이미지 생성 인공지능(AI) '스테이블 디퓨전'을 학습하는 데 사용한 데이터셋에 1000개 이상의 아동 학대 이미지가 포함된 것으로 알려졌다. 데이터셋 공급 단체는 배포를 즉시 중지했고, 스태빌리티 AI는 필터링으로 문제 이미지를 걸러낸 뒤 학습을 실시했다고 해명했다. 블룸버그는 20일(현지시간) 50억개 이상의 이미지와 캡션이 포함된 데이터셋 라이온-5B(LAION-5B)에 불법 이미지가 포함된 것을 스탠포드 인터넷 관측소(SIO)가 밝혀냈다고 보도했다. 이에 따르면 문제가 된 데이터셋은 독일의 비영리 단체인 라이온이 배포한 것으로, 가장 인기 있는 이미지 데이터셋으로 알려져 있다. SIO는 스탠포드대학교에 본부를 둔 감시 단체로, 캐나다 아동 보호 센터 및 자선 단체 등과 협력해 아동 성적 학대로 의심되는 이미지 3200장 이상을 발견했다. 이중 1000개는 외부 검증이 끝난 것으로 알려졌다. SIO는 원본 사진 링크를 법 집행 기관에 신고했다. 라이온은 곧바로 데이터셋 배포를 중단하고 문제 이미지를 삭제하기 위한 조치에 들어갔다. 이 단체 대변인은 \"우라는 불법 콘텐츠에 대해 무관용 정책을 갖고 있으며, 안전을 확인하기 위해 배포를 중단하고 불법 이미지를 제거하기 위한 필터를 만들어 게시했다\"라고 발표했다. 스태빌리티 AI는 이번 일이 자신들과 무관하다고 주장했다. 성명을 통해 \"이번 문제는 전체적으로 데이터셋에 대한 문제\"라며 \"우리는 이 데이터셋을 필터링한 하위 집합으로 모델을 학습했다. 또 미세조정으로 문제 여지를 남기지 않았다\"라고 밝혔다. 실제로 스테이블 디퓨전에서 아동 학대 이미지를 생성하는 것은 불가능하다. 하지만 SIO는 이 데이터셋을 기반으로 구축한 AI가 \"새롭고 잠재적으로 현실적인\" 관련 콘텐츠를 생성할 수 있다고 경고했다. 특히 \"스테이블 디퓨전 1.5를 기반으로 한 모델은 사용을 중단해야 한다\"라고 권장했다. 스태빌리티 AI는 지난해 말 2.0 버전 공개에 이어 현재는 'XL 터보' 버전을 서비스 중이다. 한편 라이온-5B는 캘리포니아 비영리 단체가 수집한 HTML 코드를 사용해 웹에서 이미지를 찾아 설명 텍스트와 연결한 것으로, 2022년 출시됐다. 이미 몇달 전부터 불법 이미지가 포함돼 있다는 소문이 개발자 커뮤니티와 SNS에서 퍼진 것으로도 확인됐다. 더불어 이번 문제는 AI 학습 데이터의 저작권 문제에 이어 새로운 변수로 떠오를 전망이다. 학습 데이터의 도덕적 문제까지로 확대될지 주목된다. 임대준 기자 ydj@aitimes.com"
}