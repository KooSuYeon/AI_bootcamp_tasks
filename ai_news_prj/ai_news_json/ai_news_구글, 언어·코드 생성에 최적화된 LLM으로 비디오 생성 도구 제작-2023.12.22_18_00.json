{
    "title": "구글, 언어·코드 생성에 최적화된 LLM으로 비디오 생성 도구 제작",
    "created_at": "2023.12.22 18:00",
    "content": "구글이 신개념의 비디오 생성 인공지능(AI)을 선보였다. 기존 이미지 및 비디오 생성 AI에 사용하던 '확산(Diffusion)' 방식 대신, 언어를 생성하는 '트랜스포머' 구조의 대형언어모델(LLM)로 비디오를 학습하고 생성하는 방식을 채택했다. 그 결과는 기대 이상이었다고 밝혔다. 벤처비트는 21일(현지시간) 구글 리서치의 연구진 31명이 비디오 생성을 위한 새 LLM '비디오포이엇(VideoPoet)'을 공개했다고 보도했다. 구글은 공식 블로그를 통해 \"기존 비디오 생성 모델은 대부분 확신 기반 모델\"이라며 \"반면 LLM은 언어와 코딩, 오디오 등 다양한 양식에 걸친 뛰어난 학습 능력을 보이며, 우리는 단일 LLM에서 비디오 생성 기능을 통합하는 데 초점을 맞췄다\"라고 설명했다. 확산 방식은 전체가 노이즈인 원본 이미지를 지속 필터링, 원본에 가까운 이미지를 생성하는 방법을 학습한다. 반면 트랜스포머 구조의 LLM은 개별 토큰으로 작동하기 때문에 비디오 생성이 어렵다. 구글은 이를 해결하기 위해 비디오 및 오디오 클립을 개별 토큰의 시퀀스로 인코딩하고 원래 표현으로 다시 변환할 수 있는 '토크나이저'를 활용했다고 밝혔다. 이를 바탕으로 '텍스트-비디오 전환'이나 '이미지-비디오 전환', '비디오-오디오 전환'은 물론 스타일화 및 페인팅 작업 생성 등 다수 기능을 통합, 비디오 생성을 가능케 한 것이다. 구글은 이처럼 LLM을 사용하면 기존 학습으로 획득한 기능을 효율성 향상을 위해 재사용할 수 있다고 강조했다. 또 인터넷 및 기타 소스의 2억7000개 비디오와 10억개 이상의 텍스트-이미지 쌍으로 모델을 집중 훈련했다고 소개했다. 그 결과 초당 16프레임으로 무려 1분에 달하는 분량의 비디오를 생성했다. 현재 디퓨전 모델 기반 비디오가 10초 내외인 것을 감안하면 상당한 길이다. 또 비디오포이엇이 생성한 비디오와 '소스-1' '비디오크래프터' '페나키' 등 다른 모델의 비디오를 동시에 보여준 선호도 테스트 결과 우위를 거뒀다고 밝혔다. 비디오포이엇이 앞선다고 밝힌 시청자는 24~35%였으나, 다른 모델을 선호한 경우는 8~11%에 그쳤다. 특히 비디오의 모션 선호도는 41~51%대 11~21%로, 압도적으로 앞섰다. 특히 이 모델의 장점으로 최근 숏폼 트렌드에 맞게 '세로형 비디오'를 기본으로 채택했다는 점을 꼽았다. 구글은 \"앞으로 비디오 포이엇의 기능을 확장, 텍스트-오디오 및 오디오-비디오와 같은 모든 변환 작업을 가능하게 만들어 비디오 생성의 경계를 넓히는 것\"이라고 밝혔다. 하지만 이 모델을 언제 출시할지는 공개하지 않았다. 더 많은 비디오는데모 사이트를 방문하면 확인할 수 있다. 임대준 기자 ydj@aitimes.com"
}