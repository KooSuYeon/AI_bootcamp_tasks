{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 사용환경 준비 (OpenAI)\n",
    "- API-key는 .env에서 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 로드하기\n",
    "- 사용한 모델 : gpt-4o-mini\n",
    "- 명시적으로 불러온 api-key를 할당\n",
    "- 논문에 대한 질문의 답변을 해주는 모델이므로 temperature을 0으로 설정해 창의성을 억제함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 문서 로드하기 (초거대 언어모델 연구 동향.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"data/초거대 언어모델 연구 동향.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다루지 못하는 metaData제거\n",
    "- 표 내용을 PyPDFLoader를 이용한 텍스트 변환을 하게 되면 제대로 열에 따른 띄어쓰기를 하지 못함을 발견\n",
    "- 때문에 Hallucination을 일으킬 수 있는 표 데이터 삭제를 전처리 단계에서 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 0}, page_content='8 특집원고  초거대 언어모델 연구 동향\\n초거대 언어모델 연구 동향\\n업스테이지  박찬준*･이원성･김윤기･김지후･이활석\\n \\n1. 서  론1)\\nChatGPT1)와 같은 초거대 언어모델(Large Language \\nModel, LLM) 의 등장으로 기존에 병렬적으로 연구되\\n던 다양한 자연언어처리 하위 분야들이 하나의 모델\\n로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \\n발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\\n응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \\n되었다. 프롬프트 (Prompt)를 어떻게 모델에게 입력하\\n느냐에 따라서 LLM의 다양한 능력들이 창발되고, 이\\n에 따라 사용자의 목적에 맞는 출력을 생성하는 패러\\n다임을 맞이하게 되었다 [1].\\nLLM은 최근 몇 년 간의 연구 동향에 따라 뛰어난 \\n발전을 이루고 있다. 이러한 발전은 몇 가지 주요한 \\n요인에 기반하고 있으며, 이 요인들은 현대 자연언어\\n처리 (Natural Language Processing, NLP) 연구의 핵심\\n적인 추세로 간주된다. 첫째로, 데이터의 양적 확대는 \\n무시할 수 없는 중요한 요인이다. 디지털화의 선도로, \\n텍스트 데이터의 양이 기하급수적으로 증가하였고, \\n이는 연구의 질적 변화를 가져왔다. 대규모 코퍼스의 \\n활용은 LLM의 일반화 능력을 향상시키며, 다양한 맥\\n락과 주제에 대한 깊은 학습을 가능하게 한다. 둘째\\n로, 컴퓨팅 기술의 진보는 LLM의 발전에 있어 결정\\n적이었다. 특히, Graphics Processing Unit (GPU) 및 \\nTensor Processing Unit (TPU) 와 같은 고성능 병렬 처\\n리 하드웨어의 개발은 모델 학습에 있어 병목 현상을 \\n크게 완화시켰다. 이로 인해 연구자들은 모델의 복잡\\n성을 키우고, 더욱 깊은 신경망 구조를 탐구할 수 있\\n게 되었다. 셋째, 알고리즘 및 기술의 발전은 LLM의 \\n성능 향상을 주도하였다. Attention 및 Transformer \\nArchitecture의 도입은 연구자들에게 문맥 간의 관계\\n를 더욱 정교하게 모델링할 수 있는 방법을 제공하였\\n다 [2, 3]. 이 모든 변화의 중심에는 ‘scaling law’라는 \\n* 정회원\\n1) https://openai.com/blog/chatgpt\\n학문적인 통찰이 있다 [4]. 해당 연구에 따르면, 모델\\n의 크기와 그 성능은 긍정적인 상관 관계를 보인다. \\n이를 통해 연구자들은 모델의 파라미터 수를 증가시\\n키면서, 이에 따른 성능 향상을 기술적 진보의 상호 \\n작용에서 나온 결과이며, 이러한 추세는 앞으로도 \\nNLP 연구의 주요 동력이 될 것으로 예상된다.\\n연구단계를 넘어 LLM은 산업계에서도 많은 발전\\n을 이루어 내고 있다. LLM 은 교육, 의료, 금융, 제조 \\n등 거의 모든 산업 분야에서 광범위한 활용 가능성을 \\n제시하고 있다 [5, 6, 7, 8]. 교육 분야에서는 단순한 \\n정보 검색을 넘어, 개인화된 학습 경로를 추천하는 시\\n스템, 과제의 자동 평가, 학생들의 복잡한 질문에 대\\n한 답변 제공 등의 역할로 활용될 수 있다. 이는 교육\\n의 효율성과 개인화를 동시에 추구하는 현대의 교육 \\n트렌드와 맞물려 큰 효과를 발휘할 것으로 기대된다. \\n의료 분야에서는 환자 데이터를 기반으로 한 초기 진\\n단 도구로 활용될 뿐만 아니라, 복잡한 의료 기록 분\\n석, 신약 개발에 필요한 연구 데이터 분석, 또는 최신 \\n의학 연구 동향 파악 등의 다양한 역할을 수행할 수 \\n있다. 이로써 의료 전문가들의 결정을 보조하고, 효율\\n적인 치료 방향을 도모할 수 있게 된다. 금융 분야에\\n서는 개인의 투자 성향과 시장의 동향을 분석하여 투\\n자 권고를 제공하는 것 외에도, 금융 위험을 상세하게 \\n분석하거나, 복잡한 금융 거래를 자동화하는 시스템\\n의 핵심 구성 요소로서의 역할을 할 수 있다. 이는 금\\n융 서비스의 효율과 안전성 향상에 크게 기여할 것이\\n다. 제조 분야에서도 LLM은 설계 단계부터 생산, 품\\n질 관리에 이르기까지의 전 과정에서 데이터 분석 및 \\n최적화 도구로 활용될 수 있다. 생산 효율성 향상과 \\n제품 품질 향상을 도모하며, 고객의 니즈에 더욱 민첩\\n하게 대응할 수 있는 기회를 제공한다.\\n그러나, 이러한 긍정적인 측면들과 더불어 LLM의 \\n한계점과 위험성도 고려되어야 한다. LLM 은 학습 데\\n이터의 편향성을 그대로 반영할 수 있어, 편향된 결과\\n나 추천을 할 가능성이 있다 [9]. 이는 특히 중요한 의\\n특집원고'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 1}, page_content='2023. 11 정보과학회지 9\\n사 결정을 위해 LLM을 활용하는 경우에 문제가 될 \\n수 있다. 또한, LLM 을 악의적인 목적으로 사용하는 \\n위험성도 있다 [10]. 예를 들면, 미스리딩 정보 생성이 \\n나 편향된 정보 전파를 위한 도구로 활용될 수 있다. \\n이 외에도 LLM의 동작 원리나 결과에 대한 설명력 \\n부족, 최신 정보를 반영하는 데의 한계 등 여러 문제\\n점이 있으며, 이러한 문제점들을 해결하는 것은 다가\\n오는 연구의 중요한 도전 과제로 여겨진다.\\n즉 편향성 (LLM은 학습 데이터에 포함된 편향을 \\n반영할 수 있음), 안전성 (LLM을 악의적인 목적으로 \\n사용할 수 있음), 설명 가능성 (LLM의 예측 결과를 \\n설명하기 어려움), 최신성 (최신정보를 반영하기 어려\\n움)의 문제점을 여전히 LLM의 한계점으로 보유하고 \\n있으며 이러한 문제는 장기적으로 해결하기 위해 연\\n구되어야할 것이다.\\n본 논문은 초거대 언어모델(LLM)에 대한 전반적인 \\n동향을 다루고자 작성되었다. 첫째로 초기의 언어모\\n델부터 현재의 초거대 언어모델까지의 연구 및 발전 \\n과정을 소개한다. 둘째로, 한국어 초거대 언어모델의 \\n특징 및 최근 동향을 조명한다. 셋째로, 최신 초거대 \\n언어모델 연구 동향을 심층적으로 살펴본다. 넷째로, \\n초거대 언어모델의 성능 평가 방식과 그 변화에 대해 \\n논의한다. 마지막으로, 초거대 언어모델 연구와 활용\\n에 있어 중요하게 여겨지는 윤리적 원칙과 관련된 \\n최근의 동향을 소개 한다. 본 논문을 통해 초거대 언\\n어모델에 관한 전반적인 동향과 중요한 주제들에 대\\n한 체계적인 이해를 제공하고, 이 분야의 연구자 및 \\n관련 전문가들에게 유용한 통찰과 지침을 제시하고자 \\n한다.\\n2. 언어모델부터 초거대언어모델까지\\n자연언어란 “인간의 언어”를 의미하며, 자연언어처\\n리는 자연언어를 컴퓨터가 처리하는 것을 의미한다. \\n자연언어처리를 위해서는 인간의 언어표현 체계를 컴\\n퓨터가 이해할 수 있는 형태로 변환해주는 것이 필요\\n하다. 이러한 역할을 하는 것이 바로 언어모델이다. \\n이번 섹션에서는 전통적인 언어모델 연구에 대해 먼\\n저 살펴보고, 의미기반 언어모델 연구, 문맥기반 언어\\n모델 연구, 초거대 언어모델 연구들에 대해 차례로 살\\n펴본다.\\n전통적인 언어모델 연구 전통적인 언어모델은 인간\\n이 사용하는 단어를 컴퓨터가 이해할 수 있는 숫자 \\n체계로 변환하는 데에 초점을 맞춰 발전했다. 이를 위\\n해 전통적인 언어모델은 단어 집합 (vocabulary)을 생\\n성하고, 단어 집합을 이용하여 자연언어를 컴퓨터가 \\n이해할 수 있는 형태로 변환했다. 단어 집합을 이용하\\n여 자연언어를 표현하는 전통적인 방법 중 대표적으\\n로 사용되는 방법은 원-핫 인코딩 (one-hot encoding)\\n이다. 원-핫 인코딩은 표현하고자 하는 단어의 색인 \\n(index)에만 1을 표시 하고, 다른 단어의 색인에는 0을'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 2}, page_content='10 특집원고  초거대 언어모델 연구 동향\\n치하는 정보들을 기억하지 못하는 장기 의존성 문제\\n가 존재한다. 이러한 문제를 극복하기 위해, LSTM \\n(Long Short-Term Memory) [14] 과 GRU (Gated \\nRecurrent Unit) [15] 가 등장했다. 하지만, 이들은 모두 \\n텍스트에 존재하는 단방향 문맥 정보만 활용한다는 \\n한계를 지닌다.\\n양방향 문맥 정보를 활용하기 위해, ELMo [16] 는 \\n주어진 텍스트에 존재하는 순방향 문맥 정보와 역방\\n향 문맥 정보를 함께 활용하는 양방향 학습을 제안했\\n다. 이를 위해, ELMo 는 순방 향 LSTM과 역방향 \\nLSTM를 동시에 활용한다. 하지만, 이는 LSTM을 기\\n반으로 하기 때문에, LSTM이 지니는 다음과 같은 한\\n계를 그대로 가진다: 1) 하나의 벡터에 텍스트의 모든 \\n정보를 담기 때문에 정보 손실이 발생하고, 2) 입력 \\n텍스트의 길이가 길어지면 기울기 소실 (gradient \\nvanishing)이 발생한다.\\n이러한 한계를 해결하기 위해 나온 것이 바로 \\nAttention Mechanism [2] 과 이를 활용한 Transformer \\nArchitecture [3] 이다. Attention Mechanism 은 하나의 \\n벡터에 텍스트의 모든 정보를 담는 RNN, LSTM, \\nGRU와 다르게, 텍스트 내 단어들의 벡터들을 필요에 \\n따라 적절히 활용하는 메커니즘이다. 현재 언어모델\\n의 근간이 되는 Transformer가 바로 이러한 Atten- \\ntion Mechanism을 기반으로 한다. Transformer는 크게 \\n인코더와 디코더로 구성되는데, 인코더는 주어진 텍\\n스트를 이해하는 역할을 하고 디코더는 이해한 텍스\\n트를 기반으로 언어를 생성해내는 역할을 수행한다. \\n이러한 Transformer의 인코더를 기반으로 발전한 대표\\n적인 모델이 Google2)의 BERT (Bidirectional Encoder \\nRepresentations from Transformers) [17] 이고, 디코더\\n를 기반으로 발전한 대표적인 모델이 OpenAI3)의 \\nGPT (Generative Pretrained Transformer) [18] 이다.\\nBERT는 입력 텍스트의 약 15%에 해당하는 임의의 \\n토큰을 마스킹하고 마스킹된 토큰이 무엇인지 예측하\\n는 MLM (Masked Language Modeling) 방식으로 학습\\n된다. 한편, GPT 는 이전 텍스트를 기반으로 다음에 \\n나올 토큰이 무엇인지 예측하는 NTP (Next Token \\nPrediction) 방식으로 학습된다. 이들은 별도의 레이블\\n링 작업 없이 텍스트 데이터만 있으면 학습을 할 수 \\n있다는 강점을 가진다. 이러한 강점을 바탕으로, 이후 \\n문맥기반 언어모델들은 대용량의 텍스트 데이터로 사\\n전학습 (Pretraining) 하고, 이후 특정 태스크로 미세조\\n2) https://www.google.com/\\n3) https://openai.com/\\n정(Fine-tuning)하는 Pretrain-Finetune 패러다임을 중심\\n으로 발전한다.\\n초거대 언어모델 연구 문맥기반 언어모델 이후, 다\\n양한 연구들에서 모델 및 학습 데이터의 크기와 모델\\n의 성능은 긍정적인 상관 관계를 보인다는 ‘scaling \\nl a w ’  [ 4 ,  1 9 ,  2 0 ]가 밝혀지면서, 초거대 언어모델 \\n(Large Language Model, LLM) 이 등장하기 시작했다. \\nLLM은 기존 언어모델에서와 다르게, 모델의 가중치 \\n업데이트 없이도 새로운 태스크를 수행할 수 있는 \\nIn-context learning (Zero-shot learning [21]과 Few-shot \\nlearning [22]) 능력을 가진다. 이처럼 작은 크기의 모\\n델에서는 발현되지 않던 LLM의 능력을 창발 능력 \\n(Emergent ability) [23] 이라고 부른다.\\n이러한 LLM의 창발 능력을 잘 이끌어내기 위한 연\\n구 분야가 바로 프롬프트 엔지니어링이다. 프롬프트 \\n엔지니어링이란 LLM이 모델 가중치 업데이트 없이 \\n특정 태스크를 더욱 잘 해결하게 하기 위해, 입력으로 \\n주는 프롬프트를 어떻게 설계할 것인지에 대한 연구 \\n분야이다. 가장 대표적인 프롬프트 엔지니어링 연구\\n는 Chain-of-Thought (CoT) [24] 가 있다. 이는 해결하\\n고자 하는 태스크의 예시를 일련의 중간 추론 단계와 \\n함께 넣어줌으로써, 복잡한 문제를 여러 단계로 나누\\n어 해결하는 CoT 프롬프트를 제안했다. 또한, 이러한 \\n프롬프트 엔지니어링까지도 LLM으로 대체하고자 하\\n는 연구도 활발히 진행되고 있다 [25].\\n한편, LLM 의 조종성 (Steerability)을 높이기 위해, \\nInstruction Tuning [26]과 Reinforcement Learning from \\nHuman Feedback (RLHF) [27] 과 같은 학습 기법이 등\\n장했다. Instruction Tuning 은 다양한 태스크를 (지시, \\n입력, 출력) 형태의 데이터로 구성하여, 해당 데이터\\n를 통해 LLM을 미세조정하는 학습 기법이다. RLHF\\n는 LLM이 생성할 수 있는 다양한 답변들 중 사용자\\n가 선호할만한 답변을 출력하도록 LLM을 학습하는 \\n기법이다. 하지만, 사용자 선호도를 학습하기 위해 강\\n화학습을 사용하는 RLHF는 학습 과정이 복잡하다는 \\n한계가 있어서, 이를 완화하기 위한 연구도 활발히 진\\n행되고 있다 [28].\\n3. 한국어 초거대 언어모델 동향\\nGPT [21, 22, 29], PALM [30, 20] 과 같은 대규모 \\nLLM 뿐만 아니라,  F a l c o n  [ 3 1 ,  3 2 ] ,  L l a m a  [ 3 3 ,  3 4 ] ,  \\nClaude [35], Qwen [36] 과 같은 비교적 작은 크기의 \\n오픈소스 LLM이 전 세계적으로 공개되고 활발히 연\\n구되고 있다. 하지만, 이러한 LLM들은 일반적으로 한'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 3}, page_content='2023. 11 정보과학회지 11\\n국어를 비효율적으로 토큰화하고, 학습한 한국어 토\\n큰 수가 매우 부족하다는 한계를 가진다 . 실제로, \\nGPT-3 [22] 의 경우 학습된 한국어 토큰의 비율은 \\n0.01697% 밖에 되지 않으며, 오픈소스 LLM인 Llama \\n2 [34] 의 경우도 0.06% 밖에 되지 않는다. 이에 따라, \\n한국어 사용자를 위한 한국어 LLM의 필요성이 대두\\n되고 있다.\\n이러한 필요성에 따라, 최근 많은 국내 기업에서 \\n한국어 LLM을 자체적으로 학습하기 시작했다. Naver \\nClova4)의 HyperClova [37]를 시작으로, Kakao Brain 5)\\n의 KoGPT, KT Enterprise6)의 믿음, LG AI Research 7)\\n의 Exaone, NCSOFT 8)의 V ARCO, SALTLUX9)의 \\nLuxia, 코난테크놀로지10)의 코난 LLM 등 다양한 한\\n국어 LLM이 공개되고 있다. 이들의 공통점은 자체적\\n으로 보유한 한국어 데이터와 공개되어 있는 한국어 \\n데이터, 크롤링 데이터를 적극적으로 활용하여, 한국\\n어 토큰 비율을 높여서 학습하고 있다는 것이다. 더불어 \\n업스테이지의 경우 Llama2를 파인튜닝하여Solar-0-70b  \\n모델을 개발하였고, 글로벌 LLM 플랫폼 중 하나인 \\nPoe.com에 서비스하고 있다11). 해당 모델은 한국어와 \\n영어 모두 지원하고 있다.\\n한편, 오픈소스 한국어 LLM도 존재한다. 가장 대'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 4}, page_content='12 특집원고  초거대 언어모델 연구 동향\\n요한 역할을 한다는 연구 결과들 [41, 42] 에 의해 뒷 \\n받침된다. 예를 들어, 2019 년에 발표된 T5 [43] 는 웹\\n페이지만을 사전학습에 활용하였으나, 이후에 공개된 \\nGPT-3 [22]는 웹페이지를 비롯한, 책 및 뉴스 데이터\\n를 함께 활용하였다. 더불어, Llama-1 65B 모델 [33]\\n에서는 사전학습 데이터 중 웹페이지가 차지하는 비\\n중이 87%에 달하지만, 남은 13%의 데이터는 대화 데\\n이터, 책 및 뉴스, 학술 데이터, 코드 데이터가 골고루 \\n차지하고 있다.\\n이러한 사전학습 데이터의 다양성을 강조하는 추세\\n에도 불구하고, LLM 의 성능 향상을 위한 다양한 코\\n퍼스의 최적 혼합 비율과 필요한 데이터 양에 관한 \\n연구는 아직 초기 단계에 머물러 있다. 이와 관련하여 \\n주목할 만한 연구로는 [41]이 있다. 해당 연구에서는 \\n사전 학습 코퍼스를 시간대, 필터링 기법, 도메인 혼\\n합 비율 조합에 따라 28개로 구분하고, 이를 대상으로 \\n1.5B 파라미터를 갖는 Transformer decoder-only 모델\\n을 학습 하였다. 이들은 사전학습 데이터와 평가 데이\\n터 사이의 시간적 차이 (temporal shift) 때문에 발생하\\n는 성능 저하는 미세조정 만으로는 극복하기 어려움\\n을 발견했으며, 데이터 품질 필터링 및 독성 필터링의 \\n중요성을 정량적으로 증명하였다. 또한, 사전 학습시 \\n이질적인 도메인 코퍼스를 활용하는 것이 전체적으로 \\n도움이 된다는 것을 재확인했다. 또 다른 사례로 \\nGPT-4 [29] 에서는 사전학습에 많은 자원과 시간이 \\n소요되는 문제를 완화하기 위해 predictable scaling 기\\n법을 소개했다. 이를 활용하면 LLM 사전학습 중에 \\n적은 양의 컴퓨팅으로 최종 성능을 정확히 예측할 수 \\n있는 것으로 알려져 있다.\\n코퍼스의 다양성을 강조하는 방향과는 별개로, 하\\n위 태스크에 특화된 LLM을 위한 사전학습에서는 관\\n련된 코퍼스의 비중을 증가시키는 전략도 활용되고 \\n있다. Google 에서 발표한 대화 어플리케이션을 위한 \\n언어 모델인 LaMDA [44]는 전체 사전학습 데이터 비\\n중의 약 절반 (50%) 가량을 대화 데이터로 할당하였\\n으며, 교육 및 콘텐츠 추천 영역에서 해당 모델의 효\\n용성을 입증하였다. 다국어 특화 LLM인 BLOOM \\n[45] 및 PaLM [30] 은 타겟 언어인 영어 이외의 다국\\n어 텍스트를 사전학습에 함께 활용함으로써, 다국어 \\n기반의 번역, 요약, QA 태스크에서 뛰어난 성능을 달\\n성하였다. 과학 도메인 특화 LLM 인 Galactica [46]는 \\n사전학습 데이터의 약 86%를 과학 데이터로 사용하\\n였고, 코드 생성에 특화된 LLM인 AlphaCode [47]는 \\n사전학습 데이터를 전부 코드 데이터로 사용하기도 \\n했다.17)\\n4.1.2 전처리\\n사전학습 시 수집한 데이터를 그대로 사용하는 것\\n은 데이터의 크기와 노이즈, 중복, 독성 데이터 등의 \\n존재로 인해 여러 문제를 야기할 수 있다. 따라서 사\\n전학습 용도로 데이터를 전처리하는 것이 필수적이\\n다. 이러한 전처리 과정은 크게 품질 필터링, 중복 제\\n거, 개인정보 제거, 토큰화의 순서로 이루어진다 [49]. \\n품질 필터링 (quality filtering) 단계에서는 수집된 데\\n이터로부터 저품질의 데이터를 걸러낸다. 해당 단계\\n에서는 고품질의 텍스트 데이터로부터 학습된 분류기\\n를 통해 저품질 데이터를 걸러내거나 [22, 30], 정교하\\n게 디자인된 규칙에 기반한 휴리스틱스 [45, 50]을 사\\n용하는 것이 일반적이다. 사전학습 데이터에 중복되\\n는 데이터가 존재할 경우 LLM의 성능을 저해하는 것\\n으로 알려져 있다 [51]. 이를 방지하기 위해서, 중복 \\n제거 (de-duplication) 단계에서는 반복되는 단어를 갖\\n는 저품질 문장이나, 단어 및 N-그램 기반 겹침 비율\\n에 기반하여 유사한 내용을 갖는 중복 문서들을 필터\\n링한다 [33, 50, 45, 52]. 또한 information leakage를 방\\n지하기 위해, 학습 데이터와 평가 데이터 사이의 중복 \\n데이터도 제거되어야 한다 [30]. 다음으로 개인정보 \\n제거 (privacy reduction) 단계가 수행된다. 대부분의 \\nLLM 사전학습 데이터는 웹 텍스트를 포함하므로 이\\n메일 주소나 전화번호 같은 민감 정보를 포함할 수 있\\n다. 실제로 몇몇 연구들 [53, 54]에서는 정교한 프롬프팅\\n을 통해서 LLM으로부터 개인 식별 정보 (Personally \\nIdentifiable Information, PII) 또는 Github Copilot \\nsecret API keys 와 같은 민감 정보를 추출할 수 있음\\n을 보인 바 있다. 이러한 이유로, LLM 을 윤리적으로 \\n사용하고 개인정보 침해 위험을 제거하기 위해 사전\\n학습 데이터에서 민감 정보를 제거하는 것이 필수적\\n이다. 마지막 전처리 단계로, 원본 텍스트를 토큰이라 \\n불리는 작은 단위의 시퀀스로 분리하는 토큰화 \\n(tokenization) 작업이 수행된다. 이 작업은 LLM이 등\\n장하기 이전의 전통적인 NLP 태스크에서도 중요한 \\n연구 분야였으며, LLM 이 도래한 이후에도 컴퓨팅 비\\n용, 언어 의존성, 정보 손실 등을 고려하여 토큰화를 \\n개선하기 위한 연구가 계속되고 있다. LLM 과 관련된 \\n토크나이저의 중요성에 관한 논의는 [55]를 참고하길 \\n바란다.\\n17) 코드 데이터의 중요성과 관련하여, 최근 연구 [48]는 CoT와 같 \\n은 LLM의 복잡한 추론 능력의 출현이, 텍스트와 차별화되는 코\\n드 데이터의 독특한 특성에 기인하는 것으로 추정하고 있다.'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 5}, page_content='2023. 11 정보과학회지 13\\n4.1.3 기타 고려사항\\n위에서 언급한 데이터 관련 논의 외에도, LLM 사\\n전학습에는 모델의 아키텍처, 모델의 상세 설정, 목적 \\n함수, 학습 환경 세팅 및 학습 테크닉 등 여러 고려사\\n항이 있다. 해당 논의를 모두 다루는 것은 이 논문의 \\n범위를 벗어나므로, 관심 있는 독자는 다음의 서베이 \\n논문 [49]을 참고하길 바란다.\\n4.2 미세조정\\n사전학습이 완료된 LLM은 다양한 하위 태스크를 \\n해결하기 위한 기본적인 준비가 마련된 상태라 할 수 \\n있다. 그럼에도 불구하고, 최근 연구 동향에 따르면 \\nLLM을 특정 목적에 맞게 미세조정 하는 경우가 증가\\n하고 있다. 이러한 미세조정의 대표적인 전략으로는 \\nInstruction Tuning과 Alignment Tuning이 주목받고 있\\n다. 전자는 기존에 본 적 없는 태스크에 대한 일반화 \\n능력 (unseen task generalization ability) 을 향상시키는 \\n방법론이며, 후자는 LLM의 출력을 인간의 가치와 기\\n준에 부합하도록 조정하는 접근법이다. 마지막으로, \\nLLM의 계산 집약적 특성으로 인한 한계를 개선하기 \\n위한 방법론인 자원 효율적인 (resource-efficient) 미세\\n조정 방법에 대해서도 간략히 언급하고자 한다.\\n4.2.1 Instruction Tuning\\nInstruction Tuning 이란 사전학습된 LLM을 대상으\\n로 자연어로 이루어진 포맷팅된 지시사항 (formatted \\ninstructions)과 그에 대응하는 출력 (output) 쌍으로 이\\n루어진 데이터를 기반으로 미세조정하는 추가 훈련 \\n과정을 의미한다 [26]. 이것은 기존의 지도학습 패러\\n다임과 유사하나, Instruction Tuning은 비교적 적은 수\\n의 예제만으로도 뛰어난 성능 및 새로운 태스크에 대\\n한 일반화가 가능한 것으로 알려져, 더욱 효율적인 학\\n습 패러다임이라 할 수 있다 [56].\\nInstruction Tuning 을 위해서는 태스크의 의미를 \\nLLM이 이해할 수 있도록 관련 지시사항과 이에 대응\\n하는 출력으로 이루어진 자연어 포맷의 데이터를 구\\n성해야 한다. 해당 과정은 기존에 존재하는 NLP 분야\\n의 특정한 태스크 (e.g., 번역, 요약, QA 등) 관련 데이\\n터를 형식화하는 것뿐만 아니라, 일상적인 대화 데이\\n터 [27] 또는 모델로부터 합성된 데이터 [57]를 표준 \\n화하는 방법을 포함한다. 사전학습에서 데이터셋의 \\n품질이 중요한 것과 마찬가지로, 데이터셋의 형식 및 \\n품질이 Instruction Tuning의 성공 여부에 중요한 역할\\n을 하는 것으로 알려져 있으며, 지시사항의 다양성과 \\n품질이 예제의 개수보다 더 중요한 것으로 알려져 있\\n다 [58]. 특히, 태스크 당 지시사항의 개수가 너무 많\\n을 경우 오히려 오버피팅이 발생하고, 모델 성능을 저\\n해 하는 것으로 밝혀져서 Instruction Tuning 을 위한 \\n데이터 수집 및 생성에 주의가 필요하다 [59, 60, 61].\\n일반적으로 Instruction Tuning을 통해 LLM은 태스\\n크의 성능 향상을 도모할 수 있다. 최근의 연구들은 \\n[59, 62] 77M 에서 540B에 이르는 다양한 규모의 언어 \\n모델에서 Instruction Tuning을 통한 성능 향상 효과가 \\n나타났다고 보고하였다. 더불어 태스크의 일반화 측\\n면에서 볼 때, Instruction Tuning 은 언어 모델이 자연\\n어 형태의 지시사항을 이해할 수 있도록 돕는다. 이 \\n과정에서 LLM이 인간의 지시에 따라 (instruction \\nfollowing) 특정 태스크를 수행할 수 있는 형태의 창발 \\n능력을 획득하게 된다 [23]. 결과적으로, Instruction- \\ntuned LLM 은 기존 태스크뿐만 아니라 처음 보는 태\\n스크에도 적응하고 일반화하는 능력을 갖게 된다 [59]. \\n또한, 도메인 특화된 데이터셋을 이용한 Instruction \\nTuning을 통해, 일반 LLM을 특정 분야의 전문가로 \\n학습시킬 수 있다. 이러한 시도는 LLM이 범용적인 \\n태스크 솔버 (general-purpose task solver) 측면을 넘어\\n서서, 의학 [63, 64], 법률 [65], 금융 [66] 및 전자상거\\n래 [67]와 같은 특화 도메인에 대해 전문화된 태스크 \\n솔버 (domain-specialized task solver) 로 활용될 수 있\\n음을 시사한다. 보다 자세한 Instruction Tuning에 대한 \\n논의는 다음의 서베이 논문들을 참고하길 바란다 [49, \\n56, 68].\\n4.2.2 Alignment Tuning\\nLLM의 사전학습 과정을 살펴보면, 주로 MLM 또\\n는 NTP 형태의 목적함수를 가지고 학습되기 때문에, \\n주변 또는 이전 컨텍스트를 기반으로 단어를 예측함\\n으로써 학습이 이루어진다. 따라서 사전학습 과정에\\n서는 인간의 선호가 반영된다고 보기 어렵다. 이로 인\\n해 LLM은 종종 유해한 또는 잘못된 정보의 제공이나 \\n편향된 표현을 생성하기도 한다. Alignment Tuning 은 \\n이러한 LLM의 의도치 않은 행동을 방지하기 위한 방\\n법론이다. 대표적인 전략으로, LLM을 인간의 기대치에 \\n맞게 조정하는 ‘human alignment’ [27, 69, 70] 방식이 \\n있다. 그러나 이 방법은 ‘도움이 되는지 (helpfulness)’, \\n‘정직한지 (honesty)’, ‘ 무해한지 (harmlessness)’와 같\\n은 사전학습 및 Instruction Tuning의 목적함수와는 전\\n혀 다른, 주관적인 형태의 alignment criteria를 고려해야 \\n한다. 또한 alignment criteria를 올바르게 측정하기 위\\n해서는 고품질의 human feedback 수집이 필수적이라 \\n상대적으로 많은 비용이 소모된다.'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 7}, page_content='2023. 11 정보과학회지 15\\n인간의 의사결정 과정과 비슷한 측면이 있다. 마지막\\n으로, ICL 은 전통적인 지도학습 방식에 비해 training- \\nfree learning 구조를 가지고 있으므로, 새로운 태스크 \\n적응에 필요한 계산 비용을 크게 줄일 수 있으며, 확\\n장 가능한 (scalable) 특성을 지닌다.\\n이렇듯 유용한 ICL은 어떤 원리로 작동하는 것일\\n까? 연구자들은 LLM의 대표적인 활용 패러다임으로 \\n자리 잡은 ICL의 작동 원리를 규명하기 위해 다양한 \\n측면에서 가설을 제안하였다. Chan et al. (2022) [83]\\n은 ICL 능력이 학습 데이터의 분포 특성으로부터 기\\n인한다고 주장하였다. Xie et al. (2022) [84] 은 ICL을 \\n암시적 베이지안 추론으로 설명하면서, 사전학습 분\\n포가 은닉 마코프 모델의 혼합 (mixture of hidden \\nMarkov models) 형태를 따를 때 ICL 능력이 나타난다\\n는 것을 증명하기 위해 합성 데이터 세트를 구성하였\\n다. Garg et al. (2022) [85] 은 알맞은 시연 예제가 주\\n어질 경우, Transformer가 본 적 없는 선형 함수를 학\\n습할 수 있는 효과적인 학습 알고리즘을 인코딩할 수 \\n있음을 증명하였다. 그들은 또한 ICL에 인코딩된 학\\n습 알고리즘이 최소 제곱 추정기의 오류와 비슷한 수\\n준의 오류를 달성할 수 있음을 발견하였다. 또다른 연\\n구들은 ICL과 경사 하강법 (gradient descent) 사이의 \\n관계를 발견하려고 시도했으며, 특히 최근의 연구 [86]\\n는 Transformer 기반의 in-context learner가 표준 미세\\n조정 알고리즘을 암시적으로 구현할 수 있음을 발견\\n했다. Dai et al. (2023) [87] 은 Transformer attention과 \\n경사 하강법 사이의 dual form을 밝혀냈고, 이에 따라 \\nICL을 암시적 미세조정 (implicit fine-tuning)으로 이\\n해할 것을 제안하였다. 또한, GPT 기반 ICL과 실제 \\n태스크에 대한 명시적인 미세조정을 비교한 결과, 여\\n러 관점에서 ICL이 미세 조정과 유사하게 동작함을 \\n발견하였다. Olsson et al. (2022) [88] 은 Transformer \\n내에서 이전 패턴을 복사하여 다음 토큰을 완성하는 \\n유도 헤드 (induction head)들이 존재함을 밝혔고, 이\\n러한 기능이 ICL을 구현할 수 있음을 제시했다.\\nICL 관점에서, 추론 능력을 보다 강화하기 위한 연\\n구로 CoT [24] 가 소개되었다. CoT 는 입력과 출력 사\\n이의 중간 추론 단계 (intermediate reasoning steps) 을 \\n시연 형태로 추가함으로써 이루어진다. CoT 프롬프팅\\n은 입력-출력 매핑을 여러 중간 단계로 분해함으로써, \\n산술 추론 [89], 상식 추론 [90] 및 기호 추론 [24] 등의 \\n복잡한 추론 태스크에서 LLM의 성능을 향상 시킬 수 \\n있다. 최근에는 다양한 추론 경로 (multiple reasoning \\npaths)를 생성하고 도출된 답변들간의 합의점을 찾는 \\n형태로 기존의 CoT를 강화하는 연구들이 제안되기도 \\n했다 [57, 91]. 이 외에도 재귀적인 프롬프팅 [92]을 \\n통해서 compositional generalization [93] 능력이 요구\\n되는 복잡한 태스크를 해결한 사례도 존재한다.\\n4.3.2 Augmented LLMs\\nLLM은 missing token prediction 목적 함수를 최적\\n화하는 형태로 학습되기 때문에, 사실이 아니지만 구\\n조적으로 그럴듯하게 보이는 컨텐츠를 생성하는 환각 \\n등의 내재적인 한계를 지니고 있다. 또한, 자연어 코\\n퍼스를 활용하여 학습되기 때문에, 주요 NLP 태스크\\n가 아닌 산술 추론 (e.g., 1234+4321=?) 등에 약점을 \\n보이기도 한다. 모델 크기 관점에서는, LLM 의 창발 \\n능력을 발휘하기 위해서는 대용량의 지식 등을 기억\\n해야 하고 결과적으로 많은 수의 파라미터를 요구하\\n게 된다. 기존 연구 [23] 에 따르면, 파라미터 수가 적은 \\n언어 모델은 LLM에서 나타나는 in-context learning, \\ninstruction following, step-by-step reasoning 과 같은 창\\n발 능력이 발현되지 않는다고 한다. 즉, 좋은 성능의 \\nLLM은 필연적으로 많은 수의 파라미터를 요구하게 \\n되는 것이다. 이러한 내재적인 한계를 해결하고 적은 \\n수의 파라미터로도 목적을 달성할 수 있도록, LLM 을 \\n추론 (reasoning) 및 도구 사용 (use tools) 관점에서 강\\n화한 모델을 Augmented LLMs 이라 부른다 [94]. 이 \\n중에서 추론에 관한 내용은 프롬프팅을 통해서 고도\\n화된 추론 능력을 LLM에게 부여하는 것으로, 앞서 \\n4.3.1에서 논의한 ICL 및 CoT와 연관이 깊다. 따라서 \\n해당 섹션에서는 도구 사용에 대해서 주로 논의할 것\\n이다. 이외의 Augmented LLMs에 대한 심도 있는 논\\n의는 다음 논문을 참조하길 바란다 [94].\\nRetrieval Augmented Generation LLM의 파라미터는 \\n일종의 내부 메모리 모듈의 역할을 수행하는데, 특정\\n한 태스크의 해결을 위해서는 context 내에 명시되지 \\n않은 정보를 내재적으로 갖춰야 하는 경우가 많고, 그 \\n결과로 파라미터의 수가 증가하게 된다. 그러나, 만약 \\nLLM이 외부의 지식 또는 정보에 효과적으로 접근하\\n며 그 정보를 활용할 수 있다면, 모든 지식을 내부 메\\n모리에 저장하는 대신, 필요한 정보를 외부에서 추출\\n하여 사용하는 방식으로 파라미터 수를 줄일 수 있을 \\n것이다. 이러한 관점에서 볼 때, 검색 엔진과 같은 도\\n구를 외부 메모리 모듈로 활용하는 LLM은 특정 쿼리\\n와 관련된 정보를 빠르게 색인하고 추출하여 사실 기\\n반의 답변 제공 및 최신 정보를 반영이 가능하며, 불\\n필요한 지식의 저장을 최소화함으로써, 모델의 파라\\n미터 수를 획기적으로 줄일 수 있다. 이러한 방법론을'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='16 특집원고  초거대 언어모델 연구 동향\\nRetrieval Augmented Generation (RAG) [95, 96, 97, \\n98]이라 한다.\\nOther Tools L a M D A  [ 4 4 ]는 대화 애플리케이션에 \\n특화된 LLM으로, 검색 모듈, 계산기 및 번역기 등의 \\n외부 도구 호출 기능을 가지고 있다. WebGPT [99] 는 \\n웹 브라우저와의 상호작용을 통해 검색 쿼리에 사실 \\n기반의 답변과 함께 출처 정보를 제공 한다. PAL \\n[100]은 Python 인터프리터를 통한 복잡한 기호 추론 \\n기능을 제공하며, 여러 관련 벤치마크에서 뛰어난 성\\n능을 보여주었다. 다양한 종류의 API (e.g., 계산기, 달\\n력, 검색, QA, 번역 등 단순한 API에서부터 Torch/ \\nTensorFlow/HuggingFace Hub에 이르는 복잡한 API까\\n지) 호출 기능을 갖춘 연구들 [101, 102, 103, 104, \\n105] 역시 존재한다. Microsoft는 최근 발표한 position \\npaper [104] 에서 LLM과 같은 기반 모델을 뇌 (brain) \\n와 같은 중앙 통제 시스템으로 사용하여 다양한 API\\n를 연동하는 방식으로 자사 AI 제품의 청사진을 제시\\n하였다. 이외의 참고할만한 사례로는, 오픈소스 프로\\n젝트인 LangChain18)과 상용 제품인 ChatGPT Plugin\\ns19) 등이 있으며, 이들은 LLM을 기반으로 사용자가 \\n원하는 외부 API와의 연동을 쉽게 할 수 있도록 설계\\n되었다. 국내의 비슷한 사례로는 CLOV A X20)가 있으\\n나, 아직까지는 내부 및 제휴사 API만 연동된 것으로 \\n보인다. 이외에도, 단순 도구 사용을 넘어서서 LLM을 \\n활용한 가상 에이전트 [106] 및 물리적 로봇 [107] 제\\n어에 활용한 사례도 존재한다.\\n5. 초거대 언어모델 평가 동향\\n예전부터 NLP 분야에서는 인간 수준의 성능을 달\\n성하기 위하여 다양한 벤치마크 데이터셋이 개발되었\\n다. 기존 벤치마크 데이터셋은 대부분 고도의 언어 이\\n해 능력 [108, 109] 과 일반 상식기반의 추론 능력을 \\n측정하는데 초점을 맞추고 있다 [110, 111, 112, 113, \\n114]. LLM의 등장 이후, 대부분의 벤치마크 데이터셋\\n의 유효성은 크게 낮아지고 변별력이 줄어들고 있는 \\n상황이다. 한국에서도 KoBEST [115], KLUE [116] 와 \\n같은 벤치 마크 데이터셋이 물론 존재하지만, LLM 을 \\n평가하는데 적합한 형태로 보기 어렵다. 즉 LLM이 \\n얼마나 정확한 지식을 내재하고 있으며, 이를 얼마나 \\n적절하게 발현할 수 있는지에 대한 새로운 평가 척도\\n의 개발이 절실하다. 이러한 연구와 평가 방법론의 변\\n18) https://www.langchain.com\\n19) https://openai.com/blog/chatgpt-plugins\\n20) https://clova-x.naver.com\\n화는 언어 모델의 복잡성과 다양성이 증가함에 따라 \\nNLP분야에 있어서 신중하게 고려되어야 할 중요한 \\n주제이다.\\n5.1 OpenLLM Leaderboard\\n최근, HuggingFace는 OpenLLM Leaderboard를 공개\\n하면서, 복수의 벤치마크 데이터셋을 통해 LLM의 성\\n능을 체계적으로 평가하고 있다. LLM 이 여전히 정복\\n하지 못한 추론능력, 환각현상, 상식능력 등을 종합적\\n으로 검증할 수 있는 리더보드이다. 이러한 평가 방식\\n은 GLUE [108]와 SuperGLUE [109]를 중심으로 하던 \\n언어 모델 평가의 패러다임을 전환시키고 있다 . \\nHuggingFace의 OpenLLM Leaderboard 에서는 다음과 \\n같은 4가지 종류의 평가 방법을 제시한다. ARC ( AI2 \\nReasoning Challenge) [117] 는 초등학교 수준의 과학 \\n문제를 바탕으로 모델의 추론 능력을 평가한다. ARC\\n는 2,590개의 challenge set 과 5,197개의 easy set 으로 \\n구성되고 있으며, challenge set 은 단어 중첩과 정보 \\n검색 알고리즘을 활용하여 재구성함으로써 모델이 오\\n답을 선택하거나 어렵도록 유도한다. 이를 통해 모델\\n의 추론 능력을 다각도로 평가할 수 있다.\\nHellaSWAG [ 1 1 8 ]는 일반 상식을 기반으로 한 추론 \\n능력을 평가한다. 사람에게는 약 95%의 정답율을 지\\n니는 쉬운 평가이지만, 적대적 필터링으로 인해서 모\\n델에게 난해할 수 있는 선택지를 포함하였다. 이를 통\\n해 모델의 일반상식 능력을 평가할 수 있다.\\nMMLU [ 1 1 9 ]는 언어모델이 광역 도메인의 지식에 \\n대해서 사전 훈련 과정에서 얼마나 이를 습득하고 발\\n현하는지 평가한다. 인문학, 사회학, 과학 등 57개의 \\n도메인에 대해서 초등학교 수준부터 전문가의 영역까\\n지의 문제 해결을 포함한다. 총 15,908개의 질의응답 \\n쌍을 지니고 있으며, 각 도메인마다 최소 100개 이상\\n의 예시를 포함하고 있다. 이를 통해 모델의 언어종합\\n이해능력도를 측정할 수 있다.\\nTruthfulQA [120] 는 언어모델이 얼마나 높은 정보\\n력을 바탕으로 신뢰성 있는 정보를 생산하는지 평가\\n한다. 온라인에서 수집한 텍스트 정보는 허위 정보를 \\n포함할 가능성이 높으며, 모델 사이즈가 커지는 것은 \\n오히려 허위 정보를 모방할 가능성이 높아진다는 것\\n을 가정한다. 38 개의 도메인에 817개의 질의 쌍을 구\\n성하고, zero-shot 세팅을 기본으로 모델의 성능을 측\\n정 한다. 성능에 대한 평가는 진실성과 정보전달 측면\\n으로 나누어 진행하며, 사람 평가자의 점수와 해당 점\\n수로 학습을 진행한 모델을 활용한다. 이를 통해 모델\\n의 환각현상에 얼마나 강건한지 평가할 수 있다. 국내'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 10}, page_content='18 특집원고  초거대 언어모델 연구 동향\\n버시 보호, 3) 다양성 존중, 4) 침해금지, 5) 공공성, 6) \\n연대성, 7) 데이터 관리, 8) 책임성, 9) 안정성, 10) 투\\n명성 등의 요건이 충족되어야 한다는 내용이 포함되\\n어 있다.\\n다양한 윤리 원칙에 명시된 내용들은 크게 6가지로 \\n인간성, 책임성, 보안성, 안전성, 투명성, 다양성으로 \\n구분된다.\\n인간성 (Humanity & Human-centered)은 인공지능\\n의 개발과 활용은 인간과 사회에 유익한 가치를 제공\\n하며 인간의 권리와 자유를 침해하지 않는다는 내용\\n이다.\\n책임성 (Responsibility & Accountability)은 인공지\\n능을 개발하고 활용하는 주체들의 역할과 책임을 명\\n확히 설정하여 발생할 수 있는 피해를 최소화 한다는 \\n내용이다.\\n보안성 (Privacy & Security)은 인공지능 개발 및 활\\n용하는 과정에서 사용자의 개인정보와 프라이버시를 \\n보호하기 위해 정보 보안을 고려하여 설계한다는 내\\n용이다.\\n안전성 (Safety & Reliability)은 인공지능의 개발과 \\n활용 과정에서 발생할 수 있는 잠재적 위험에 대응하\\n고 안전하게 작동할 수 있도록 한다는 내용이다.\\n투명성 (Transparency & Explainability)은 인공지능 \\n의 작동 방식 또는 데이터 활용 방안에 대해 투명하\\n게 공개하여 사용자들의 이해를 높이고 신뢰할 수 있\\n도록 한다는 내용이다. \\n다양성 (Fairness & Diversity)은 인공지능을 개발하\\n고 활용하는 과정에서 성별･연령･국적･인종･지역･종\\n교 등에 대한 차별을 최소화하여 다양한 가치를 존중\\n한다는 내용이다.\\n이외에도 각 기업마다 인공지능 윤리원칙을 제시하\\n고 있으며 이에 대한 정보는 표 1과 같다.\\n7. 결  론\\n본 논문은, 초거대언어모델 (LLM)의 발전과 활용\\n에 대한 근본적인 이해를 제공하려 하였다. LLM 의 \\n등장은 자연언어처리 (NLP)의 다양한 분야에서 혁신\\n적인 변화를 가져왔으며, 이로 인해 번역, 요약, 질의\\n응답, 형태소분석 등 다양한 태스크들이 하나의 모델\\n로 수행될 수 있게 되었다. 데이터의 양적 확대, 컴퓨\\n팅 기술의 진보, 그리고 알고리즘 및 기술의 발전은 \\nLLM의 발전을 이끌었다. 이러한 기술적, 연구적 발전\\n은 교육, 의료, 금융, 제조 등 다양한 산업 분야에서 \\nLLM의 활용 가능성을 넓혔다. 그러나, LLM 의 활용\\n과 발전에는 여러 가지 도전 과제와 문제점이 존재한\\n다. 편향성, 안전성, 설명 가능성 및 최신성 문제는 \\nLLM의 한계점으로 지속적으로 고려되어야 하며, 이\\n러한 문제점들을 해결하는 것은 다가오는 연구에서의 \\n중요한 도전 과제로 남아 있다. 이러한 문제와 도전을 \\n극복함으로써, LLM 은 향후 NLP 연구와 산업계에서 \\n더욱 중요한 역할을 차지할 것으로 예상된다. 이 분야\\n의 연구가 계속 진행됨에 따라, 더욱 정교하고 다양한 \\n어플리케이션의 등장이 기대되며, 이를 통해 사회적, \\n산업적 가치가 더욱 향상될 것이다. LLM 의 연구와 \\n활용은 계속되는 윤리적 고민과 함께 발전해 나가야 \\n하며, 향후 연구는 이러한 모델의 가능성과 한계를 더\\n욱 탐색하고 활용 하는 방향으로 전개될 것으로 보인\\n다. 본 논문이 LLM에 대한 깊이 있는 이해를 제공하\\n고, 이 분야의 연구자 및 전문가들에게 유익한 인사이\\n트와 지침을 제공할 수 있기를 희망한다.\\n참고문헌\\n[ 1 ] J. Zhang, H. Feng, B. Liu, and D. Zhao, “Survey of \\ntechnology in network security situation awareness,” \\nSensors, V ol. 23, No. 5, p. 2608, 2023.\\n[ 2 ] D. Bahdanau, K. Cho, and Y . Bengio, “Neural machine \\ntranslation by jointly learning to align and translate,” \\narXiv preprint arXiv:1409.0473, 2014.\\n[ 3 ] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, \\nA. N. Gomez, L- . Kaiser, and I. Polosukhin, “Attention \\nis all you need,” Advances in neural infor- mation \\nprocessing systems, V ol. 30, 2017.\\n[ 4 ] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. \\nChess, R. Child, S. Gray, A. Radford, J. Wu, and D. \\nAmodei, “Scaling laws for neural language models,” \\narXiv preprint arXiv:2001.08361, 2020.\\n[ 5 ] I. L. Alberts, L. Mercolli, T. Pyka, G. Prenosil, K. Shi, A. \\nRominger, and A. Afshar-Oromieh, “Large lan- guage \\nmodels (llm) and chatgpt: what will the impact on nuclear \\nmedicine be?” European journal of nuclear medicine and \\nmolecular imaging, V ol. 50, No. 6, pp. 1549–1552, 2023.\\n[ 6 ] M. Fraiwan and N. Khasawneh, “A review of chat- gpt \\napplications in education, marketing, software en- \\ngineering, and healthcare: Benefits, drawbacks, and re- \\nsearch directions,” arXiv preprint arXiv:2305.00237, \\n2023.\\n[ 7 ] M. Sallam, N. Salim, M. Barakat, and A. Al-Tammemi, \\n“Chatgpt applications in medical, dental, pharmacy, and \\npublic health education: A descriptive study high-'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 11}, page_content='2023. 11 정보과학회지 19\\nlighting the advantages and limitations,” Narra J, V ol. 3, \\nNo. 1, pp. e103–e103, 2023.\\n[ 8 ] A. Bahrini, M. Khamoshifar, H. Abbasimehr, R. J. Riggs, \\nM. Esmaeili, R. M. Majdabadkohne, and M. Pasehvar, \\n“Chatgpt: Applications, opportunities, and threats,” 2023 \\nSystems and Information Engineer- ing Design \\nSymposium (SIEDS), pp. 274–279, 2023.\\n[ 9 ] O. Shaikh, H. Zhang, W. Held, M. Bernstein, and D. Yang, \\n“On second thought, let’s not think step by step! bias and \\ntoxicity in zero-shot reasoning,” arXiv preprint \\narXiv:2212.08061, 2022.\\n[10] B. Hu, Q. Sheng, J. Cao, Y . Shi, Y . Li, D. Wang, and P . \\nQi, “Bad actor, good advisor: Exploring the role of large \\nlanguage models in fake news detection,” arXiv preprint \\narXiv:2309.12247, 2023.\\n[11] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Ef- ficient \\nestimation of word representations in vector space,” arXiv \\npreprint arXiv:1301.3781, 2013.\\n[12] J. Pennington, R. Socher, and C. D. Manning, “Glove: \\nGlobal vectors for word representation,” Proceedings of \\nthe 2014 conference on empirical methods in natural \\nlanguage processing (EMNLP), pp. 1532–1543, 2014.\\n[13] P . Bojanowski, E. Grave, A. Joulin, and T. Mikolov, \\n“Enriching word vectors with subword information,” \\nTransactions of the association for computational lin- \\nguistics, V ol. 5, pp. 135–146, 2017.\\n[14] S. Hochreiter and J. Schmidhuber, “Long short-term \\nmemory,” Neural computation, V ol. 9, No. 8, pp. 1735–\\n1780, 1997.\\n[15] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bah- danau, \\nF. Bougares, H. Schwenk, and Y . Bengio, “Learning \\nphrase representations using rnn encoder- decoder for \\nstatistical machine translation,” arXiv preprint \\narXiv:1406.1078, 2014.\\n[16] M. E. Peters, M. Neumann, M. Iyyer , M. Gardner, C. \\nClark, K. Lee, and L. Zettlemoyer, “Deep contextualized \\nword representations,” Proceedings of the 2018 \\nConference of the North American Chapter of  the  \\nAssociation  for  Computational  Linguistics: Human \\nLanguage Technologies, Volume 1 (Long Papers), pp. \\n2227–2237, Jun. 2018. [Online]. Available: \\nhttps://aclanthology.org/N18-1202\\n[17] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: \\nPre-training of deep bidirectional transform- ers for \\nlanguage understanding,” arXiv preprint arXiv:1810. \\n04805, 2018.\\n[18] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et \\nal., “Improving language understanding by genera- tive \\npre-training,” 2018.\\n[19] D. Hernandez, J. Kaplan, T. Henighan, and S. Mc- \\nCandlish, “Scaling laws for transfer,” arXiv preprint \\narXiv:2102.01293, 2021.\\n[20] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lep- ikhin, \\nA. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen et al., \\n“Palm 2 technical report,” arXiv preprint arXiv:2305. \\n10403, 2023.\\n[21] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. \\nSutskever et al. , “Language models are unsupervised \\nmultitask learners,” OpenAI blog, V ol. 1, No. 8, p. 9, 2019.\\n[22] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Ka- plan, \\nP . Dhariwal, A. Neelakantan, P . Shyam, G. Sas- try, A. \\nAskell et al., “Language models are few-shot learners,” \\nAdvances in neural information processing systems, V ol. \\n33, pp. 1877–1901, 2020.\\n[23] J. W ei, Y . T ay , R. Bommasani, C. Raffel, B. Zoph, S. \\nBorgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler \\net al. , “Emergent abilities of large language models,” \\narXiv preprint arXiv:2206.07682, 2022.\\n[24] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. \\nC h i ,  Q .  V .  L e ,  D .  Z h o u  et al. , “Chain-of-thought \\nprompting elicits reasoning in large language models,” \\nAdvances in Neural Information Processing Systems, V ol. \\n35, pp. 24 824–24 837, 2022.\\n[25] C. Yang, X. Wang, Y . Lu, H. Liu, Q. V . Le, D. Zhou, and \\nX. Chen, “Large language models as optimizers,” arXiv \\npreprint arXiv:2309.03409, 2023.\\n[26] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester, \\nN. Du, A. M. Dai, and Q. V . Le, “Finetuned language \\nmodels are zero-shot learners,” arXiv preprint arXiv: \\n2109.01652, 2021.\\n[27] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wain- wright, \\nP. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray et \\nal., “Training language models to follow in-structions \\nwith human feedback,” Advances in Neural Information \\nProcessing Systems, Vol. 35, pp. 27 730–27 744, 2022.\\n[28] Z. Y uan, H. Y uan, C. T an, W . W ang, S. Huang, and F . \\nHuang, “Rrhf: Rank responses to align language models \\nwith human feedback without tears,” arXiv preprint \\narXiv:2304.05302, 2023.\\n[29] OpenAI, “Gpt-4 technical report,” 2023.\\n[30] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. \\nMishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton,'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 12}, page_content='20 특집원고  초거대 언어모델 연구 동향\\nS. Gehrmann et al., “Palm: Scaling language modeling \\nwith pathways,” arXiv preprint arXiv:2204.02311, 2022.\\n[31] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap- pelli, \\nR. Cojocaru, M. Debbah, E. Goffinet, D. Hes- low, J. \\nLaunay, Q. Malartic et al. , “Falcon-40b: an open large \\nlanguage model with state-of-the-art perfor- mance,” \\nTechnical report, Technology Innovation In- stitute, Tech. \\nRep., 2023.\\n[32] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. \\nCappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. \\nLaunay, “The refinedweb dataset for falcon llm: \\noutperforming curated corpora with web data, and web \\ndata only,” arXiv preprint arXiv:2306.01116, 2023.\\n[33] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. \\nLachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, \\nF. Azhar et al. , “Llama: Open and efficient foundation \\nlanguage models,” arXiv preprint arXiv:2302.13971, \\n2023.\\n[34] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma- hairi, \\nY . Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale \\net al. , “Llama 2: Open foundation and fine-tuned chat \\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\\n[35] Anthropic, “Model card and evaluations for claude \\nmodels,” 2023.\\n[36] A. Group, “Qwen technical report,” 2023.\\n[37] B. Kim, H. Kim, S.-W. Lee, G. Lee, D. Kwak, D. H. Jeon, \\nS. Park, S. Kim, S. Kim, D. Seo et al., “What changes can \\nlarge-scale language models bring? intensive study on \\nhyperclova: Billions-scale korean generative pretrained \\ntransformers,” arXiv preprint arXiv:2109.04650, 2021.\\n[38] H. Ko, K. Yang, M. Ryu, T. Choi, S. Yang, S. Park et al., \\n“A technical report for polyglot-ko: Open-source \\nlarge-scale korean language models,” arXiv preprint \\narXiv:2306.02254, 2023.\\n[39] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. \\nArora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, \\nE. Brunskill et al. , “On the opportuni- ties and risks of \\nfoundation models,” arXiv preprint arXiv:2108.07258, \\n2021.\\n[40] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and \\nD. Yang, “Is chatgpt a general-purpose natu- ral language \\nprocessing task solver?” arXiv preprint arXiv:2302. \\n06476, 2023.\\n[41] S. Longpre, G. Yauney, E. Reif, K. Lee, A. Roberts, B. \\nZoph, D. Zhou, J. Wei, K. Robinson, D. Mimno et al., “A \\npretrainer’s guide to training data: Measur- ing the effects \\nof data age, domain coverage, quality, & toxicity,” arXiv \\npreprint arXiv:2305.13169, 2023.\\n[42] A. Lee, B. Miranda, and S. Koyejo, “Beyond scale: the \\ndiversity coefficient as a data quality metric demon- \\nstrates llms are pre-trained on formally diverse data,” \\narXiv preprint arXiv:2306.13840, 2023.\\n[43] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. \\nMatena, Y . Zhou, W. Li, and P. J. Liu, “Exploring the limits \\nof transfer learning with a unified text-to- text \\ntransformer,” The Journal of Machine Learning Research, \\nV ol. 21, No. 1, pp. 5485–5551, 2020.\\n[44] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, \\nKulshreshtha,  H.-T.  Cheng,  A.  Jin,  T.  Bos, L. Baker, \\nY.  D u  et al. , “Lamda: Language models for dialog \\napplications,” arXiv preprint arXiv:2201.08239, 2022.\\n[45] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili’c, D. \\nHesslow, R. Castagn´e, A. S. Luccioni, F. Yvon, M. Gall´e \\net al., “Bloom: A 176b-parameter open- access \\nmultilingual language model,” arXiv preprint arXiv: \\n2211.05100, 2022.\\n[46] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. \\nHartshorn, E. Saravia, A. Poulton, V . Kerkez, and R. \\nStojnic, “Galactica: A large language model for sci- ence,” \\narXiv preprint arXiv:2211.09085, 2022.\\n[47] Y . Li, D. Choi, J. Chung, N. Kushman, J. Schrit- twieser, \\nR. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago \\net al. , “Competition-level code genera-tion with \\nalphacode,” Science, V ol. 378, No. 6624, pp. 1092–\\n1097, 2022.\\n[48] H. Fu, Yao; Peng and T. Khot, “How does gpt obtain its \\nability? tracing emergent abilities of language mod- els \\nto their sources,” Yao Fu’s Notion, Dec 2022.\\n[49] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . \\nMin, B. Zhang, J. Zhang, Z. Dong et al., “A survey of large \\nlanguage models,” arXiv preprint arXiv:2303.18223, \\n2023.\\n[50] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoff- mann, \\nF. Song, J. Aslanides, S. Henderson, R. Ring, S. Young \\net al., “Scaling language models: Meth-ods, analysis & \\ninsights from training gopher,” arXiv preprint arXiv: \\n2112.11446, 2021.\\n[51] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. \\nDrain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. \\nHenighan, T. Hume et al. , “Scaling laws and in- \\nterpretability of learning from repeated data,” arXiv \\npreprint arXiv:2205.10487, 2022.'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 13}, page_content='2023. 11 정보과학회지 21\\n[52] K. Lee, D. Ippolito, A. Nystrom, C. Zhang, D. Eck, C. \\nCallison-Burch, and N. Carlini, “Deduplicating training \\ndata makes language models better,” arXiv preprint \\narXiv:2107.06499, 2021.\\n[53] N. Lukas, A. Salem, R. Sim, S. Tople, L. Wutschitz, and \\nS. Zanella-B´eguelin, “Analyzing leakage of per-sonally \\nidentifiable information in language models,” arXiv \\npreprint arXiv:2302.00539, 2023.\\n[ 5 4 ]L .  N i u ,  S .  M i r z a ,  Z .  M a r a d n i ,  a n d  C .  P ¨ o p p e r ,  \\n“{CodexLeaks}: Privacy leaks from code generation \\nlanguage models in {GitHub} copilot,” 32nd USENIX \\nSecurity Symposium (USENIX Security 23), pp. 2133– \\n2150, 2023.\\n[55] J.  Kaddour,  J.  Harris,  M.  Mozes,  H.  Bradley, R. Raileanu, \\nand R. McHardy, “Challenges and ap- plications of large \\nlanguage models,” arXiv preprint arXiv:2307.10169, \\n2023.\\n[56] R. Lou, K. Zhang, and W. Yin, “Is prompt all you need? \\nno. a comprehensive and broader view of instruc- tion \\nlearning,” arXiv preprint arXiv:2303.10475, 2023.\\n[57] Y . W ang, Y . Kordi, S. Mishra, A. Liu, N. A. Smith, D. \\nKhashabi, and H. Hajishirzi, “Self-instruct: Align- ing \\nlanguage model with self generated instructions,” arXiv \\npreprint arXiv:2212.10560, 2022.\\n[58] C. Zhou, P. Liu, P. Xu, S. Iyer, J. Sun, Y. Mao, X. Ma, A. \\nEfrat, P . Y u, L. Y u et al. , “Lima: Less is more for \\nalignment,” arXiv preprint arXiv:2305.11206, 2023.\\n[59] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y . Tay, W. \\nFedus, E. Li, X. Wang, M. Dehghani, S. Brahma et al., \\n“Scaling instruction-finetuned language mod- els,” arXiv \\npreprint arXiv:2210.11416, 2022.\\n[60] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Ko- rdi, A. \\nMirzaei, A. Arunkumar, A. Ashok, A. S. Dhanasekaran, \\nA. Naik, D. Stap et al. , “Super- naturalinstructions: \\nGeneralization via declarative in- structions on 1600+ nlp \\ntasks,” arXiv preprint arXiv:2204.07705, 2022.\\n[61] H. Chen, Y . Zhang, Q. Zhang, H. Yang, X. Hu, X. Ma, Y . \\nYanggong, and J. Zhao, “Maybe only 0.5% data is needed: \\nA preliminary exploration of low training data instruction \\ntuning,” arXiv preprint arXiv:2305.09246, 2023.\\n[62] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y . \\nTay, D. Zhou, Q. V . Le, B. Zoph, J. Wei et al., “The flan \\ncollection: Designing data and meth- ods for effective \\ninstruction tuning,” arXiv preprint arXiv:2301.13688, \\n2023.\\n[63] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. \\nChung, N. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl \\net al. , “Large language models encode clinical \\nknowledge,” arXiv preprint arXiv:2212.13138, 2022.\\n[64] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wul- czyn, \\nL. Hou, K. Clark, S. Pfohl, H. Cole-Lewis, D. Neal et al., \\n“Towards expert-level medical question answering with \\nlarge language models,” arXiv preprint arXiv:2305. \\n09617, 2023.\\n[65] C. Xiao, X. Hu, Z. Liu, C. Tu, and M. Sun, “Law- former: \\nA pre-trained language model for chinese legal long \\ndocuments,” AI Open, V ol. 2, pp. 79–84, 2021.\\n[66] S. Wu, O. Irsoy , S. Lu, V . Dabravolski, M. Dredze, S. \\nGehrmann, P. Kambadur, D. Rosenberg, and G. Mann, \\n“Bloomberggpt: A large language model for finance,” \\narXiv preprint arXiv:2303.17564, 2023.\\n[67] Y . Li, S. Ma, X. Wang, S. Huang, C. Jiang, H.-T. Zheng, \\nP. Xie, F. Huang, and Y . Jiang, “Ecomgpt: \\nInstruction-tuning large language model with chain- \\nof-task tasks for e-commerce,” arXiv preprint arXiv: \\n2308.06966, 2023.\\n[68] S. Zhang, L. Dong, X. Li, S. Zhang, X. Sun, S. Wang, J. \\nLi, R. Hu, T. Zhang, F. Wu et al., “Instruction tuning for \\nlarge language models: A survey,” arXiv preprint \\narXiv:2308.10792, 2023.\\n[69] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. \\nRadford, D. Amodei, P. Christiano, and G. Irv- ing, \\n“Fine-tuning language models from human pref- \\nerences,” arXiv preprint arXiv:1909.08593, 2019.\\n[70] A. Askell, Y . Bai, A. Chen, D. Drain, D. Ganguli, T. \\nHenighan, A. Jones, N. Joseph, B. Mann, N. Das- Sarma \\net al., “A general language assistant as a labora- tory for \\nalignment,” arXiv preprint arXiv:2112.00861, 2021.\\n[71] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. \\nDe Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly, \\n“Parameter-efficient transfer learning for nlp,” \\nInternational Conference on Machine Learning, pp. 2790\\n–2799, 2019.\\n[72] Z. Hu, Y . Lan, L. Wang, W. Xu, E.-P . Lim, R. K.-W. Lee, \\nL. Bing, and S. Poria, “Llm-adapters: An adapter family \\nfor parameter-efficient fine-tuning of large lan- guage \\nmodels,” arXiv preprint arXiv:2304.01933, 2023.\\n[73] X. L. Li and P. Liang, “Prefix-tuning: Optimizing \\ncontinuous prompts for generation,” arXiv preprint \\narXiv:2101.00190, 2021.\\n[74] B. Lester, R. Al-Rfou, and N. Constant, “The power of \\nscale for parameter-efficient prompt tuning,” arXiv'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 14}, page_content='22 특집원고  초거대 언어모델 연구 동향\\npreprint arXiv:2104.08691, 2021.\\n[75] X. Liu, Y . Zheng, Z. Du, M. Ding, Y . Qian, Z. Yang, and \\nJ. Tang, “Gpt understands, too,” AI Open, 2023.\\n[76] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, \\nL. Wang, and W. Chen, “Lora: Low-rank adaptation of \\nlarge language models,” arXiv preprint arXiv:2106. \\n09685, 2021.\\n[77] J. He, C. Zhou, X. Ma, T. Berg-Kirkpatrick, and G. \\nNeubig, “Towards a unified view of parameter-efficient \\ntransfer learning,” arXiv preprint arXiv:2110.04366, \\n2021.\\n[78] N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, \\nY. Chen, C.-M. Chan, W. Chen et al., “Parameter-efficient \\nfine-tuning of large-scale pre- trained language models,” \\nNature Machine Intelli- gence, V ol. 5, No. 3, pp. 220–\\n235, 2023.\\n[79] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, \\nand K. Keutzer, “A survey of quantization methods for \\nefficient neural network inference,” Low-Power Com- \\nputer Vision, pp. 291–326, 2022.\\n[80] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettle- \\nmoyer, “Qlora: Efficient finetuning of quantized llms,” \\narXiv preprint arXiv:2305.14314, 2023.\\n[81] Z. Yao, X. Wu, C. Li, S. Youn, and Y . He, “Zeroquant- v2: \\nExploring post-training quantization in llms from \\ncomprehensive study to low rank compensation,” arXiv \\npreprint arXiv:2303.08302, 2023.\\n[82] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. \\nSun, J. Xu, and Z. Sui, “A survey for in-context learning,” \\narXiv preprint arXiv:2301.00234, 2022.\\n[83] S. Chan, A. Santoro, A. Lampinen, J. Wang, A. Singh, P. \\nRichemond, J. McClelland, and F. Hill, “Data dis- \\ntributional properties drive emergent in-context learn- ing \\nin transformers,” Advances in Neural Information \\nProcessing Systems, V ol. 35, pp. 18 878–18 891, 2022.\\n[84] S. M. Xie, A. Raghunathan, P. Liang, and T. Ma, “An \\nexplanation of in-context learning as implicit bayesian \\ninference,” arXiv preprint arXiv:2111.02080, 2021.\\n[85] S. Garg, D. Tsipras, P. S. Liang, and G. Valiant, “What can \\ntransformers learn in-context? a case study of sim- ple \\nfunction classes,” Advances in Neural Information \\nProcessing Systems, V ol. 35, pp. 30 583–30 598, 2022.\\n[86] E. Akyu¨rek, D. Schuurmans, J. Andreas, T. Ma, and D. \\nZhou, “What learning algorithm is in-context learn- ing? \\ninvestigations with linear models,” arXiv preprint \\narXiv:2211.15661, 2022.\\n[87] D. Dai, Y . Sun, L. Dong, Y . Hao, S. Ma, Z. Sui, and F. Wei, \\n“Why can gpt learn in-context? language models \\nimplicitly perform gradient descent as meta- optimizers,” \\nICLR 2023 Workshop on Mathematical and Empirical \\nUnderstanding of Foundation Models, 2023.\\n[88] C. Olsson, N. Elhage, N. Nanda, N. Joseph, N. Das- \\nSarma, T. Henighan, B. Mann, A. Askell, Y . Bai, A. Chen \\net al., “In-context learning and induction heads,” arXiv \\npreprint arXiv:2209.11895, 2022.\\n[89] S.-Y . Miao, C.-C. Liang, and K.-Y . Su, “A diverse cor- pus \\nfor evaluating and developing english math word problem \\nsolvers,” arXiv preprint arXiv:2106.15772, 2021.\\n[ 9 0 ]A .  T a l m o r ,  J .  H e r z i g ,  N .  L o u r i e ,  a n d  J .  B e r a n t ,  \\n“Commonsenseqa: A question answering challenge \\ntargeting commonsense knowledge,” arXiv preprint \\narXiv:1811.00937, 2018.\\n[91] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. \\nZhou, “Rationale-augmented ensembles in language \\nmodels,” arXiv preprint arXiv:2207.00747, 2022.\\n[92] D. Zhou, N. Sch¨arli, L. Hou, J. Wei, N. Scales, X. Wang, \\nD .  S c h u u r m a n s ,  C .  C u i ,  O .  B o u s q u e t ,  Q .  L e  et al. , \\n“Least-to-most prompting enables complex rea- soning \\nin large language models,” arXiv preprint \\narXiv:2205.10625, 2022.\\n[93] B. Lake and M. Baroni, “Generalization without sys- \\ntematicity: On the compositional skills of sequence-to- \\nsequence recurrent networks,” International conference \\non machine learning, pp. 2873–2882, 2018.\\n[94] G. Mialon, R. Dess’ı, M. Lomeli, C. Nalmpantis, R. Pa- \\nsunuru, R. Raileanu, B. Rozi`ere, T. Schick, J. Dwivedi- \\nYu, A. Celikyilmaz et al. , “Augmented language mod- \\nels: a survey,” arXiv preprint arXiv:2302.07842, 2023.\\n[95] P.  Lewis,  E.  Perez,  A.  Piktus,  F.  Petroni, V. Karpukhin, \\nN. Goyal, H. Ku¨ttler, M. Lewis, W.-t. Yih, T. \\nRockt¨aschel et al., “Retrieval-augmented gen- eration \\nfor knowledge-intensive nlp tasks,” Advances in Neural \\nInformation Processing Systems, V ol. 33, pp. 9459–\\n9474, 2020.\\n[96] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, \\n“Retrieval augmented language model pre-training,” \\nInternational conference on machine learning, pp. 3929–\\n3938, 2020.\\n[97] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. \\nRutherford, K. Millican, G. B. V an Den Driessche, J.-B. \\nLespiau, B. Damoc, A. Clark et al., “Improv- ing language \\nmodels by retrieving from trillions of to- kens,”'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 15}, page_content='2023. 11 정보과학회지 23\\nInternational conference on machine learning, pp. 2206–\\n2240, 2022.\\n[98] G.  Izacard,  P.  Lewis,  M.  Lomeli,  L.  Hosseini, F. Petroni, \\nT. Schick, J. Dwivedi-Y u, A. Joulin, S. Riedel, and E. \\nGrave, “Few-shot learning with re- trieval augmented \\nlanguage models,” arXiv preprint arXiv:2208.03299, \\n2022.\\n[99] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, \\nC . H e s s e , S . J a i n , V . K o s a r a j u , W .  S a u n -  d e r s  et al. , \\n“Webgpt: Browser-assisted question- answering with \\nhuman feedback,” arXiv preprint arXiv:2112.09332, \\n2021.\\n[100]L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. \\nCallan, and G. Neubig, “Pal: Program-aided lan- guage \\nmodels,” International Conference on Machine Learning, \\npp. 10 764–10 799, 2023.\\n[101]T. Schick, J. Dwivedi-Yu, R. Dess`ı, R. Raileanu, M.  \\nLomeli,  L.  Zettlemoyer,  N.  Cancedda,  and T. Scialom, \\n“Toolformer: Language models can teach themselves to \\nuse tools,” arXiv preprint arXiv:2302.04761, 2023.\\n[102]S. G. Patil, T. Zhang, X. Wang, and J. E. Gonzalez, \\n“Gorilla: Large language model connected with mas- sive \\napis,” arXiv preprint arXiv:2305.15334, 2023.\\n[103]S. Hao, T. Liu, Z. Wang, and Z. Hu, “Toolkengpt: Aug- \\nmenting frozen language models with massive tools via \\ntool embeddings,” arXiv preprint arXiv:2305.11554, \\n2023.\\n[104]Y . Liang, C. Wu, T. Song, W. Wu, Y . Xia, Y . Liu, Y . Ou, \\nS. Lu, L. Ji, S. Mao et al., “Taskma- trix. ai: Completing \\ntasks by connecting founda- tion models with millions of \\napis,” arXiv preprint arXiv:2303.16434, 2023.\\n[105]Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. \\nCong, X. Tang, B. Qian et al., “Toolllm: Facilitat- ing large \\nlanguage models to master 16000+ real-world apis,” \\narXiv preprint arXiv:2307.16789, 2023.\\n[106]S. Li, X. Puig, C. Paxton, Y . Du, C. Wang, L. Fan, T. Chen, \\nD.-A. Huang, E. Akyu¨rek, A. Anandku- mar et al. , \\n“Pre-trained language models for interac- tive \\ndecision-making,” Advances in Neural Information \\nProcessing Systems, V ol. 35, pp. 31 199–31 212, 2022.\\n[107]A. Zeng, M. Attarian, B. Ichter, K. Choromanski, A. \\nWong, S. Welker, F. Tombari, A. Purohit, M. Ryoo, V . \\nSindhwani et al., “Socratic models: Composing zero-shot \\nmultimodal reasoning with language,” arXiv preprint \\narXiv:2204.00598, 2022.\\n[108]A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. \\nR. Bowman, “Glue: A multi-task benchmark and analysis \\nplatform for natural language understanding,” \\nInternational Conference on Learning Representations, \\n2018.\\n[109]A. Wang, Y . Pruksachatkun, N. Nangia, A. Singh, J. \\nMichael, F. Hill, O. Levy, and S. Bowman, “Su- perglue: \\nA stickier benchmark for general-purpose lan- guage \\nunderstanding systems,” Advances in neural in- \\nformation processing systems, V ol. 32, 2019.\\n[110]R. Zellers, Y . Bisk, R. Schwartz, and Y . Choi, “Swag: A \\nlarge-scale adversarial dataset for grounded common- \\nsense inference,” Proceedings of the 2018 Conference \\non Empirical Methods in Natural Language Processing, \\npp. 93–104, 2018.\\n[111] L. Huang, R. Le Bras, C. Bhagavatula, and Y . Choi, \\n“Cosmos qa: Machine reading comprehension with con- \\ntextual commonsense reasoning,” Proceedings of the \\n2019 Conference on Empirical Methods in Natural \\nLanguage Processing and the 9th International Joint \\nConference on Natural Language Processing (EMNLP- \\nIJCNLP), pp. 2391–2401, 2019.\\n[112]A. T almor, J. Herzig, N. Lourie, and J. Berant, “Com- \\nmonsenseqa: A question answering challenge target- ing \\ncommonsense knowledge,” Proceedings of the 2019 \\nConference of the North American Chapter of the As- \\nsociation for Computational Linguistics: Human Lan- \\nguage Technologies, Volume 1 (Long and Short Pa- pers), \\npp. 4149–4158, 2019.\\n[113]Y . Bisk, R. Zellers, J. Gao, Y . Choi et al., “Piqa: Reasoning \\nabout physical commonsense in natural lan- guage,” \\nProceedings of the AAAI conference on artifi- cial \\nintelligence, V ol. 34, No. 05, pp. 7432–7439, 2020.\\n[114]N.  Mostafazadeh,  A.  Kalyanpur,  L.  Moon, D. Buchanan, \\nL. Berkowitz, O. Biran, and J. Chu- Carroll, “Glucose: \\nGeneralized and contextualized story explanations,” \\nProceedings of the 2020 Con- ference on Empirical \\nMethods in Natural Language Processing (EMNLP), pp. \\n4569–4586, 2020.\\n[115]M. Jang, D. Kim, D. S. Kwon, and E. Davis, “Kobest: \\nKorean balanced evaluation of significant tasks,” Pro- \\nceedings of the 29th International Conference on Com- \\nputational Linguistics, pp. 3697–3708, 2022.\\n[116]S. Park, J. Moon, S. Kim, W. I. Cho, J. Han, J. Park, C. \\nSong, J. Kim, Y . Song, T. Oh et al. , “Klue: Korean \\nlanguage understanding evaluation,” arXiv preprint \\narXiv:2105.09680, 2021.'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_table_section(text):\n",
    "    # \"표\"라는 단어가 포함된 부분부터 그 이후의 내용 제거\n",
    "    text_without_table = re.split(r\"\\n표\", text, maxsplit=1)[0]\n",
    "    return text_without_table.strip()\n",
    "\n",
    "for doc in docs:\n",
    "    doc.page_content = remove_table_section(doc.page_content)\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 문서 청크로 나누기\n",
    "- chunk_size=100: 각 청크의 길이를 100글자로 지정함 이때 한국어, 영어 모두 같은 동일하게 100글자 제한이 적용됨, 논문의 문장의 길이를 살펴본 결과 짧은 문장 구분을 하고 있다는 특징을 파악해 이에적합한 청크 길이를 선택함 (문장의 단위 자체 가 긴 글의 경우 보통 512 토큰을 할당한다고 함)\n",
    "- chunk_overlap=10 : 청크 간 10글자씩 겹침, 앞 뒤로 해당 겹침은 적용이 되며 이는 모델의 청크 간의 문맥을 잃지 않도록 도와줌 (긴 글의 경우 보통 100토큰)\n",
    "- length_function=len : 각 청크의 길이를 측정할 때 len함수를 이용해 계산함\n",
    "- is_sperate_regex=False : 구분자로 정규식을 사용하지 않음, 복잡하지 않은 패턴 매칭일 경우에 사용함\n",
    "\n",
    "---\n",
    "CharacterTextPlitter : 텍스트를 나눌 때 사용할 구분자를 지정해서 나누는 방법\n",
    "RecursiveCharacterTextSplitter : 단일 구분자 기준으로 텍스트를 분할하는 것이 아닌 우선순위에 따라 재귀적으로 적용하여 텍스트를 나눔\n",
    "\n",
    "---\n",
    "\n",
    "#### 결론 : 불러온 문서는 논문임. 때문에 문장단위 유사도보다 문단별 유사도를 통해 찾는 것이 더 적합하다는 판단을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 0}, page_content='8 특집원고  초거대 언어모델 연구 동향\\n초거대 언어모델 연구 동향\\n업스테이지  박찬준*･이원성･김윤기･김지후･이활석\\n \\n1. 서  론1)\\nChatGPT1)와 같은 초거대 언어모델(Large Language \\nModel, LLM) 의 등장으로 기존에 병렬적으로 연구되\\n던 다양한 자연언어처리 하위 분야들이 하나의 모델\\n로 처리되고 있으며, 태스크 수렴 현상 (Converge)이 \\n발생하고 있다. 즉 하나의 LLM으로 번역, 요약, 질의\\n응답, 형태소분석 등의 작업을 모두 처리할 수 있게 \\n되었다. 프롬프트 (Prompt)를 어떻게 모델에게 입력하\\n느냐에 따라서 LLM의 다양한 능력들이 창발되고, 이\\n에 따라 사용자의 목적에 맞는 출력을 생성하는 패러\\n다임을 맞이하게 되었다 [1].\\nLLM은 최근 몇 년 간의 연구 동향에 따라 뛰어난 \\n발전을 이루고 있다. 이러한 발전은 몇 가지 주요한 \\n요인에 기반하고 있으며, 이 요인들은 현대 자연언어\\n처리 (Natural Language Processing, NLP) 연구의 핵심\\n적인 추세로 간주된다. 첫째로, 데이터의 양적 확대는 \\n무시할 수 없는 중요한 요인이다. 디지털화의 선도로, \\n텍스트 데이터의 양이 기하급수적으로 증가하였고, \\n이는 연구의 질적 변화를 가져왔다. 대규모 코퍼스의 \\n활용은 LLM의 일반화 능력을 향상시키며, 다양한 맥\\n락과 주제에 대한 깊은 학습을 가능하게 한다. 둘째\\n로, 컴퓨팅 기술의 진보는 LLM의 발전에 있어 결정\\n적이었다. 특히, Graphics Processing Unit (GPU) 및 \\nTensor Processing Unit (TPU) 와 같은 고성능 병렬 처\\n리 하드웨어의 개발은 모델 학습에 있어 병목 현상을 \\n크게 완화시켰다. 이로 인해 연구자들은 모델의 복잡\\n성을 키우고, 더욱 깊은 신경망 구조를 탐구할 수 있\\n게 되었다. 셋째, 알고리즘 및 기술의 발전은 LLM의 \\n성능 향상을 주도하였다. Attention 및 Transformer \\nArchitecture의 도입은 연구자들에게 문맥 간의 관계\\n를 더욱 정교하게 모델링할 수 있는 방법을 제공하였\\n다 [2, 3]. 이 모든 변화의 중심에는 ‘scaling law’라는 \\n* 정회원\\n1) https://openai.com/blog/chatgpt\\n학문적인 통찰이 있다 [4]. 해당 연구에 따르면, 모델\\n의 크기와 그 성능은 긍정적인 상관 관계를 보인다. \\n이를 통해 연구자들은 모델의 파라미터 수를 증가시\\n키면서, 이에 따른 성능 향상을 기술적 진보의 상호 \\n작용에서 나온 결과이며, 이러한 추세는 앞으로도 \\nNLP 연구의 주요 동력이 될 것으로 예상된다.\\n연구단계를 넘어 LLM은 산업계에서도 많은 발전\\n을 이루어 내고 있다. LLM 은 교육, 의료, 금융, 제조 \\n등 거의 모든 산업 분야에서 광범위한 활용 가능성을 \\n제시하고 있다 [5, 6, 7, 8]. 교육 분야에서는 단순한 \\n정보 검색을 넘어, 개인화된 학습 경로를 추천하는 시\\n스템, 과제의 자동 평가, 학생들의 복잡한 질문에 대\\n한 답변 제공 등의 역할로 활용될 수 있다. 이는 교육\\n의 효율성과 개인화를 동시에 추구하는 현대의 교육 \\n트렌드와 맞물려 큰 효과를 발휘할 것으로 기대된다. \\n의료 분야에서는 환자 데이터를 기반으로 한 초기 진\\n단 도구로 활용될 뿐만 아니라, 복잡한 의료 기록 분\\n석, 신약 개발에 필요한 연구 데이터 분석, 또는 최신 \\n의학 연구 동향 파악 등의 다양한 역할을 수행할 수 \\n있다. 이로써 의료 전문가들의 결정을 보조하고, 효율\\n적인 치료 방향을 도모할 수 있게 된다. 금융 분야에\\n서는 개인의 투자 성향과 시장의 동향을 분석하여 투\\n자 권고를 제공하는 것 외에도, 금융 위험을 상세하게 \\n분석하거나, 복잡한 금융 거래를 자동화하는 시스템\\n의 핵심 구성 요소로서의 역할을 할 수 있다. 이는 금\\n융 서비스의 효율과 안전성 향상에 크게 기여할 것이\\n다. 제조 분야에서도 LLM은 설계 단계부터 생산, 품\\n질 관리에 이르기까지의 전 과정에서 데이터 분석 및 \\n최적화 도구로 활용될 수 있다. 생산 효율성 향상과 \\n제품 품질 향상을 도모하며, 고객의 니즈에 더욱 민첩\\n하게 대응할 수 있는 기회를 제공한다.\\n그러나, 이러한 긍정적인 측면들과 더불어 LLM의 \\n한계점과 위험성도 고려되어야 한다. LLM 은 학습 데\\n이터의 편향성을 그대로 반영할 수 있어, 편향된 결과\\n나 추천을 할 가능성이 있다 [9]. 이는 특히 중요한 의\\n특집원고'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 1}, page_content='2023. 11 정보과학회지 9\\n사 결정을 위해 LLM을 활용하는 경우에 문제가 될 \\n수 있다. 또한, LLM 을 악의적인 목적으로 사용하는 \\n위험성도 있다 [10]. 예를 들면, 미스리딩 정보 생성이 \\n나 편향된 정보 전파를 위한 도구로 활용될 수 있다. \\n이 외에도 LLM의 동작 원리나 결과에 대한 설명력 \\n부족, 최신 정보를 반영하는 데의 한계 등 여러 문제\\n점이 있으며, 이러한 문제점들을 해결하는 것은 다가\\n오는 연구의 중요한 도전 과제로 여겨진다.\\n즉 편향성 (LLM은 학습 데이터에 포함된 편향을 \\n반영할 수 있음), 안전성 (LLM을 악의적인 목적으로 \\n사용할 수 있음), 설명 가능성 (LLM의 예측 결과를 \\n설명하기 어려움), 최신성 (최신정보를 반영하기 어려\\n움)의 문제점을 여전히 LLM의 한계점으로 보유하고 \\n있으며 이러한 문제는 장기적으로 해결하기 위해 연\\n구되어야할 것이다.\\n본 논문은 초거대 언어모델(LLM)에 대한 전반적인 \\n동향을 다루고자 작성되었다. 첫째로 초기의 언어모\\n델부터 현재의 초거대 언어모델까지의 연구 및 발전 \\n과정을 소개한다. 둘째로, 한국어 초거대 언어모델의 \\n특징 및 최근 동향을 조명한다. 셋째로, 최신 초거대 \\n언어모델 연구 동향을 심층적으로 살펴본다. 넷째로, \\n초거대 언어모델의 성능 평가 방식과 그 변화에 대해 \\n논의한다. 마지막으로, 초거대 언어모델 연구와 활용\\n에 있어 중요하게 여겨지는 윤리적 원칙과 관련된 \\n최근의 동향을 소개 한다. 본 논문을 통해 초거대 언\\n어모델에 관한 전반적인 동향과 중요한 주제들에 대\\n한 체계적인 이해를 제공하고, 이 분야의 연구자 및 \\n관련 전문가들에게 유용한 통찰과 지침을 제시하고자 \\n한다.\\n2. 언어모델부터 초거대언어모델까지\\n자연언어란 “인간의 언어”를 의미하며, 자연언어처\\n리는 자연언어를 컴퓨터가 처리하는 것을 의미한다. \\n자연언어처리를 위해서는 인간의 언어'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 2}, page_content='10 특집원고  초거대 언어모델 연구 동향\\n치하는 정보들을 기억하지 못하는 장기 의존성 문제\\n가 존재한다. 이러한 문제를 극복하기 위해, LSTM \\n(Long Short-Term Memory) [14] 과 GRU (Gated \\nRecurrent Unit) [15] 가 등장했다. 하지만, 이들은 모두 \\n텍스트에 존재하는 단방향 문맥 정보만 활용한다는 \\n한계를 지닌다.\\n양방향 문맥 정보를 활용하기 위해, ELMo [16] 는 \\n주어진 텍스트에 존재하는 순방향 문맥 정보와 역방\\n향 문맥 정보를 함께 활용하는 양방향 학습을 제안했\\n다. 이를 위해, ELMo 는 순방 향 LSTM과 역방향 \\nLSTM를 동시에 활용한다. 하지만, 이는 LSTM을 기\\n반으로 하기 때문에, LSTM이 지니는 다음과 같은 한\\n계를 그대로 가진다: 1) 하나의 벡터에 텍스트의 모든 \\n정보를 담기 때문에 정보 손실이 발생하고, 2) 입력 \\n텍스트의 길이가 길어지면 기울기 소실 (gradient \\nvanishing)이 발생한다.\\n이러한 한계를 해결하기 위해 나온 것이 바로 \\nAttention Mechanism [2] 과 이를 활용한 Transformer \\nArchitecture [3] 이다. Attention Mechanism 은 하나의 \\n벡터에 텍스트의 모든 정보를 담는 RNN, LSTM, \\nGRU와 다르게, 텍스트 내 단어들의 벡터들을 필요에 \\n따라 적절히 활용하는 메커니즘이다. 현재 언어모델\\n의 근간이 되는 Transformer가 바로 이러한 Atten- \\ntion Mechanism을 기반으로 한다. Transformer는 크게 \\n인코더와 디코더로 구성되는데, 인코더는 주어진 텍\\n스트를 이해하는 역할을 하고 디코더는 이해한 텍스\\n트를 기반으로 언어를 생성해내는 역할을 수행한다. \\n이러한 Transformer의 인코더를 기반으로 발전한 대'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 3}, page_content='2023. 11 정보과학회지 11\\n국어를 비효율적으로 토큰화하고, 학습한 한국어 토\\n큰 수가 매우 부족하다는 한계를 가진다 . 실제로, \\nGPT-3 [22] 의 경우 학습된 한국어 토큰의 비율은 \\n0.01697% 밖에 되지 않으며, 오픈소스 LLM인 Llama \\n2 [34] 의 경우도 0.06% 밖에 되지 않는다. 이에 따라, \\n한국어 사용자를 위한 한국어 LLM의 필요성이 대두\\n되고 있다.\\n이러한 필요성에 따라, 최근 많은 국내 기업에서 \\n한국어 LLM을 자체적으로 학습하기 시작했다. Naver \\nClova4)의 HyperClova [37]를 시작으로, Kakao Brain 5)\\n의 KoGPT, KT Enterprise6)의 믿음, LG AI Research 7)\\n의 Exaone, NCSOFT 8)의 V ARCO, SALTLUX9)의 \\nLuxia, 코난테크놀로지10)의 코난 LLM 등 다양한 한\\n국어 LLM이 공개되고 있다. 이들의 공통점은 자체적\\n으로 보유한 한국어 데이터와 공개되어 있는 한국어 \\n데이터, 크롤링 데이터를 적극적으로 활용하여, 한국\\n어 토큰 비율을 높여서 학습하고 있다는 것이다. 더불어 \\n업스테이지의 경우 Llama2를 파인튜닝하여Solar-0-70b  \\n모델을 개발하였고, 글로벌 LLM 플랫폼 중 하나인 \\nPoe.com에 서비스하고 있다11). 해당 모델은 한국어와 \\n영어 모두 지원하고 있다.\\n한편, 오픈소스 한국어 LLM도 존재한다. 가장 대'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 4}, page_content='12 특집원고  초거대 언어모델 연구 동향\\n요한 역할을 한다는 연구 결과들 [41, 42] 에 의해 뒷 \\n받침된다. 예를 들어, 2019 년에 발'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 5}, page_content='2023. 11 정보과학회지 13\\n4.1.3 기타 고려사항\\n위에서 언급한 데이터 관련 논의 외에도, LLM 사\\n전학습에는 모델의 아키텍처, 모델의 상세 설정, 목적 \\n함수, 학습 환경 세팅 및 학습 테크닉 등 여러 고려사\\n항이 있다. 해당 논의를 모두 다루는 것은 이 논문의 \\n범위를 벗어나므로, 관심 있는 독자는 다음의 서베이 \\n논문 [49]을 참고하길 바란다.\\n4.2 미세조정\\n사전학습이 완료된 LLM은 다양한 하위 태스크를 \\n해결하기 위한 기본적인 준비가 마련된 상태라 할 수 \\n있다. 그럼에도 불구하고, 최근 연구 동향에 따르면 \\nLLM을 특정 목적에 맞게 미세조정 하는 경우가 증가\\n하고 있다. 이러한 미세조정의 대'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 7}, page_content='2023. 11 정보과학회지 15\\n인간의 의사결정 과정과 비슷한 측면이 있다. 마지막\\n으로, ICL 은 전통적인 지도학습 방식에 비해 training- \\nfree learning 구조를 가지고 있으므로, 새로운 태스크 \\n적응에 필요한 계산 비용을 크게 줄일 수 있으며, 확\\n장 가능한 (scalable) 특성을 지닌다.\\n이렇듯 유용한 ICL은 어떤 원리로 작동하는 것일\\n까? 연구자들은 LLM의 대'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='16 특집원고  초거대 언어모델 연구 동향\\nRetrieval Augmented Generation (RAG) [95, 96, 97, \\n98]이라 한다.\\nOther Tools L a M D A  [ 4 4 ]는 대화 애플리케이션에 \\n특화된 LLM으로, 검색 모듈, 계산기 및 번역기 등의 \\n외부 도구 호출 기능을 가지고 있다. WebGPT [99] 는 \\n웹 브라우저와의 상호작용을 통해 검색 쿼리에 사실 \\n기반의 답변과 함께 출처 정보를 제공 한다. PAL \\n[100]은 Python 인터프리터를 통한 복잡한 기호 추론 \\n기능을 제공하며, 여러 관련 벤치마크에서 뛰어난 성\\n능을 보여주었다. 다양한 종류의 API (e.g., 계산기, 달\\n력, 검색, QA, 번역 등 단순한 API에서부터 Torch/ \\nTensorFlow/HuggingFace Hub에 이르는 복잡한 API까\\n지) 호출 기능을 갖춘 연구들 [101, 102, 103, 104, \\n105] 역시 존재한다. Microsoft는 최근 발'),\n",
       " Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits_char = text_splitter.split_documents(docs)\n",
    "splits_char[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "splits_recur = recursive_text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splits_recur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 벡터 임베딩 생성\n",
    "- 텍스트를 벡터로 변환해줌\n",
    "\n",
    "### 6. 벡터 스토어 생성\n",
    "- FAISS : 대규모 벡터 데이터를 효율적으로 저장하고 유사도 검색을 수행함\n",
    "- 벡터 스토어란 벡터를 저장하고 저장한 벡터를 유사도 기반으로 검색하기 위해 설계된 DB와 비슷한 개념\n",
    "- 즉, 벡터 스토어가 큰 개념이고, 이를 활용할 수 있는 라이브러리로 FAISS가 존재하는데 특히나 대규모 벡터 데이터의 검색을 위해 최적회된 라이브러리임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. FAISS를 Retriever로 변환\n",
    "- retriever 사용 이유 : 벡터 유사도 검색을 한 후 (FAISS) 검색 결과를 텍스트 형태로 반환해줘야 하기 때문\n",
    "- search_type=\"similarity\" : 유사도 기반 검색\n",
    "- search_kwargs={\"k\": 5} : 검색에 해당하는 Document를 5개 가져옴 (엄밀히 말하자면 문장의 자세한 정보가 포함되어 있는 5개의 Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG 성능 올리기 - Retreiever 활용\n",
    "\n",
    "- 기본 유사도 기반 FAISS retriever를 사용한 것에 더해 BM25 retriever를 함께 앙상블 시킴\n",
    "- BM25Retriever는 단어 빈도 기반 점수 계산 retriever임\n",
    "- 앙상블의 비율은 0.5씩 할당해 단어 빈도 점수, FAISS 기반 유사도가 높은 상위 5개의 문서가 추출됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "faiss_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "retriever = EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, faiss_retriever],\n",
    "            weights=[0.5, 0.5]  # 가중치 설정 (가중치의 합은 1.0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 프롬프트 템플릿 정의\n",
    "- system : 답변해줄 AI의 역할 및 요구사항 정의\n",
    "- user : 사용자에게 입력받을 사항 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. RAG 체인 구성\n",
    "1. contextual_prompt로 들어온 question은 rag_chain_debug에서 retriever로 전달됨\n",
    "2. 관련된 문서 리스트는 input[\"context\"] 형태로 전달됨\n",
    "3. RunnablePassthrough 클래스는 데이터를 전달하는 역할을 함. invoke() 메서드를 통해 입력된 데이터를 반환함\n",
    "4. ContextToText 클래스 내의 invoke 함수를 통해 inputs[\"context\"]로 들어온 관련 문서 (Document) 는 문자열로 결합되게 되어 model로는 content와 question을 결합한 딕셔너리 형태로 model에 전달됨\n",
    "5. DebugPassThrough 클래스 내의 invoke 함수는 디버깅 (어느 페이지에서 어떤 줄의 내용을 근거했는지를 추적하기 위한 용도). ContextToText 클래스와는 다르게 어떠한 가공도 하지 않음\n",
    "6. 정리하자면 앞서 FAISS를 통해 질문과 관련있는 Document를 가져오고 model은 들어온 질문 데이터 분석과 가져온 Document를 기반으로 한 답변 데이터 생성을 하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,                    # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()        # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()|   contextual_prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 챗봇 구동 확인\n",
    "\n",
    "#### 질문\n",
    "---\n",
    "\n",
    "아래 질문들의 경우 표 데이터를 제거한 후 제대로 추출할 수 있었던 질문, 표 데이터도 같은 문맥의 문서로 취급되었기 때문\n",
    "\n",
    "\n",
    "\n",
    "1. Open  Ko-LLM  Leaderboard에는 어떤 기업들이 참여하고 있어?\n",
    "2. Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?\n",
    "\n",
    "---\n",
    "\n",
    "아래 질문들의 경우 retriever에 BM25를 적용함으로 제대로 추출할 수 있었던 질문, 적용하지 않을 시 Hullcination을 일으킴\n",
    "\n",
    "\n",
    "\n",
    "3. 한국의 LLM 리더보드에 ETRI가 참여하고 있어?\n",
    "4. 한국의 LLM 리더보드에 카카오가 참여하고 있어?\n",
    "5. Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?\n",
    "6. Open  Ko-LLM  Leaderboard에는 ETRI가 참여하고 있어?\n",
    "7. 카카오의 인공지능 윤리 원칙에 책임성이 포함되어 있어?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: Open  Ko-LLM  Leaderboard에는 어떤 기업들이 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 12}, page_content='20 특집원고  초거대 언어모델 연구 동향\\nS. Gehrmann et al., “Palm: Scaling language modeling \\nwith pathways,” arXiv preprint arXiv:2204.02311, 2022.\\n[31] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap- pelli, \\nR. Cojocaru, M. Debbah, E. Goffinet, D. Hes- low, J. \\nLaunay, Q. Malartic et al. , “Falcon-40b: an open large \\nlanguage model with state-of-the-art perfor- mance,” \\nTechnical report, Technology Innovation In- stitute, Tech. \\nRep., 2023.\\n[32] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. \\nCappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. \\nLaunay, “The refinedweb dataset for falcon llm: \\noutperforming curated corpora with web data, and web \\ndata only,” arXiv preprint arXiv:2306.01116, 2023.\\n[33] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. \\nLachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, \\nF. Azhar et al. , “Llama: Open and efficient foundation \\nlanguage models,” arXiv preprint arXiv:2302.13971, \\n2023.\\n[34] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma- hairi, \\nY . Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale \\net al. , “Llama 2: Open foundation and fine-tuned chat \\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\\n[35] Anthropic, “Model card and evaluations for claude \\nmodels,” 2023.\\n[36] A. Group, “Qwen technical report,” 2023.\\n[37] B. Kim, H. Kim, S.-W. Lee, G. Lee, D. Kwak, D. H. Jeon, \\nS. Park, S. Kim, S. Kim, D. Seo et al., “What changes can \\nlarge-scale language models bring? intensive study on \\nhyperclova: Billions-scale korean generative pretrained \\ntransformers,” arXiv preprint arXiv:2109.04650, 2021.\\n[38] H. Ko, K. Yang, M. Ryu, T. Choi, S. Yang, S. Park et al., \\n“A technical report for polyglot-ko: Open-source \\nlarge-scale korean language models,” arXiv preprint \\narXiv:2306.02254, 2023.\\n[39] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. \\nArora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, \\nE. Brunskill et al. , “On the opportuni- ties and risks of \\nfoundation models,” arXiv preprint arXiv:2108.07258, \\n2021.\\n[40] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and \\nD. Yang, “Is chatgpt a general-purpose natu- ral language \\nprocessing task solver?” arXiv preprint arXiv:2302. \\n06476, 2023.\\n[41] S. Longpre, G. Yauney, E. Reif, K. Lee, A. Roberts, B. \\nZoph, D. Zhou, J. Wei, K. Robinson, D. Mimno et al., “A \\npretrainer’s guide to training data: Measur- ing the effects \\nof data age, domain coverage, quality, & toxicity,” arXiv \\npreprint arXiv:2305.13169, 2023.\\n[42] A. Lee, B. Miranda, and S. Koyejo, “Beyond scale: the \\ndiversity coefficient as a data quality metric demon- \\nstrates llms are pre-trained on formally diverse data,” \\narXiv preprint arXiv:2306.13840, 2023.\\n[43] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. \\nMatena, Y . Zhou, W. Li, and P. J. Liu, “Exploring the limits \\nof transfer learning with a unified text-to- text \\ntransformer,” The Journal of Machine Learning Research, \\nV ol. 21, No. 1, pp. 5485–5551, 2020.\\n[44] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, \\nKulshreshtha,  H.-T.  Cheng,  A.  Jin,  T.  Bos, L. Baker, \\nY.  D u  et al. , “Lamda: Language models for dialog \\napplications,” arXiv preprint arXiv:2201.08239, 2022.\\n[45] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili’c, D. \\nHesslow, R. Castagn´e, A. S. Luccioni, F. Yvon, M. Gall´e \\net al., “Bloom: A 176b-parameter open- access \\nmultilingual language model,” arXiv preprint arXiv: \\n2211.05100, 2022.\\n[46] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. \\nHartshorn, E. Saravia, A. Poulton, V . Kerkez, and R. \\nStojnic, “Galactica: A large language model for sci- ence,” \\narXiv preprint arXiv:2211.09085, 2022.\\n[47] Y . Li, D. Choi, J. Chung, N. Kushman, J. Schrit- twieser, \\nR. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago \\net al. , “Competition-level code genera-tion with \\nalphacode,” Science, V ol. 378, No. 6624, pp. 1092–\\n1097, 2022.\\n[48] H. Fu, Yao; Peng and T. Khot, “How does gpt obtain its \\nability? tracing emergent abilities of language mod- els \\nto their sources,” Yao Fu’s Notion, Dec 2022.\\n[49] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . \\nMin, B. Zhang, J. Zhang, Z. Dong et al., “A survey of large \\nlanguage models,” arXiv preprint arXiv:2303.18223, \\n2023.\\n[50] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoff- mann, \\nF. Song, J. Aslanides, S. Henderson, R. Ring, S. Young \\net al., “Scaling language models: Meth-ods, analysis & \\ninsights from training gopher,” arXiv preprint arXiv: \\n2112.11446, 2021.\\n[51] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. \\nDrain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. \\nHenighan, T. Hume et al. , “Scaling laws and in- \\nterpretability of learning from repeated data,” arXiv \\npreprint arXiv:2205.10487, 2022.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='V2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 7}, page_content='2023. 11 정보과학회지 15\\n인간의 의사결정 과정과 비슷한 측면이 있다. 마지막\\n으로, ICL 은 전통적인 지도학습 방식에 비해 training- \\nfree learning 구조를 가지고 있으므로, 새로운 태스크 \\n적응에 필요한 계산 비용을 크게 줄일 수 있으며, 확\\n장 가능한 (scalable) 특성을 지닌다.\\n이렇듯 유용한 ICL은 어떤 원리로 작동하는 것일\\n까? 연구자들은 LLM의 대표적인 활용 패러다임으로 \\n자리 잡은 ICL의 작동 원리를 규명하기 위해 다양한 \\n측면에서 가설을 제안하였다. Chan et al. (2022) [83]\\n은 ICL 능력이 학습 데이터의 분포 특성으로부터 기\\n인한다고 주장하였다. Xie et al. (2022) [84] 은 ICL을 \\n암시적 베이지안 추론으로 설명하면서, 사전학습 분\\n포가 은닉 마코프 모델의 혼합 (mixture of hidden \\nMarkov models) 형태를 따를 때 ICL 능력이 나타난다\\n는 것을 증명하기 위해 합성 데이터 세트를 구성하였\\n다. Garg et al. (2022) [85] 은 알맞은 시연 예제가 주\\n어질 경우, Transformer가 본 적 없는 선형 함수를 학\\n습할 수 있는 효과적인 학습 알고리즘을 인코딩할 수 \\n있음을 증명하였다. 그들은 또한 ICL에 인코딩된 학\\n습 알고리즘이 최소 제곱 추정기의 오류와 비슷한 수\\n준의 오류를 달성할 수 있음을 발견하였다. 또다른 연\\n구들은 ICL과 경사 하강법 (gradient descent) 사이의 \\n관계를 발견하려고 시도했으며, 특히 최근의 연구 [86]\\n는 Transformer 기반의 in-context learner가 표준 미세\\n조정 알고리즘을 암시적으로 구현할 수 있음을 발견\\n했다. Dai et al. (2023) [87] 은 Transformer attention과 \\n경사 하강법 사이의 dual form을 밝혀냈고, 이에 따라 \\nICL을 암시적 미세조정 (implicit fine-tuning)으로 이\\n해할 것을 제안하였다. 또한, GPT 기반 ICL과 실제 \\n태스크에 대한 명시적인 미세조정을 비교한 결과, 여\\n러 관점에서 ICL이 미세 조정과 유사하게 동작함을 \\n발견하였다. Olsson et al. (2022) [88] 은 Transformer \\n내에서 이전 패턴을 복사하여 다음 토큰을 완성하는 \\n유도 헤드 (induction head)들이 존재함을 밝혔고, 이\\n러한 기능이 ICL을 구현할 수 있음을 제시했다.\\nICL 관점에서, 추론 능력을 보다 강화하기 위한 연\\n구로 CoT [24] 가 소개되었다. CoT 는 입력과 출력 사\\n이의 중간 추론 단계 (intermediate reasoning steps) 을 \\n시연 형태로 추가함으로써 이루어진다. CoT 프롬프팅\\n은 입력-출력 매핑을 여러 중간 단계로 분해함으로써, \\n산술 추론 [89], 상식 추론 [90] 및 기호 추론 [24] 등의 \\n복잡한 추론 태스크에서 LLM의 성능을 향상 시킬 수 \\n있다. 최근에는 다양한 추론 경로 (multiple reasoning \\npaths)를 생성하고 도출된 답변들간의 합의점을 찾는 \\n형태로 기존의 CoT를 강화하는 연구들이 제안되기도 \\n했다 [57, 91]. 이 외에도 재귀적인 프롬프팅 [92]을 \\n통해서 compositional generalization [93] 능력이 요구\\n되는 복잡한 태스크를 해결한 사례도 존재한다.\\n4.3.2 Augmented LLMs\\nLLM은 missing token prediction 목적 함수를 최적\\n화하는 형태로 학습되기 때문에, 사실이 아니지만 구\\n조적으로 그럴듯하게 보이는 컨텐츠를 생성하는 환각 \\n등의 내재적인 한계를 지니고 있다. 또한, 자연어 코\\n퍼스를 활용하여 학습되기 때문에, 주요 NLP 태스크\\n가 아닌 산술 추론 (e.g., 1234+4321=?) 등에 약점을 \\n보이기도 한다. 모델 크기 관점에서는, LLM 의 창발 \\n능력을 발휘하기 위해서는 대용량의 지식 등을 기억\\n해야 하고 결과적으로 많은 수의 파라미터를 요구하\\n게 된다. 기존 연구 [23] 에 따르면, 파라미터 수가 적은 \\n언어 모델은 LLM에서 나타나는 in-context learning, \\ninstruction following, step-by-step reasoning 과 같은 창\\n발 능력이 발현되지 않는다고 한다. 즉, 좋은 성능의 \\nLLM은 필연적으로 많은 수의 파라미터를 요구하게 \\n되는 것이다. 이러한 내재적인 한계를 해결하고 적은 \\n수의 파라미터로도 목적을 달성할 수 있도록, LLM 을 \\n추론 (reasoning) 및 도구 사용 (use tools) 관점에서 강\\n화한 모델을 Augmented LLMs 이라 부른다 [94]. 이 \\n중에서 추론에 관한 내용은 프롬프팅을 통해서 고도\\n화된 추론 능력을 LLM에게 부여하는 것으로, 앞서 \\n4.3.1에서 논의한 ICL 및 CoT와 연관이 깊다. 따라서 \\n해당 섹션에서는 도구 사용에 대해서 주로 논의할 것\\n이다. 이외의 Augmented LLMs에 대한 심도 있는 논\\n의는 다음 논문을 참조하길 바란다 [94].\\nRetrieval Augmented Generation LLM의 파라미터는 \\n일종의 내부 메모리 모듈의 역할을 수행하는데, 특정\\n한 태스크의 해결을 위해서는 context 내에 명시되지 \\n않은 정보를 내재적으로 갖춰야 하는 경우가 많고, 그 \\n결과로 파라미터의 수가 증가하게 된다. 그러나, 만약 \\nLLM이 외부의 지식 또는 정보에 효과적으로 접근하\\n며 그 정보를 활용할 수 있다면, 모든 지식을 내부 메\\n모리에 저장하는 대신, 필요한 정보를 외부에서 추출\\n하여 사용하는 방식으로 파라미터 수를 줄일 수 있을 \\n것이다. 이러한 관점에서 볼 때, 검색 엔진과 같은 도\\n구를 외부 메모리 모듈로 활용하는 LLM은 특정 쿼리\\n와 관련된 정보를 빠르게 색인하고 추출하여 사실 기\\n반의 답변 제공 및 최신 정보를 반영이 가능하며, 불\\n필요한 지식의 저장을 최소화함으로써, 모델의 파라\\n미터 수를 획기적으로 줄일 수 있다. 이러한 방법론을'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='화는 언어 모델의 복잡성과 다양성이 증가함에 따라 \\nNLP분야에 있어서 신중하게 고려되어야 할 중요한 \\n주제이다.\\n5.1 OpenLLM Leaderboard'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역')], 'question': 'Open  Ko-LLM  Leaderboard에는 어떤 기업들이 참여하고 있어?'}\n",
      "RAG response : Open Ko-LLM Leaderboard에는 Polyglot-Ko, KULLM, KoAlpaca, 42MARU, ETRI, Maum.AI 등 다양한 기업들이 참여하고 있습니다.\n",
      "Debug Output: Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 12}, page_content='20 특집원고  초거대 언어모델 연구 동향\\nS. Gehrmann et al., “Palm: Scaling language modeling \\nwith pathways,” arXiv preprint arXiv:2204.02311, 2022.\\n[31] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap- pelli, \\nR. Cojocaru, M. Debbah, E. Goffinet, D. Hes- low, J. \\nLaunay, Q. Malartic et al. , “Falcon-40b: an open large \\nlanguage model with state-of-the-art perfor- mance,” \\nTechnical report, Technology Innovation In- stitute, Tech. \\nRep., 2023.\\n[32] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. \\nCappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. \\nLaunay, “The refinedweb dataset for falcon llm: \\noutperforming curated corpora with web data, and web \\ndata only,” arXiv preprint arXiv:2306.01116, 2023.\\n[33] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. \\nLachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, \\nF. Azhar et al. , “Llama: Open and efficient foundation \\nlanguage models,” arXiv preprint arXiv:2302.13971, \\n2023.\\n[34] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma- hairi, \\nY . Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale \\net al. , “Llama 2: Open foundation and fine-tuned chat \\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\\n[35] Anthropic, “Model card and evaluations for claude \\nmodels,” 2023.\\n[36] A. Group, “Qwen technical report,” 2023.\\n[37] B. Kim, H. Kim, S.-W. Lee, G. Lee, D. Kwak, D. H. Jeon, \\nS. Park, S. Kim, S. Kim, D. Seo et al., “What changes can \\nlarge-scale language models bring? intensive study on \\nhyperclova: Billions-scale korean generative pretrained \\ntransformers,” arXiv preprint arXiv:2109.04650, 2021.\\n[38] H. Ko, K. Yang, M. Ryu, T. Choi, S. Yang, S. Park et al., \\n“A technical report for polyglot-ko: Open-source \\nlarge-scale korean language models,” arXiv preprint \\narXiv:2306.02254, 2023.\\n[39] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. \\nArora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, \\nE. Brunskill et al. , “On the opportuni- ties and risks of \\nfoundation models,” arXiv preprint arXiv:2108.07258, \\n2021.\\n[40] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and \\nD. Yang, “Is chatgpt a general-purpose natu- ral language \\nprocessing task solver?” arXiv preprint arXiv:2302. \\n06476, 2023.\\n[41] S. Longpre, G. Yauney, E. Reif, K. Lee, A. Roberts, B. \\nZoph, D. Zhou, J. Wei, K. Robinson, D. Mimno et al., “A \\npretrainer’s guide to training data: Measur- ing the effects \\nof data age, domain coverage, quality, & toxicity,” arXiv \\npreprint arXiv:2305.13169, 2023.\\n[42] A. Lee, B. Miranda, and S. Koyejo, “Beyond scale: the \\ndiversity coefficient as a data quality metric demon- \\nstrates llms are pre-trained on formally diverse data,” \\narXiv preprint arXiv:2306.13840, 2023.\\n[43] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. \\nMatena, Y . Zhou, W. Li, and P. J. Liu, “Exploring the limits \\nof transfer learning with a unified text-to- text \\ntransformer,” The Journal of Machine Learning Research, \\nV ol. 21, No. 1, pp. 5485–5551, 2020.\\n[44] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, \\nKulshreshtha,  H.-T.  Cheng,  A.  Jin,  T.  Bos, L. Baker, \\nY.  D u  et al. , “Lamda: Language models for dialog \\napplications,” arXiv preprint arXiv:2201.08239, 2022.\\n[45] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili’c, D. \\nHesslow, R. Castagn´e, A. S. Luccioni, F. Yvon, M. Gall´e \\net al., “Bloom: A 176b-parameter open- access \\nmultilingual language model,” arXiv preprint arXiv: \\n2211.05100, 2022.\\n[46] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. \\nHartshorn, E. Saravia, A. Poulton, V . Kerkez, and R. \\nStojnic, “Galactica: A large language model for sci- ence,” \\narXiv preprint arXiv:2211.09085, 2022.\\n[47] Y . Li, D. Choi, J. Chung, N. Kushman, J. Schrit- twieser, \\nR. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago \\net al. , “Competition-level code genera-tion with \\nalphacode,” Science, V ol. 378, No. 6624, pp. 1092–\\n1097, 2022.\\n[48] H. Fu, Yao; Peng and T. Khot, “How does gpt obtain its \\nability? tracing emergent abilities of language mod- els \\nto their sources,” Yao Fu’s Notion, Dec 2022.\\n[49] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . \\nMin, B. Zhang, J. Zhang, Z. Dong et al., “A survey of large \\nlanguage models,” arXiv preprint arXiv:2303.18223, \\n2023.\\n[50] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoff- mann, \\nF. Song, J. Aslanides, S. Henderson, R. Ring, S. Young \\net al., “Scaling language models: Meth-ods, analysis & \\ninsights from training gopher,” arXiv preprint arXiv: \\n2112.11446, 2021.\\n[51] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. \\nDrain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. \\nHenighan, T. Hume et al. , “Scaling laws and in- \\nterpretability of learning from repeated data,” arXiv \\npreprint arXiv:2205.10487, 2022.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='V2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='화는 언어 모델의 복잡성과 다양성이 증가함에 따라 \\nNLP분야에 있어서 신중하게 고려되어야 할 중요한 \\n주제이다.\\n5.1 OpenLLM Leaderboard')], 'question': 'Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?'}\n",
      "RAG response : 제공된 정보에는 Open Ko-LLM Leaderboard에 참여하는 기업 목록이 포함되어 있지만, 카카오에 대한 언급은 없습니다. 따라서 카카오는 참여하고 있지 않은 것으로 보입니다.\n",
      "Debug Output: 한국의 LLM 리더보드에 ETRI가 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 4}, page_content='12 특집원고  초거대 언어모델 연구 동향\\n요한 역할을 한다는 연구 결과들 [41, 42] 에 의해 뒷 \\n받침된다. 예를 들어, 2019 년에 발표된 T5 [43] 는 웹\\n페이지만을 사전학습에 활용하였으나, 이후에 공개된 \\nGPT-3 [22]는 웹페이지를 비롯한, 책 및 뉴스 데이터\\n를 함께 활용하였다. 더불어, Llama-1 65B 모델 [33]\\n에서는 사전학습 데이터 중 웹페이지가 차지하는 비\\n중이 87%에 달하지만, 남은 13%의 데이터는 대화 데\\n이터, 책 및 뉴스, 학술 데이터, 코드 데이터가 골고루 \\n차지하고 있다.\\n이러한 사전학습 데이터의 다양성을 강조하는 추세\\n에도 불구하고, LLM 의 성능 향상을 위한 다양한 코\\n퍼스의 최적 혼합 비율과 필요한 데이터 양에 관한 \\n연구는 아직 초기 단계에 머물러 있다. 이와 관련하여 \\n주목할 만한 연구로는 [41]이 있다. 해당 연구에서는 \\n사전 학습 코퍼스를 시간대, 필터링 기법, 도메인 혼\\n합 비율 조합에 따라 28개로 구분하고, 이를 대상으로 \\n1.5B 파라미터를 갖는 Transformer decoder-only 모델\\n을 학습 하였다. 이들은 사전학습 데이터와 평가 데이\\n터 사이의 시간적 차이 (temporal shift) 때문에 발생하\\n는 성능 저하는 미세조정 만으로는 극복하기 어려움\\n을 발견했으며, 데이터 품질 필터링 및 독성 필터링의 \\n중요성을 정량적으로 증명하였다. 또한, 사전 학습시 \\n이질적인 도메인 코퍼스를 활용하는 것이 전체적으로 \\n도움이 된다는 것을 재확인했다. 또 다른 사례로 \\nGPT-4 [29] 에서는 사전학습에 많은 자원과 시간이 \\n소요되는 문제를 완화하기 위해 predictable scaling 기\\n법을 소개했다. 이를 활용하면 LLM 사전학습 중에 \\n적은 양의 컴퓨팅으로 최종 성능을 정확히 예측할 수 \\n있는 것으로 알려져 있다.\\n코퍼스의 다양성을 강조하는 방향과는 별개로, 하\\n위 태스크에 특화된 LLM을 위한 사전학습에서는 관\\n련된 코퍼스의 비중을 증가시키는 전략도 활용되고 \\n있다. Google 에서 발표한 대화 어플리케이션을 위한 \\n언어 모델인 LaMDA [44]는 전체 사전학습 데이터 비\\n중의 약 절반 (50%) 가량을 대화 데이터로 할당하였\\n으며, 교육 및 콘텐츠 추천 영역에서 해당 모델의 효\\n용성을 입증하였다. 다국어 특화 LLM인 BLOOM \\n[45] 및 PaLM [30] 은 타겟 언어인 영어 이외의 다국\\n어 텍스트를 사전학습에 함께 활용함으로써, 다국어 \\n기반의 번역, 요약, QA 태스크에서 뛰어난 성능을 달\\n성하였다. 과학 도메인 특화 LLM 인 Galactica [46]는 \\n사전학습 데이터의 약 86%를 과학 데이터로 사용하\\n였고, 코드 생성에 특화된 LLM인 AlphaCode [47]는 \\n사전학습 데이터를 전부 코드 데이터로 사용하기도 \\n했다.17)\\n4.1.2 전처리\\n사전학습 시 수집한 데이터를 그대로 사용하는 것\\n은 데이터의 크기와 노이즈, 중복, 독성 데이터 등의 \\n존재로 인해 여러 문제를 야기할 수 있다. 따라서 사\\n전학습 용도로 데이터를 전처리하는 것이 필수적이\\n다. 이러한 전처리 과정은 크게 품질 필터링, 중복 제\\n거, 개인정보 제거, 토큰화의 순서로 이루어진다 [49]. \\n품질 필터링 (quality filtering) 단계에서는 수집된 데\\n이터로부터 저품질의 데이터를 걸러낸다. 해당 단계\\n에서는 고품질의 텍스트 데이터로부터 학습된 분류기\\n를 통해 저품질 데이터를 걸러내거나 [22, 30], 정교하\\n게 디자인된 규칙에 기반한 휴리스틱스 [45, 50]을 사\\n용하는 것이 일반적이다. 사전학습 데이터에 중복되\\n는 데이터가 존재할 경우 LLM의 성능을 저해하는 것\\n으로 알려져 있다 [51]. 이를 방지하기 위해서, 중복 \\n제거 (de-duplication) 단계에서는 반복되는 단어를 갖\\n는 저품질 문장이나, 단어 및 N-그램 기반 겹침 비율\\n에 기반하여 유사한 내용을 갖는 중복 문서들을 필터\\n링한다 [33, 50, 45, 52]. 또한 information leakage를 방\\n지하기 위해, 학습 데이터와 평가 데이터 사이의 중복 \\n데이터도 제거되어야 한다 [30]. 다음으로 개인정보 \\n제거 (privacy reduction) 단계가 수행된다. 대부분의 \\nLLM 사전학습 데이터는 웹 텍스트를 포함하므로 이\\n메일 주소나 전화번호 같은 민감 정보를 포함할 수 있\\n다. 실제로 몇몇 연구들 [53, 54]에서는 정교한 프롬프팅\\n을 통해서 LLM으로부터 개인 식별 정보 (Personally \\nIdentifiable Information, PII) 또는 Github Copilot \\nsecret API keys 와 같은 민감 정보를 추출할 수 있음\\n을 보인 바 있다. 이러한 이유로, LLM 을 윤리적으로 \\n사용하고 개인정보 침해 위험을 제거하기 위해 사전\\n학습 데이터에서 민감 정보를 제거하는 것이 필수적\\n이다. 마지막 전처리 단계로, 원본 텍스트를 토큰이라 \\n불리는 작은 단위의 시퀀스로 분리하는 토큰화 \\n(tokenization) 작업이 수행된다. 이 작업은 LLM이 등\\n장하기 이전의 전통적인 NLP 태스크에서도 중요한 \\n연구 분야였으며, LLM 이 도래한 이후에도 컴퓨팅 비\\n용, 언어 의존성, 정보 손실 등을 고려하여 토큰화를 \\n개선하기 위한 연구가 계속되고 있다. LLM 과 관련된 \\n토크나이저의 중요성에 관한 논의는 [55]를 참고하길 \\n바란다.\\n17) 코드 데이터의 중요성과 관련하여, 최근 연구 [48]는 CoT와 같 \\n은 LLM의 복잡한 추론 능력의 출현이, 텍스트와 차별화되는 코\\n드 데이터의 독특한 특성에 기인하는 것으로 추정하고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 3}, page_content='2023. 11 정보과학회지 11\\n국어를 비효율적으로 토큰화하고, 학습한 한국어 토\\n큰 수가 매우 부족하다는 한계를 가진다 . 실제로, \\nGPT-3 [22] 의 경우 학습된 한국어 토큰의 비율은 \\n0.01697% 밖에 되지 않으며, 오픈소스 LLM인 Llama \\n2 [34] 의 경우도 0.06% 밖에 되지 않는다. 이에 따라, \\n한국어 사용자를 위한 한국어 LLM의 필요성이 대두\\n되고 있다.\\n이러한 필요성에 따라, 최근 많은 국내 기업에서 \\n한국어 LLM을 자체적으로 학습하기 시작했다. Naver \\nClova4)의 HyperClova [37]를 시작으로, Kakao Brain 5)\\n의 KoGPT, KT Enterprise6)의 믿음, LG AI Research 7)\\n의 Exaone, NCSOFT 8)의 V ARCO, SALTLUX9)의 \\nLuxia, 코난테크놀로지10)의 코난 LLM 등 다양한 한\\n국어 LLM이 공개되고 있다. 이들의 공통점은 자체적\\n으로 보유한 한국어 데이터와 공개되어 있는 한국어 \\n데이터, 크롤링 데이터를 적극적으로 활용하여, 한국\\n어 토큰 비율을 높여서 학습하고 있다는 것이다. 더불어 \\n업스테이지의 경우 Llama2를 파인튜닝하여Solar-0-70b  \\n모델을 개발하였고, 글로벌 LLM 플랫폼 중 하나인 \\nPoe.com에 서비스하고 있다11). 해당 모델은 한국어와 \\n영어 모두 지원하고 있다.\\n한편, 오픈소스 한국어 LLM도 존재한다. 가장 대'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 10}, page_content='다. 본 논문이 LLM에 대한 깊이 있는 이해를 제공하\\n고, 이 분야의 연구자 및 전문가들에게 유익한 인사이\\n트와 지침을 제공할 수 있기를 희망한다.\\n참고문헌'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='능을 체계적으로 평가하고 있다. LLM 이 여전히 정복\\n하지 못한 추론능력, 환각현상, 상식능력 등을 종합적\\n으로 검증할 수 있는 리더보드이다. 이러한 평가 방식'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='LLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한')], 'question': '한국의 LLM 리더보드에 ETRI가 참여하고 있어?'}\n",
      "RAG response : 네, 한국의 LLM 리더보드에 ETRI가 참여하고 있습니다.\n",
      "Debug Output: 한국의 LLM 리더보드에 카카오가 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 4}, page_content='12 특집원고  초거대 언어모델 연구 동향\\n요한 역할을 한다는 연구 결과들 [41, 42] 에 의해 뒷 \\n받침된다. 예를 들어, 2019 년에 발표된 T5 [43] 는 웹\\n페이지만을 사전학습에 활용하였으나, 이후에 공개된 \\nGPT-3 [22]는 웹페이지를 비롯한, 책 및 뉴스 데이터\\n를 함께 활용하였다. 더불어, Llama-1 65B 모델 [33]\\n에서는 사전학습 데이터 중 웹페이지가 차지하는 비\\n중이 87%에 달하지만, 남은 13%의 데이터는 대화 데\\n이터, 책 및 뉴스, 학술 데이터, 코드 데이터가 골고루 \\n차지하고 있다.\\n이러한 사전학습 데이터의 다양성을 강조하는 추세\\n에도 불구하고, LLM 의 성능 향상을 위한 다양한 코\\n퍼스의 최적 혼합 비율과 필요한 데이터 양에 관한 \\n연구는 아직 초기 단계에 머물러 있다. 이와 관련하여 \\n주목할 만한 연구로는 [41]이 있다. 해당 연구에서는 \\n사전 학습 코퍼스를 시간대, 필터링 기법, 도메인 혼\\n합 비율 조합에 따라 28개로 구분하고, 이를 대상으로 \\n1.5B 파라미터를 갖는 Transformer decoder-only 모델\\n을 학습 하였다. 이들은 사전학습 데이터와 평가 데이\\n터 사이의 시간적 차이 (temporal shift) 때문에 발생하\\n는 성능 저하는 미세조정 만으로는 극복하기 어려움\\n을 발견했으며, 데이터 품질 필터링 및 독성 필터링의 \\n중요성을 정량적으로 증명하였다. 또한, 사전 학습시 \\n이질적인 도메인 코퍼스를 활용하는 것이 전체적으로 \\n도움이 된다는 것을 재확인했다. 또 다른 사례로 \\nGPT-4 [29] 에서는 사전학습에 많은 자원과 시간이 \\n소요되는 문제를 완화하기 위해 predictable scaling 기\\n법을 소개했다. 이를 활용하면 LLM 사전학습 중에 \\n적은 양의 컴퓨팅으로 최종 성능을 정확히 예측할 수 \\n있는 것으로 알려져 있다.\\n코퍼스의 다양성을 강조하는 방향과는 별개로, 하\\n위 태스크에 특화된 LLM을 위한 사전학습에서는 관\\n련된 코퍼스의 비중을 증가시키는 전략도 활용되고 \\n있다. Google 에서 발표한 대화 어플리케이션을 위한 \\n언어 모델인 LaMDA [44]는 전체 사전학습 데이터 비\\n중의 약 절반 (50%) 가량을 대화 데이터로 할당하였\\n으며, 교육 및 콘텐츠 추천 영역에서 해당 모델의 효\\n용성을 입증하였다. 다국어 특화 LLM인 BLOOM \\n[45] 및 PaLM [30] 은 타겟 언어인 영어 이외의 다국\\n어 텍스트를 사전학습에 함께 활용함으로써, 다국어 \\n기반의 번역, 요약, QA 태스크에서 뛰어난 성능을 달\\n성하였다. 과학 도메인 특화 LLM 인 Galactica [46]는 \\n사전학습 데이터의 약 86%를 과학 데이터로 사용하\\n였고, 코드 생성에 특화된 LLM인 AlphaCode [47]는 \\n사전학습 데이터를 전부 코드 데이터로 사용하기도 \\n했다.17)\\n4.1.2 전처리\\n사전학습 시 수집한 데이터를 그대로 사용하는 것\\n은 데이터의 크기와 노이즈, 중복, 독성 데이터 등의 \\n존재로 인해 여러 문제를 야기할 수 있다. 따라서 사\\n전학습 용도로 데이터를 전처리하는 것이 필수적이\\n다. 이러한 전처리 과정은 크게 품질 필터링, 중복 제\\n거, 개인정보 제거, 토큰화의 순서로 이루어진다 [49]. \\n품질 필터링 (quality filtering) 단계에서는 수집된 데\\n이터로부터 저품질의 데이터를 걸러낸다. 해당 단계\\n에서는 고품질의 텍스트 데이터로부터 학습된 분류기\\n를 통해 저품질 데이터를 걸러내거나 [22, 30], 정교하\\n게 디자인된 규칙에 기반한 휴리스틱스 [45, 50]을 사\\n용하는 것이 일반적이다. 사전학습 데이터에 중복되\\n는 데이터가 존재할 경우 LLM의 성능을 저해하는 것\\n으로 알려져 있다 [51]. 이를 방지하기 위해서, 중복 \\n제거 (de-duplication) 단계에서는 반복되는 단어를 갖\\n는 저품질 문장이나, 단어 및 N-그램 기반 겹침 비율\\n에 기반하여 유사한 내용을 갖는 중복 문서들을 필터\\n링한다 [33, 50, 45, 52]. 또한 information leakage를 방\\n지하기 위해, 학습 데이터와 평가 데이터 사이의 중복 \\n데이터도 제거되어야 한다 [30]. 다음으로 개인정보 \\n제거 (privacy reduction) 단계가 수행된다. 대부분의 \\nLLM 사전학습 데이터는 웹 텍스트를 포함하므로 이\\n메일 주소나 전화번호 같은 민감 정보를 포함할 수 있\\n다. 실제로 몇몇 연구들 [53, 54]에서는 정교한 프롬프팅\\n을 통해서 LLM으로부터 개인 식별 정보 (Personally \\nIdentifiable Information, PII) 또는 Github Copilot \\nsecret API keys 와 같은 민감 정보를 추출할 수 있음\\n을 보인 바 있다. 이러한 이유로, LLM 을 윤리적으로 \\n사용하고 개인정보 침해 위험을 제거하기 위해 사전\\n학습 데이터에서 민감 정보를 제거하는 것이 필수적\\n이다. 마지막 전처리 단계로, 원본 텍스트를 토큰이라 \\n불리는 작은 단위의 시퀀스로 분리하는 토큰화 \\n(tokenization) 작업이 수행된다. 이 작업은 LLM이 등\\n장하기 이전의 전통적인 NLP 태스크에서도 중요한 \\n연구 분야였으며, LLM 이 도래한 이후에도 컴퓨팅 비\\n용, 언어 의존성, 정보 손실 등을 고려하여 토큰화를 \\n개선하기 위한 연구가 계속되고 있다. LLM 과 관련된 \\n토크나이저의 중요성에 관한 논의는 [55]를 참고하길 \\n바란다.\\n17) 코드 데이터의 중요성과 관련하여, 최근 연구 [48]는 CoT와 같 \\n은 LLM의 복잡한 추론 능력의 출현이, 텍스트와 차별화되는 코\\n드 데이터의 독특한 특성에 기인하는 것으로 추정하고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 3}, page_content='2023. 11 정보과학회지 11\\n국어를 비효율적으로 토큰화하고, 학습한 한국어 토\\n큰 수가 매우 부족하다는 한계를 가진다 . 실제로, \\nGPT-3 [22] 의 경우 학습된 한국어 토큰의 비율은 \\n0.01697% 밖에 되지 않으며, 오픈소스 LLM인 Llama \\n2 [34] 의 경우도 0.06% 밖에 되지 않는다. 이에 따라, \\n한국어 사용자를 위한 한국어 LLM의 필요성이 대두\\n되고 있다.\\n이러한 필요성에 따라, 최근 많은 국내 기업에서 \\n한국어 LLM을 자체적으로 학습하기 시작했다. Naver \\nClova4)의 HyperClova [37]를 시작으로, Kakao Brain 5)\\n의 KoGPT, KT Enterprise6)의 믿음, LG AI Research 7)\\n의 Exaone, NCSOFT 8)의 V ARCO, SALTLUX9)의 \\nLuxia, 코난테크놀로지10)의 코난 LLM 등 다양한 한\\n국어 LLM이 공개되고 있다. 이들의 공통점은 자체적\\n으로 보유한 한국어 데이터와 공개되어 있는 한국어 \\n데이터, 크롤링 데이터를 적극적으로 활용하여, 한국\\n어 토큰 비율을 높여서 학습하고 있다는 것이다. 더불어 \\n업스테이지의 경우 Llama2를 파인튜닝하여Solar-0-70b  \\n모델을 개발하였고, 글로벌 LLM 플랫폼 중 하나인 \\nPoe.com에 서비스하고 있다11). 해당 모델은 한국어와 \\n영어 모두 지원하고 있다.\\n한편, 오픈소스 한국어 LLM도 존재한다. 가장 대'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 3}, page_content='되고 있다.\\n이러한 필요성에 따라, 최근 많은 국내 기업에서 \\n한국어 LLM을 자체적으로 학습하기 시작했다. Naver'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='V2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='능을 체계적으로 평가하고 있다. LLM 이 여전히 정복\\n하지 못한 추론능력, 환각현상, 상식능력 등을 종합적\\n으로 검증할 수 있는 리더보드이다. 이러한 평가 방식')], 'question': '한국의 LLM 리더보드에 카카오가 참여하고 있어?'}\n",
      "RAG response : 네, 카카오는 한국어 LLM 리더보드에 참여하고 있습니다.\n",
      "Debug Output: Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 12}, page_content='20 특집원고  초거대 언어모델 연구 동향\\nS. Gehrmann et al., “Palm: Scaling language modeling \\nwith pathways,” arXiv preprint arXiv:2204.02311, 2022.\\n[31] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap- pelli, \\nR. Cojocaru, M. Debbah, E. Goffinet, D. Hes- low, J. \\nLaunay, Q. Malartic et al. , “Falcon-40b: an open large \\nlanguage model with state-of-the-art perfor- mance,” \\nTechnical report, Technology Innovation In- stitute, Tech. \\nRep., 2023.\\n[32] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. \\nCappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. \\nLaunay, “The refinedweb dataset for falcon llm: \\noutperforming curated corpora with web data, and web \\ndata only,” arXiv preprint arXiv:2306.01116, 2023.\\n[33] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. \\nLachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, \\nF. Azhar et al. , “Llama: Open and efficient foundation \\nlanguage models,” arXiv preprint arXiv:2302.13971, \\n2023.\\n[34] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma- hairi, \\nY . Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale \\net al. , “Llama 2: Open foundation and fine-tuned chat \\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\\n[35] Anthropic, “Model card and evaluations for claude \\nmodels,” 2023.\\n[36] A. Group, “Qwen technical report,” 2023.\\n[37] B. Kim, H. Kim, S.-W. Lee, G. Lee, D. Kwak, D. H. Jeon, \\nS. Park, S. Kim, S. Kim, D. Seo et al., “What changes can \\nlarge-scale language models bring? intensive study on \\nhyperclova: Billions-scale korean generative pretrained \\ntransformers,” arXiv preprint arXiv:2109.04650, 2021.\\n[38] H. Ko, K. Yang, M. Ryu, T. Choi, S. Yang, S. Park et al., \\n“A technical report for polyglot-ko: Open-source \\nlarge-scale korean language models,” arXiv preprint \\narXiv:2306.02254, 2023.\\n[39] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. \\nArora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, \\nE. Brunskill et al. , “On the opportuni- ties and risks of \\nfoundation models,” arXiv preprint arXiv:2108.07258, \\n2021.\\n[40] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and \\nD. Yang, “Is chatgpt a general-purpose natu- ral language \\nprocessing task solver?” arXiv preprint arXiv:2302. \\n06476, 2023.\\n[41] S. Longpre, G. Yauney, E. Reif, K. Lee, A. Roberts, B. \\nZoph, D. Zhou, J. Wei, K. Robinson, D. Mimno et al., “A \\npretrainer’s guide to training data: Measur- ing the effects \\nof data age, domain coverage, quality, & toxicity,” arXiv \\npreprint arXiv:2305.13169, 2023.\\n[42] A. Lee, B. Miranda, and S. Koyejo, “Beyond scale: the \\ndiversity coefficient as a data quality metric demon- \\nstrates llms are pre-trained on formally diverse data,” \\narXiv preprint arXiv:2306.13840, 2023.\\n[43] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. \\nMatena, Y . Zhou, W. Li, and P. J. Liu, “Exploring the limits \\nof transfer learning with a unified text-to- text \\ntransformer,” The Journal of Machine Learning Research, \\nV ol. 21, No. 1, pp. 5485–5551, 2020.\\n[44] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, \\nKulshreshtha,  H.-T.  Cheng,  A.  Jin,  T.  Bos, L. Baker, \\nY.  D u  et al. , “Lamda: Language models for dialog \\napplications,” arXiv preprint arXiv:2201.08239, 2022.\\n[45] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili’c, D. \\nHesslow, R. Castagn´e, A. S. Luccioni, F. Yvon, M. Gall´e \\net al., “Bloom: A 176b-parameter open- access \\nmultilingual language model,” arXiv preprint arXiv: \\n2211.05100, 2022.\\n[46] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. \\nHartshorn, E. Saravia, A. Poulton, V . Kerkez, and R. \\nStojnic, “Galactica: A large language model for sci- ence,” \\narXiv preprint arXiv:2211.09085, 2022.\\n[47] Y . Li, D. Choi, J. Chung, N. Kushman, J. Schrit- twieser, \\nR. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago \\net al. , “Competition-level code genera-tion with \\nalphacode,” Science, V ol. 378, No. 6624, pp. 1092–\\n1097, 2022.\\n[48] H. Fu, Yao; Peng and T. Khot, “How does gpt obtain its \\nability? tracing emergent abilities of language mod- els \\nto their sources,” Yao Fu’s Notion, Dec 2022.\\n[49] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . \\nMin, B. Zhang, J. Zhang, Z. Dong et al., “A survey of large \\nlanguage models,” arXiv preprint arXiv:2303.18223, \\n2023.\\n[50] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoff- mann, \\nF. Song, J. Aslanides, S. Henderson, R. Ring, S. Young \\net al., “Scaling language models: Meth-ods, analysis & \\ninsights from training gopher,” arXiv preprint arXiv: \\n2112.11446, 2021.\\n[51] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. \\nDrain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. \\nHenighan, T. Hume et al. , “Scaling laws and in- \\nterpretability of learning from repeated data,” arXiv \\npreprint arXiv:2205.10487, 2022.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='V2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 8}, page_content='화는 언어 모델의 복잡성과 다양성이 증가함에 따라 \\nNLP분야에 있어서 신중하게 고려되어야 할 중요한 \\n주제이다.\\n5.1 OpenLLM Leaderboard')], 'question': 'Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?'}\n",
      "RAG response : 제공된 정보에는 Open Ko-LLM Leaderboard에 참여하는 기업 목록이 포함되어 있지만, 카카오는 언급되지 않았습니다. 따라서 카카오가 참여하고 있는지 여부는 확인할 수 없습니다.\n",
      "Debug Output: Open  Ko-LLM  Leaderboard에는 ETRI가 참여하고 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 12}, page_content='20 특집원고  초거대 언어모델 연구 동향\\nS. Gehrmann et al., “Palm: Scaling language modeling \\nwith pathways,” arXiv preprint arXiv:2204.02311, 2022.\\n[31] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap- pelli, \\nR. Cojocaru, M. Debbah, E. Goffinet, D. Hes- low, J. \\nLaunay, Q. Malartic et al. , “Falcon-40b: an open large \\nlanguage model with state-of-the-art perfor- mance,” \\nTechnical report, Technology Innovation In- stitute, Tech. \\nRep., 2023.\\n[32] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. \\nCappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. \\nLaunay, “The refinedweb dataset for falcon llm: \\noutperforming curated corpora with web data, and web \\ndata only,” arXiv preprint arXiv:2306.01116, 2023.\\n[33] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. \\nLachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, \\nF. Azhar et al. , “Llama: Open and efficient foundation \\nlanguage models,” arXiv preprint arXiv:2302.13971, \\n2023.\\n[34] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma- hairi, \\nY . Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale \\net al. , “Llama 2: Open foundation and fine-tuned chat \\nmodels,” arXiv preprint arXiv:2307.09288, 2023.\\n[35] Anthropic, “Model card and evaluations for claude \\nmodels,” 2023.\\n[36] A. Group, “Qwen technical report,” 2023.\\n[37] B. Kim, H. Kim, S.-W. Lee, G. Lee, D. Kwak, D. H. Jeon, \\nS. Park, S. Kim, S. Kim, D. Seo et al., “What changes can \\nlarge-scale language models bring? intensive study on \\nhyperclova: Billions-scale korean generative pretrained \\ntransformers,” arXiv preprint arXiv:2109.04650, 2021.\\n[38] H. Ko, K. Yang, M. Ryu, T. Choi, S. Yang, S. Park et al., \\n“A technical report for polyglot-ko: Open-source \\nlarge-scale korean language models,” arXiv preprint \\narXiv:2306.02254, 2023.\\n[39] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. \\nArora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, \\nE. Brunskill et al. , “On the opportuni- ties and risks of \\nfoundation models,” arXiv preprint arXiv:2108.07258, \\n2021.\\n[40] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and \\nD. Yang, “Is chatgpt a general-purpose natu- ral language \\nprocessing task solver?” arXiv preprint arXiv:2302. \\n06476, 2023.\\n[41] S. Longpre, G. Yauney, E. Reif, K. Lee, A. Roberts, B. \\nZoph, D. Zhou, J. Wei, K. Robinson, D. Mimno et al., “A \\npretrainer’s guide to training data: Measur- ing the effects \\nof data age, domain coverage, quality, & toxicity,” arXiv \\npreprint arXiv:2305.13169, 2023.\\n[42] A. Lee, B. Miranda, and S. Koyejo, “Beyond scale: the \\ndiversity coefficient as a data quality metric demon- \\nstrates llms are pre-trained on formally diverse data,” \\narXiv preprint arXiv:2306.13840, 2023.\\n[43] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. \\nMatena, Y . Zhou, W. Li, and P. J. Liu, “Exploring the limits \\nof transfer learning with a unified text-to- text \\ntransformer,” The Journal of Machine Learning Research, \\nV ol. 21, No. 1, pp. 5485–5551, 2020.\\n[44] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, \\nKulshreshtha,  H.-T.  Cheng,  A.  Jin,  T.  Bos, L. Baker, \\nY.  D u  et al. , “Lamda: Language models for dialog \\napplications,” arXiv preprint arXiv:2201.08239, 2022.\\n[45] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili’c, D. \\nHesslow, R. Castagn´e, A. S. Luccioni, F. Yvon, M. Gall´e \\net al., “Bloom: A 176b-parameter open- access \\nmultilingual language model,” arXiv preprint arXiv: \\n2211.05100, 2022.\\n[46] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. \\nHartshorn, E. Saravia, A. Poulton, V . Kerkez, and R. \\nStojnic, “Galactica: A large language model for sci- ence,” \\narXiv preprint arXiv:2211.09085, 2022.\\n[47] Y . Li, D. Choi, J. Chung, N. Kushman, J. Schrit- twieser, \\nR. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago \\net al. , “Competition-level code genera-tion with \\nalphacode,” Science, V ol. 378, No. 6624, pp. 1092–\\n1097, 2022.\\n[48] H. Fu, Yao; Peng and T. Khot, “How does gpt obtain its \\nability? tracing emergent abilities of language mod- els \\nto their sources,” Yao Fu’s Notion, Dec 2022.\\n[49] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . \\nMin, B. Zhang, J. Zhang, Z. Dong et al., “A survey of large \\nlanguage models,” arXiv preprint arXiv:2303.18223, \\n2023.\\n[50] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoff- mann, \\nF. Song, J. Aslanides, S. Henderson, R. Ring, S. Young \\net al., “Scaling language models: Meth-ods, analysis & \\ninsights from training gopher,” arXiv preprint arXiv: \\n2112.11446, 2021.\\n[51] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. \\nDrain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. \\nHenighan, T. Hume et al. , “Scaling laws and in- \\nterpretability of learning from repeated data,” arXiv \\npreprint arXiv:2205.10487, 2022.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='V2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역')], 'question': 'Open  Ko-LLM  Leaderboard에는 ETRI가 참여하고 있어?'}\n",
      "RAG response : 네, Open Ko-LLM Leaderboard에는 ETRI가 참여하고 있습니다.\n",
      "Debug Output: 카카오의 인공지능 윤리 원칙에 책임성이 포함되어 있어?\n",
      "Debug Output: {'context': [Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 10}, page_content='18 특집원고  초거대 언어모델 연구 동향\\n버시 보호, 3) 다양성 존중, 4) 침해금지, 5) 공공성, 6) \\n연대성, 7) 데이터 관리, 8) 책임성, 9) 안정성, 10) 투\\n명성 등의 요건이 충족되어야 한다는 내용이 포함되\\n어 있다.\\n다양한 윤리 원칙에 명시된 내용들은 크게 6가지로 \\n인간성, 책임성, 보안성, 안전성, 투명성, 다양성으로 \\n구분된다.\\n인간성 (Humanity & Human-centered)은 인공지능\\n의 개발과 활용은 인간과 사회에 유익한 가치를 제공\\n하며 인간의 권리와 자유를 침해하지 않는다는 내용\\n이다.\\n책임성 (Responsibility & Accountability)은 인공지\\n능을 개발하고 활용하는 주체들의 역할과 책임을 명\\n확히 설정하여 발생할 수 있는 피해를 최소화 한다는 \\n내용이다.\\n보안성 (Privacy & Security)은 인공지능 개발 및 활\\n용하는 과정에서 사용자의 개인정보와 프라이버시를 \\n보호하기 위해 정보 보안을 고려하여 설계한다는 내\\n용이다.\\n안전성 (Safety & Reliability)은 인공지능의 개발과 \\n활용 과정에서 발생할 수 있는 잠재적 위험에 대응하\\n고 안전하게 작동할 수 있도록 한다는 내용이다.\\n투명성 (Transparency & Explainability)은 인공지능 \\n의 작동 방식 또는 데이터 활용 방안에 대해 투명하\\n게 공개하여 사용자들의 이해를 높이고 신뢰할 수 있\\n도록 한다는 내용이다. \\n다양성 (Fairness & Diversity)은 인공지능을 개발하\\n고 활용하는 과정에서 성별･연령･국적･인종･지역･종\\n교 등에 대한 차별을 최소화하여 다양한 가치를 존중\\n한다는 내용이다.\\n이외에도 각 기업마다 인공지능 윤리원칙을 제시하\\n고 있으며 이에 대한 정보는 표 1과 같다.\\n7. 결  론\\n본 논문은, 초거대언어모델 (LLM)의 발전과 활용\\n에 대한 근본적인 이해를 제공하려 하였다. LLM 의 \\n등장은 자연언어처리 (NLP)의 다양한 분야에서 혁신\\n적인 변화를 가져왔으며, 이로 인해 번역, 요약, 질의\\n응답, 형태소분석 등 다양한 태스크들이 하나의 모델\\n로 수행될 수 있게 되었다. 데이터의 양적 확대, 컴퓨\\n팅 기술의 진보, 그리고 알고리즘 및 기술의 발전은 \\nLLM의 발전을 이끌었다. 이러한 기술적, 연구적 발전\\n은 교육, 의료, 금융, 제조 등 다양한 산업 분야에서 \\nLLM의 활용 가능성을 넓혔다. 그러나, LLM 의 활용\\n과 발전에는 여러 가지 도전 과제와 문제점이 존재한\\n다. 편향성, 안전성, 설명 가능성 및 최신성 문제는 \\nLLM의 한계점으로 지속적으로 고려되어야 하며, 이\\n러한 문제점들을 해결하는 것은 다가오는 연구에서의 \\n중요한 도전 과제로 남아 있다. 이러한 문제와 도전을 \\n극복함으로써, LLM 은 향후 NLP 연구와 산업계에서 \\n더욱 중요한 역할을 차지할 것으로 예상된다. 이 분야\\n의 연구가 계속 진행됨에 따라, 더욱 정교하고 다양한 \\n어플리케이션의 등장이 기대되며, 이를 통해 사회적, \\n산업적 가치가 더욱 향상될 것이다. LLM 의 연구와 \\n활용은 계속되는 윤리적 고민과 함께 발전해 나가야 \\n하며, 향후 연구는 이러한 모델의 가능성과 한계를 더\\n욱 탐색하고 활용 하는 방향으로 전개될 것으로 보인\\n다. 본 논문이 LLM에 대한 깊이 있는 이해를 제공하\\n고, 이 분야의 연구자 및 전문가들에게 유익한 인사이\\n트와 지침을 제공할 수 있기를 희망한다.\\n참고문헌\\n[ 1 ] J. Zhang, H. Feng, B. Liu, and D. Zhao, “Survey of \\ntechnology in network security situation awareness,” \\nSensors, V ol. 23, No. 5, p. 2608, 2023.\\n[ 2 ] D. Bahdanau, K. Cho, and Y . Bengio, “Neural machine \\ntranslation by jointly learning to align and translate,” \\narXiv preprint arXiv:1409.0473, 2014.\\n[ 3 ] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, \\nA. N. Gomez, L- . Kaiser, and I. Polosukhin, “Attention \\nis all you need,” Advances in neural infor- mation \\nprocessing systems, V ol. 30, 2017.\\n[ 4 ] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. \\nChess, R. Child, S. Gray, A. Radford, J. Wu, and D. \\nAmodei, “Scaling laws for neural language models,” \\narXiv preprint arXiv:2001.08361, 2020.\\n[ 5 ] I. L. Alberts, L. Mercolli, T. Pyka, G. Prenosil, K. Shi, A. \\nRominger, and A. Afshar-Oromieh, “Large lan- guage \\nmodels (llm) and chatgpt: what will the impact on nuclear \\nmedicine be?” European journal of nuclear medicine and \\nmolecular imaging, V ol. 50, No. 6, pp. 1549–1552, 2023.\\n[ 6 ] M. Fraiwan and N. Khasawneh, “A review of chat- gpt \\napplications in education, marketing, software en- \\ngineering, and healthcare: Benefits, drawbacks, and re- \\nsearch directions,” arXiv preprint arXiv:2305.00237, \\n2023.\\n[ 7 ] M. Sallam, N. Salim, M. Barakat, and A. Al-Tammemi, \\n“Chatgpt applications in medical, dental, pharmacy, and \\npublic health education: A descriptive study high-'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='2023. 11 정보과학회지 17\\n의 경우도 많은 모델들이 OpenLLM Leaderboard에 참\\n가하고 있으며, 특히 업스테이지가 두드러진 성과를 \\n보였다. 업스테이지는 해당 리더보드에서 두 번이나 \\n세계 1위의 자리를 차지한 뛰어난 성과를 보였다. 이\\n로 인해 다양한 국내 기업들이 이 리더보드에서의 경\\n쟁에 참여하게 되었으며, 국내 LLM 연구 분야 활성\\n화에 일조하였다.\\n5.2 Open Ko-LLM Leaderboard\\n한국어에서도 Open LLM 리더보드가 운영되고 있다. \\nO p e n  K o - L L M  L e a d e r b o a r d21)라는 이름으로 NIA와 \\n업스테이지에서 공동 주관을 하고 있으며, KT Cloud\\n의 인프라 지원으로 운영되고 있다 . Ko-HellaSwag, \\nKo-MMLU, Ko-Arc, Ko-Truthful QA, Ko-CommonGen \\nV2의 총 5가지 태스크로 운영되고 있다. 기존 영어 \\nOpenLLM Leaderboard에서 운영하고 있는 4개의 태\\n스크를 한국어화 시킨 데이터에, 고려대학교 자연언\\n어처리 연구실에서 구축한 Ko-CommonGen V2 밴치\\n마크 데이터셋을 추가하여, 평가 지표로 활용하고 있\\n는 리더보드이다.\\n해당 리더보드는 오픈 후 2주만에 100개가 넘는 모\\n델들이 참여할 뿐만 아니라, 한국의 대표적인 Open \\nLLM인 Polyglot-Ko [38], KULLM 22), KoAlpaca 23)와 \\n더불어 42MARU24), ETRI 25), Maum.AI 26) 등 다양한 \\n21) https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\\n22) https://github.com/nlpai-lab/KULLM  \\n23) https://github.com/Beomi/KoAlpaca\\n기업들이 참여하고 있다. 오픈 초기 모델들은 평균 점\\n수가 대부분 30점대 초반이었으나 2주만에 대부분 45\\n점을 돌파하여 50%의 큰 향상폭을 보여주고 있다. 즉 \\n다양한 모델들의 활발한 참여와 치열한 경쟁이 펼쳐\\n지고 있다. 해당 리더보드를 통해 한국어 LLM 평가 \\n생태계에 큰 기여를 하고 있으며, 현재 평가 허브 역\\n할을 감당하고 있다.\\n6. 초거대 언어모델 윤리 원칙 동향\\nLLM을 포함한 인공지능 모델에 대한 적절한 개발\\n과 올바른 활용을 위한 윤리 원칙이 필수적이다. 각 \\n국제기구, 정부, 기업에서는 인공지능 윤리 원칙을 마\\n련하여 인공지능을 개발하고 활용하는 주체들이 이를 \\n준수하도록 방향을 제시하고 있다.\\n과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고 \\n있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을 \\n지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이\\n24) https://www.42maru.ai/kr/\\n25) https://www.etri.re.kr/intro.html \\n26) https://maum.ai/'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='있다. 3대 기본원칙에는 인간성을 구현하기 위해 인공\\n지능의 개발 및 활용 과정에서 1) 인간의 존엄성 원칙, \\n2) 사회의 공공선 원칙, 3) 기술의 합목적성 원칙을'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 16}, page_content='24 특집원고  초거대 언어모델 연구 동향\\n[117]P . Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, \\nC. Schoenick, and O. Tafjord, “Think you have solved \\nquestion answering? try arc, the ai2 reasoning challenge,” \\narXiv preprint arXiv:1803.05457, 2018.\\n[118]R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, \\n“Hellaswag: Can a machine really finish your sentence?” \\nProceedings of the 57th Annual Meeting of the Association \\nfor Computational Linguistics, pp. 4791–4800, 2019.\\n[119] D.  Hendrycks,  C.  Burns,  S.  Basart,  A.  Zou, M. Mazeika, \\nD. Song, and J. Steinhardt, “Measuring massive multitask \\nlanguage understanding,” Interna- tional Conference on \\nLearning Representations, 2020.\\n[120]S. Lin, J. Hilton, and O. Evans, “Truthfulqa: Measur- ing \\nhow models mimic human falsehoods,” Proceed- ings of \\nthe 60th Annual Meeting of the Association for \\nComputational Linguistics (Volume 1: Long Papers), pp. \\n3214–3252, 2022.\\n \\n박 찬 준\\n2019 부산외국어대학교 언어처리창의융합과 졸업 \\n(학사)\\n2023 고려대학교 컴퓨터학과 졸업 (박사)\\n2018~2019 SYSTRAN Research Engineer\\n2022~현재 Upstage Technical Leader\\n관심분야 : 자연언어처리, 초거대언어모델, 기계번역, \\n데이터중심 인공지능\\nEmail : chanjun.park@upstage.ai\\n이 원 성\\n2012 연세대학교 정보산업공학과 졸업 (학사)\\n2018 KAIST 산업및시스템공학과 졸업 (박사)\\n2018~2021 SK Telecom Data Scientist\\n2021~현재 Upstage Technical Leader\\n관심분야 : 추천시스템, 초거대언어모델, 개인화 AI\\nEmail : wonsung.lee@upstage.ai\\n김 윤 기\\n2020 한양대학교 산업공학과 졸업 (학사)\\n2023 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2023~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : eddie@upstage.ai\\n김 지 후\\n2019 경희대학교 산업경영공학과 졸업 (학사)\\n2021 한양대학교 컴퓨터소프트웨어학과 졸업 (석사)\\n2021~현재 Upstage AI Research Engineer\\n관심분야 : 추천시스템, 초거대언어모델, 초개인화 AI\\nEmail : jerry@upstage.ai\\n이 활 석\\n2011 KAIST 전기 및 전자공학 졸업 (박사)\\n2011~2016 한화테크윈 선행기술 연구원 비전기술\\n그룹 연구원\\n2016~2017 NCSOFT AI Center AI Lab Vision TF 연구원\\n2017~2020 네이버 Clova Visual AI 책임리더\\n2020~현재 Upstage CTO\\n관심분야 : 초거대언어모델, OCR\\nEmail : hwalsuk.lee@upstage.ai'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='과학기술정보통신부가 2020년 12월 23일에 마련한 \\n인공지능 (AI) 윤리기준은 최고 가치인 인간성(Humanity)\\n을 위한 3대 기본원칙과 10대 핵심요건을 제시하고'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 6}, page_content='14 특집원고  초거대 언어모델 연구 동향\\n이러한 alignment criteria 는 대부분 인간의 인식을 \\n기반으로 하므로 LLM에 직접 최적화 목표로서 차용\\n하기에는 어려움이 따른다. 이에, LLM을 인간의 가치\\n와 일치시키기 위한 방법으로 인간의 피드백을 기반\\n으로 한 강화 학습 (RLHF) [27, 69] 이 제안되었다. \\nRLHF는 수집된 인간의 피드백 데이터를 활용하여 \\nLLM을 미세조정하는 방법으로 상술한 alignment criteria\\n를 개선하는 데 유용하다. RLHF 는 강화 학습 알고리\\n즘을 사용하여 인간의 피드백을 바탕으로 보상 모델\\n을 학습하면서 LLM을 적응시킨다. InstructGPT [27] \\n또는 ChatGPT와 같은 성공 사례에서 알 수 있듯이, \\n인간을 학습 루프에 포함시키는 이러한 방법은 LLM\\n을 well-aligned 형태로 개선하는 데 중요한 역할을 한\\n다. 결과적으로, 개선된 LLM은 편향이 적고, 더욱 안\\n전한 내용을 생성하게 된다 . Alignment Tuning 이 \\nLLM의 사용성 개선을 위해 중요함에도 불구하고, 주\\n관적인 alignment criteria의 특성 상 의도치 않은 부작\\n용이 발생하기도 한다 . 실제로, alignment 과정이 \\nLLM의 기본 능력을 일정부분 감소시킬 수도 있음이 \\n밝혀졌으며, 이러한 현상을 alignment tax라고 부른다 \\n[70].\\n4.2.3 Resource-Efficient Fine-Tuning\\n다음으로 LLM의 계산 집약적 특성으로 인한 한계\\n를 개선하기 위한 방법론인 자원 효율적인 (Resource- \\nEfficient) 미세조정 방법에 대해서도 간략히 언급할 \\n것이다. LLM 들은 수많은 모델 파라미터를 가지고 있\\n기 때문에, 각 미세조정 시에 모든 파라미터를 튜닝하\\n는 것은 비용 관점에서 비효율적이다. 따라서, 가능한 \\n한 좋은 성능을 유지하면서, 학습가능한 파라미터의 \\n수를 줄이는 Parameter-Efficient Fine-Tuning (PEFT) \\n방법에 대해 살펴볼 것이다.\\nAdaptor Tuning [71, 72] 은 Transformer 구조에 \\nadaptor라 부르는 작은 신경망 모듈을 추가한다. 이 \\n과정에서 원래의 언어 모델의 파라미터는 고정된 상\\n태로, adaptor 모듈의 파라미터만 특정 태스크 목적을 \\n달성하기 위해 최적화된다. Prefix Tuning [73] 은 학습\\n가능한 연속 벡터로 구성된 일련의 prefix 시퀀스를 \\n각 Transformer 레이어에 추가한다. 이러한 prefix \\nvector들은 태스크 별로 할당되며, 일종의 가상 토큰 \\n임베딩으로 볼 수 있다. 마찬가지로 prefix 파라미터\\n만 학습되기 때문에, 파라미터 효율적인 방식의 최적\\n화가 가능하다.\\nTransformer 모델 계층에 학습가능한 벡터를 추가\\n하는 Pre-fix Tuning 과는 대조적으로, Prompt Tuning \\n[74, 75]은 학습 가능한 프롬프트 벡터를 입력 계층에 \\n추가하는 형태로 이루어진다. 입력 텍스트에 프롬프트 \\n토큰을 덧붙이고, 학습 과정에서 프롬프트 임베딩만 \\n최적화되기 때문에 효율적인 태스크 특화 미세조정이 \\n가능하다. Low-Rank Adaptation (LoRA) [76] 은 이름\\n에서 알 수 있듯이 PEFT에 low-rank approximation을 \\n차용한다. 모델의 파라미터 W0를 업데이트한다고 가\\n정하자. 이 과정은 W0 ← W0 +  ∆W로 서술할 수 있\\n다. 이때, 원래의 파라미터 행렬 W0 ∈ Rd×k는 고정한 \\n뒤, 업데이트 행렬 ∆W 를 low-rank 행렬 분해를 통\\n해 근사함으로써 업데이트 식을 다음과 같이 표현할 \\n수 있다: W 0 +  ∆W ≃ W0 +  B A ,  이때, B ∈ Rd×r, A \\n∈ Rr×k, 그리고 rank r ≪ min(d, k )이다. 결과적으로, \\nLoRA는 메모리 및 스토리지 비용을 크게 절약할 수 \\n있으며 태스크 별로 효과적인 모델 적응을 가능케 한\\n다. 지금까지 PEFT 방법을 간략하게 살펴보았다. 이\\n에 대한 보다 심도있는 논의는 다음 논문들을 참고하\\n길 바란다 [77, 78].\\n또다른 자원효율적인 미세조정 방법으로는 Memory- \\nEfficient Fine-Tuning 방법이 있다. LLM 은 많은 모델 \\n파라미터로 인해 추론 시에 대용량의 메모리를 필요\\n로 하며, 이는 LLM의 활용 관점에서 매우 큰 장애물\\n이다. 이를 해결하기 위해서, 양자화 (quantization) [79]\\n와 같은 모델 압축 (model compression) 접근법을 통\\n해 LLM의 메모리 사용량을 줄이는 방법들이 활발하\\n게 연구되고 있다 [80, 81].\\n4.3 활용 및 증강\\n4.3.1 Utilization of LLMs\\n해당 섹션에서는 LLM을 활용하는 방법들에 살펴\\n볼 것이다. LLM 을 활용하는 가장 대표적인 방법 중 \\n하나는 태스크를 해결하기 위한 적절한 프롬프팅 전\\n략을 수립하는 것이고, 대표적인 프롬프팅 방법으로\\n는 in-context learning (ICL) 이 있다 . ICL 은 시연 \\n(demonstration) 형태의 몇 가지 예시만으로 언어 모 \\n델이 태스크를 학습하게 하는 방식이다. 이는 잘 훈련\\n된 언어 모델이 시연에 기반하여 태스크의 잠재적인 \\n특성을 파악할 수 있음을 전제로 한다. ICL 을 위한 \\n프롬프트는 자연어 텍스트 형태의 태스크 설명, 시연\\n을 위한 몇 가지 예시 및 테스트 쿼리로 구성된다. 최\\n신 연구 [82]에 따르면, ICL 은 다음과 같은 다양한 이\\n점을 보유하고 있다. 첫째, 자연어 형태로 제공되는 \\n시연은 LLM과의 명확하고 이해하기 쉬운 소통 방식\\n을 제공한다 [22]. 둘째, ICL 은 유사성에서 학습하는'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 9}, page_content='지켜야 한다는 내용을 담고 있다. 10대 핵심요건에는 \\n3대 기본원칙을 실천하고 이행할 수 있도록 인공지능 \\n개발부터 활용 전 과정에서 1) 인권 보장, 2) 프라이'), Document(metadata={'source': '초거대 언어모델 연구 동향.pdf', 'page': 10}, page_content='명성 등의 요건이 충족되어야 한다는 내용이 포함되\\n어 있다.\\n다양한 윤리 원칙에 명시된 내용들은 크게 6가지로 \\n인간성, 책임성, 보안성, 안전성, 투명성, 다양성으로')], 'question': '카카오의 인공지능 윤리 원칙에 책임성이 포함되어 있어?'}\n",
      "RAG response : 제공된 문맥에서는 카카오의 인공지능 윤리 원칙에 대한 구체적인 내용이 언급되지 않았습니다. 그러나 일반적으로 인공지능 윤리 원칙에는 책임성이 포함되어 있으며, 이는 인공지능을 개발하고 활용하는 주체들의 역할과 책임을 명확히 설정하여 발생할 수 있는 피해를 최소화하는 내용을 포함합니다. 따라서 카카오의 윤리 원칙에도 책임성이 포함될 가능성이 높습니다.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"질문을 입력하세요! 종료를 원한다면 exit을 입력하세요.\")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    \n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    print(\"RAG response : \" + response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-RAG 모델과의 비교\n",
    "- Hallucination을 일으킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 모델 초기화\n",
    "model_raw = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: Open  Ko-LLM  Leaderboard에는 어떤 기업들이 참여하고 있어?\n",
      "Raw AI Response: Open Ko-LLM Leaderboard는 Kakao Brain, Kakao Enterprise, NAVER, AILAB, SK T-Brain, LG CNS, LG Electronics, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMSUNG Research, SAMSUNG SDS, SAMSUNG Electronics, SAMS\n",
      "question: Open  Ko-LLM  Leaderboard에는 카카오가 참여하고 있어?\n",
      "Raw AI Response: 네, Open Ko-LLM Leaderboard에는 카카오가 참여하고 있습니다.\n",
      "question: 한국의 LLM 리더보드에 ETRI가 참여하고 있어?\n",
      "Raw AI Response: 죄송하지만, 제가 알기로는 현재 Open Ko-LLM Leaderboard에 ETRI(한국전자통신연구원)가 참여하고 있는지에 대한 정보는 없습니다. 최신 정보를 확인하려면 해당 리더보드의 공식 웹사이트나 관련 기관의 공식 발표를 참고하시는 것이 좋을 것 같습니다.\n",
      "question: 카카오의 인공지능 윤리 원칙에 책임성이 포함되어 있어?\n",
      "Raw AI Response: 네, 카카오의 인공지능 윤리 원칙에는 책임성이 포함되어 있습니다. 카카오는 인공지능 기술을 개발하고 활용함에 있어서 사용자의 프라이버시와 안전을 보호하고, 공정성과 투명성을 유지하며, 사회적 책임을 다하는 것을 중요하게 생각하고 있습니다. 이러한 가치를 바탕으로 카카오는 다양한 인공지능 기술을 개발하고 서비스에 적용하고 있습니다.\n",
      "question: 확실해?\n",
      "Raw AI Response: 죄송합니다. 제가 이전에 말씀드린 내용은 잘못된 정보였습니다. 카카오의 인공지능 윤리 원칙에 책임성이 명시되어 있는지에 대해서는 정확한 정보를 확인할 수 없습니다. 카카오의 공식 웹사이트나 관련된 공식 발표를 참고하시는 것이 더 정확한 정보를 얻을 수 있을 것입니다. 이용자분께 혼란을 드려 죄송합니다.\n"
     ]
    }
   ],
   "source": [
    "# 시스템 메시지 설정\n",
    "system_message = SystemMessage(content=\"너는 최근 초거대 언어모델 연구 동향을 알려주는 인공지능이야. 질문에 알맞은 답변을 해줘.\")\n",
    "messages = [system_message]\n",
    "\n",
    "while True:\n",
    "    # 유저 입력\n",
    "    user_input = input(\"질문을 입력하세요 : \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    print(\"question: \" + user_input)\n",
    "    # 사용자 메시지 추가\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    \n",
    "    # ChatOpenAI 모델을 이용해 답변 생성\n",
    "    response = model_raw.invoke(messages)\n",
    "    \n",
    "    # AI의 답변을 가져와 저장\n",
    "    reply = response.content\n",
    "    messages.append(AIMessage(content=reply))\n",
    "    \n",
    "    print(\"Raw AI Response: \" + reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 왜 RAG 이 필요한가\n",
    "\n",
    "- RAG를 통해 LLM 모델의 Hallucination을 줄일 수 있으며 업데이트 되지 않은 최신 소식 / 답변하고자 하는 최신 소식 / 본인 서비스에 대한 사적인 정보에 대한 답변을 할 수 있기 때문임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
